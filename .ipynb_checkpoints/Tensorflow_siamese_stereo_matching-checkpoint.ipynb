{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.compat.v1 as tf1\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import ndimage\n",
    "from CBCA import *\n",
    "from sgm import *\n",
    "import scipy\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d(input_images, weight):\n",
    "    return tf.nn.conv2d(input_images, weight ,strides=[1,1,1,1], padding='SAME',name=\"conv\")\n",
    "\n",
    "def max_pool(x):\n",
    "    return tf.nn.max_pool(x,[1,2,2,1],[1,2,2,1], padding='VALID',name='maxpool')\n",
    "\n",
    "def conv_bn_relu(input_layer, bias_shape, kernel_shape, phase, scope ,reuse =False ):\n",
    "    with tf.compat.v1.variable_scope(scope, reuse = reuse):\n",
    "        W = tf.compat.v1.get_variable(\"weight\", kernel_shape, initializer=tf1.glorot_uniform_initializer())\n",
    "        b = tf.compat.v1.get_variable(\"biases\", bias_shape ,initializer=tf1.glorot_uniform_initializer())\n",
    "        conv = conv2d(input_layer, W)\n",
    "        output = tf.nn.bias_add(conv, b)\n",
    "        normal = tf.compat.v1.layers.batch_normalization(output, training = phase)\n",
    "        out = tf.nn.relu(normal)\n",
    "    return out\n",
    "\n",
    "def conv(input_layer, bias_shape, kernel_shape,scope, reuse=False):\n",
    "    with tf.compat.v1.variable_scope(scope,reuse = reuse):\n",
    "        W = tf.compat.v1.get_variable(\"weight\", kernel_shape, initializer=tf1.glorot_uniform_initializer())\n",
    "        b = tf.compat.v1.get_variable(\"biases\", bias_shape ,initializer=tf1.glorot_uniform_initializer())\n",
    "        conv = conv2d(input_layer, W)\n",
    "        out = tf.nn.bias_add(conv, b)\n",
    "        \n",
    "    return out\n",
    "\n",
    "def deconv(input_layer, bias_shape, kernel_shape, output_shape, scope ,reuse =False):\n",
    "    with tf.compat.v1.variable_scope(scope, reuse = reuse):\n",
    "        W = tf.compat.v1.get_variable(\"weight\", kernel_shape, initializer=tf1.glorot_uniform_initializer())\n",
    "        b = tf.compat.v1.get_variable(\"bias\", bias_shape, initializer=tf1.glorot_uniform_initializer())\n",
    "        deconv = tf.nn.conv2d_transpose(input_layer, W, output_shape, strides = [1,2,2,1])\n",
    "        out = tf.nn.bias_add(deconv, b)\n",
    "        \n",
    "        return out\n",
    "def inner_product(left, right, disp, width):\n",
    "    disp_vol = []\n",
    "    for i in range(disp):\n",
    "        output = tf.reduce_sum(tf.multiply(left, right[:,:,disp-i-1:disp -1 -i + width,: ]),axis =3)\n",
    "        disp_vol.append(output)\n",
    "        logits = tf.transpose(tf.stack(disp_vol),[1,2,3,0])\n",
    "        \n",
    "    return logits\n",
    "\n",
    "def compute_loss(y_truth, y_pre):\n",
    "\n",
    "    num_classes = 129\n",
    "    valid_pixels = tf.not_equal(y_truth, 0)\n",
    "    labels = tf.reshape(tf.boolean_mask(y_truth, valid_pixels),[-1])\n",
    "    logits = tf.reshape(tf.boolean_mask(y_pre, valid_pixels),[-1, 129])\n",
    "    loss = tf.nn.sparse_softmax_cross_entropy_with_logits(labels, logits)\n",
    "    cross_entropy = tf.reduce_mean(loss)\n",
    "  \n",
    "    return cross_entropy\n",
    "def network_4(input_image, n_channels, n_filters, batch_size, H,W, phase , reuse=False):\n",
    "    n1 = conv_bn_relu(input_image,bias_shape=[n_filters], kernel_shape=[3,3,n_channels,n_filters], phase = phase, scope ='conv1',reuse = reuse )\n",
    "    n2 = conv_bn_relu(n1, bias_shape=[n_filters], kernel_shape=[3, 3, n_filters, n_filters], phase = phase, scope = 'conv2',reuse=reuse )\n",
    "    n2 = max_pool(n2)\n",
    "    n3 = conv_bn_relu(n2, [n_filters], kernel_shape=[3,3,n_filters,n_filters], phase = phase, scope ='conv3',reuse=reuse)\n",
    "    n4 = conv(n3,[n_filters],[3,3,n_filters,n_filters],'conv4',reuse= reuse)\n",
    "    n5 = deconv(n4, [n_filters], [3, 3, n_filters, n_filters],[batch_size , H, W, n_filters],'deconv1',reuse = reuse)\n",
    "    \n",
    "    return n5\n",
    "\n",
    "def accuracy_calculate(Y_truth, Y_pre):\n",
    "    compare = tf.equal(Y_truth, tf.cast(tf.argmax(Y_pre,-1), tf.int32))\n",
    "    accuracy = tf.reduce_mean(tf.cast(compare,\"float\")) \n",
    "    return accuracy\n",
    "\n",
    "def error(output,y_,threshold=5):\n",
    "    errors = np.abs(output-y_)\n",
    "    valid_pixels = errors[y_!=0]\n",
    "    n_err   = np.sum(valid_pixels > threshold)\n",
    "    n_total = len(valid_pixels)\n",
    "    return float(n_err)/float(n_total)\n",
    "\n",
    "def network_7(input_image, n_channels, n_filters, batch_size, H, W, phase, reuse=False):\n",
    "    \n",
    "    n1 = conv_bn_relu(input_image, [n_filters], kernel_shape=[3, 3, n_channels,n_filters], phase = phase, scope ='conv1',reuse = reuse )\n",
    "    n2 = conv_bn_relu(n1, [n_filters], kernel_shape = [3, 3, n_filters, n_filters], phase = phase,  scope = 'conv2', reuse=reuse )\n",
    "    \n",
    "    n2 = max_pool(n2)\n",
    "    \n",
    "    n3 = conv_bn_relu(n2, [n_filters], kernel_shape = [3, 3, n_filters, n_filters], phase = phase, scope = 'conv3', reuse=reuse)\n",
    "    n4 = conv_bn_relu(n3, [n_filters], kernel_shape = [3, 3, n_filters, n_filters], phase = phase, scope = 'conv4', reuse=reuse)\n",
    "    \n",
    "    n4 = max_pool(n4)\n",
    "    \n",
    "    n5 = conv_bn_relu(n4, [n_filters], kernel_shape = [3, 3, n_filters, n_filters], phase = phase, scope = 'conv5', reuse=reuse)\n",
    "    n6 = conv_bn_relu(n5, [n_filters], kernel_shape = [3, 3, n_filters, n_filters], phase = phase, scope = 'conv6', reuse=reuse)\n",
    "    \n",
    "    n7 = conv(n6,[n_filters],[3,3,n_filters,n_filters],'conv7',reuse= reuse)\n",
    "    \n",
    "    n8 = deconv(n7, [n_filters], [3, 3, n_filters, n_filters],[batch_size , int(H /2), int(W /2), n_filters],'deconv1',reuse = reuse)\n",
    "    n9 = deconv(n8, [n_filters], [3, 3, n_filters, n_filters],[batch_size , H, W, n_filters],'deconv2',reuse = reuse)\n",
    "    \n",
    "    return n9\n",
    "    \n",
    "def init_placeholder():\n",
    "    tf1.disable_eager_execution()\n",
    "    tf1.reset_default_graph()\n",
    "    phase = tf1.placeholder(tf1.bool)\n",
    "    with tf1.name_scope(\"Im_left\"):\n",
    "        image_left  = tf.compat.v1.placeholder(tf.float32, left_shape,  name='image_left' )\n",
    "    with tf1.name_scope(\"Im_right\"):\n",
    "        image_right = tf.compat.v1.placeholder(tf.float32, right_shape, name='image_right')\n",
    "    with tf1.name_scope(\"Im_gt\"):\n",
    "        im_gt = tf.compat.v1.placeholder(tf.int32, gt_shape, name='groud_truth')\n",
    "\n",
    "    return phase, image_left, image_right, im_gt\n",
    "\n",
    "\n",
    "def make_architecture(phase, image_left, image_right, im_gt):\n",
    " \n",
    "    with tf.compat.v1.name_scope(\"stereo_matching\") as scope:\n",
    "        left_network =  network_7(image_left,  3, 64,batch_size, rec_field, rec_field, phase = phase)\n",
    "        right_network = network_7(image_right, 3, 64,batch_size, rec_field, patch_right,phase=phase, reuse=True)\n",
    "\n",
    "    with tf1.name_scope(\"Model\"):\n",
    "        output = inner_product(left_network, right_network, num_classes, rec_field)\n",
    "\n",
    "\n",
    "    with tf1.name_scope(\"Loss\"):\n",
    "        loss = compute_loss(im_gt,output)\n",
    "\n",
    "\n",
    "    global_step = tf.Variable(0, trainable=False)\n",
    "    starter_learning_rate = 0.00001\n",
    "    learning_rate = tf.compat.v1.train.exponential_decay(starter_learning_rate,\n",
    "                                                      global_step, 4000, 0.96, staircase=True)\n",
    "    update_ops = tf1.get_collection(tf1.GraphKeys.UPDATE_OPS)\n",
    "    with tf1.control_dependencies(update_ops):\n",
    "        train_network = tf.compat.v1.train.AdamOptimizer(learning_rate = learning_rate).minimize(loss,global_step=global_step)\n",
    "\n",
    "    return loss, output, train_network\n",
    "\n",
    "\n",
    "def inner_product_test(h9_left, h9_right, batch_size, rows, cols, n_classes):\n",
    "    prod_left=np.ones((batch_size,rows,cols,n_classes))*(-1e9)\n",
    "    prod_right=np.ones((batch_size,rows,cols,n_classes))*(-1e9)\n",
    "    start=0\n",
    "\n",
    "    for disp in range(n_classes):\n",
    "        \n",
    "        \n",
    "        if (cols-disp  > 0):\n",
    "            left_features = h9_left[:,:,disp:cols,:]\n",
    "            right_features = h9_right[:,:,0:cols-disp ,:]\n",
    "\n",
    "            multiplication = np.multiply(left_features,right_features)\n",
    "            inner_product = np.sum(multiplication,axis=3)\n",
    "            \n",
    "            prod_left[:,:,disp:cols, disp] = inner_product\n",
    "            prod_right[:,:,0:cols-disp,disp] = inner_product\n",
    "    \n",
    "    return prod_left, prod_right\n",
    "\n",
    "\n",
    "def processs_input_image(image):\n",
    "    image=np.array(image,dtype=np.float32)\n",
    "    image=(image-np.mean(image))/np.std(image)\n",
    "    return image\n",
    "  \n",
    "def train(left_images,right_images,disp_images):\n",
    "\n",
    "    phase, image_left, image_right, im_gt = init_placeholder()\n",
    "    loss, output, train_network = make_architecture(phase, image_left, image_right, im_gt)\n",
    "    log_dir = '/content/drive/My Drive/Colab Notebooks/log_dirs'\n",
    "    saver = tf1.train.Saver()\n",
    "    tf1.summary.scalar(\"Loss\", loss)\n",
    "    merged_summary_op = tf1.summary.merge_all() \n",
    "    writer = tf1.summary.FileWriter('./graphs',graph=tf1.get_default_graph())\n",
    "\n",
    "    variable_init = tf1.global_variables_initializer()\n",
    "    with tf1.Session() as sess:\n",
    "      #sess.run(variable_init)\n",
    "        saver.restore(sess, path_check_1+\"/model_1.ckpt\")\n",
    "        for i in range(epoch):\n",
    "            left, right, gt=load_random_patch(left_images,right_images,disp_images,rec_field,right_left,max_disp,batch_size,valid_pixels_train)\n",
    "\n",
    "            left = left.astype('float32') / 255\n",
    "            right = right.astype('float32') / 255\n",
    "            _, summ = sess.run([train_network, merged_summary_op],feed_dict = {image_left: left ,\n",
    "                                                                  image_right: right,\n",
    "                                                                  im_gt: gt,\n",
    "                                                                  phase : True})\n",
    "            writer.add_summary(summ, i)\n",
    "\n",
    "            if i%50 == 0 :\n",
    "\n",
    "                L_train, out_train = sess.run([loss, output], feed_dict={image_left: left,\n",
    "                                                            image_right: right,\n",
    "                                                            im_gt: gt, \n",
    "                                                            phase : False})\n",
    "                err_train = error(np.argmax(out_train,-1), gt)\n",
    "\n",
    "\n",
    "\n",
    "                print('\\r',\"Epoch:\",str(i),\" Loss:\",'{:.5}'.format(str(L_train)), \"Error:\",'{:.5}'.format(str(err_train)), end='')\n",
    "\n",
    "\n",
    "            if i % 500 == 0:\n",
    "                saver.save(sess, path_check_2+\"/model_2.ckpt\")\n",
    "                \n",
    "def pred(im_left, im_right):\n",
    "  \n",
    "    \n",
    "    tf1.disable_eager_execution()\n",
    "    phase, image_left, image_right, im_gt = init_placeholder()\n",
    "    with tf.compat.v1.name_scope(\"stereo_matching\") as scope:\n",
    "        n9_left =  network_7(image_left,  3, 64, batch_size, img_h, img_w, phase = phase)\n",
    "        n9_right = network_7(image_right, 3, 64, batch_size, img_h, img_w, phase = phase, reuse=True)\n",
    "    \n",
    "    \n",
    "    sess = tf1.Session()\n",
    "    saver = tf1.train.Saver()\n",
    "    saver.restore(sess, path_check+'model_250k.ckpt')\n",
    "  \n",
    "    #Adding axis to image\n",
    "    left =  im_left [np.newaxis,...]\n",
    "    right = im_right[np.newaxis,...]\n",
    "    \n",
    "    #Resize image\n",
    "    left_resized  = tf1.image.resize_images(left,  resize_shape)\n",
    "    right_resized = tf1.image.resize_images(right, resize_shape)\n",
    "\n",
    "\n",
    "    \n",
    "    left_, right_ = sess.run([left_resized, right_resized])\n",
    "\n",
    "    left_vol, right_vol = sess.run([n9_left, n9_right],feed_dict={ image_left : left_,\n",
    "                                                                   image_right: right_,\n",
    "                                                                   phase : False})\n",
    "    \n",
    "    prod_left, prod_right = inner_product_test(left_vol, right_vol, batch_size, img_h, img_w, num_classes)\n",
    "    \n",
    "    print(\"prod_left\",prod_left.shape)\n",
    "    print(\"prod_left\",prod_right.shape)\n",
    "    out_disp_L = np.argmax(prod_left, 3)[0,:,:]\n",
    "    out_disp_R = np.argmax(prod_right, 3)[0,:,:]\n",
    "    \n",
    "    return prod_left, prod_right, left_[0], right_[0]\n",
    "\n",
    "def test(im_left, im_right, gt):\n",
    "  \n",
    "    \n",
    "    tf1.disable_eager_execution()\n",
    "    phase, image_left, image_right, im_gt = init_placeholder()\n",
    "    with tf.compat.v1.name_scope(\"stereo_matching\") as scope:\n",
    "        n7_left =  network_7(image_left,  3, 64, batch_size, img_h, img_w, phase = phase)\n",
    "        n7_right = network_7(image_right, 3, 64, batch_size, img_h, img_w, phase = phase, reuse=True)\n",
    "    \n",
    "    \n",
    "    sess = tf1.Session()\n",
    "    saver = tf1.train.Saver()\n",
    "    saver.restore(sess, path_check+'model_250k.ckpt')\n",
    "\n",
    "    #Adding axis to image\n",
    "    left =  im_left [np.newaxis,...]\n",
    "    right = im_right[np.newaxis,...]\n",
    "    im_gt = gt[...,np.newaxis]\n",
    "    #Resize image\n",
    "    left_resized  = tf1.image.resize_images(left,  resize_shape)\n",
    "    right_resized = tf1.image.resize_images(right, resize_shape)\n",
    "    gt_resized =    tf1.image.resize_images(im_gt, resize_shape, method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "\n",
    "    \n",
    "    \n",
    "    left_, right_, gt_ = sess.run([left_resized, right_resized, gt_resized])\n",
    "\n",
    "    left_vol, right_vol = sess.run([n7_left, n7_right],feed_dict={ image_left : left_,\n",
    "                                                                   image_right: right_,\n",
    "                                                                   phase : False})\n",
    "    gt_ = np.transpose(gt_,[2,0,1])\n",
    "    \n",
    "    prod = inner_product_test(left_vol, right_vol, batch_size, img_h, img_w, num_classes)\n",
    "    \n",
    "    #out_disp = np.argmax(prod, 3)[0,:,:]\n",
    "    \n",
    "    out_disp = np.argmax(prod, 3)\n",
    "\n",
    "    err = error(out_disp, gt_,threshold=3)\n",
    "    print(err)\n",
    "   \n",
    "    \n",
    "    return prod, left_,right_,gt_\n",
    "\n",
    "def load_disp(path):\n",
    "    return np.round(ndimage.imread(path,flatten=True)/256.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cal_path = \"/media/sansii/Software/san_projects/Major_project\"\n",
    "mapx1, mapy1, mapx2, mapy2, roi1, roi2, Q = load_parameters(cal_path)\n",
    "frameL = ndimage.imread('/media/sansii/Software/san_projects/Major_project/Stereo_images/Left/0.jpg')\n",
    "frameR = ndimage.imread('/media/sansii/Software/san_projects/Major_project/Stereo_images/Right/0.jpg')\n",
    "img_rect1 = cv2.remap(frameL, mapx1, mapy1, cv2.INTER_LINEAR)\n",
    "img_rect2 = cv2.remap(frameR, mapx2, mapy2, cv2.INTER_LINEAR)\n",
    "\n",
    "#x1,y1,w1,h1 = roi1\n",
    "\n",
    "x2,y2,w2,h2 = roi2\n",
    "img_rect1 = img_rect1[y2:y2+h2, x2:x2+w2]\n",
    "img_rect2 = img_rect2[y2:y2+h2, x2:x2+w2]\n",
    "\n",
    "\n",
    "dim = (1280, 720)\n",
    "\n",
    "L_resized = cv2.resize(img_rect1, dim, interpolation = cv2.INTER_AREA)\n",
    "R_resized = cv2.resize(img_rect2, dim, interpolation = cv2.INTER_AREA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/sansii/.local/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1635: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From <ipython-input-2-c7181df26752>:13: batch_normalization (from tensorflow.python.layers.normalization) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.BatchNormalization instead.  In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.BatchNormalization` documentation).\n",
      "WARNING:tensorflow:From /home/sansii/.local/lib/python3.6/site-packages/tensorflow_core/python/layers/normalization.py:327: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "INFO:tensorflow:Restoring parameters from /media/sansii/Software/san_projects/Major_project/Final_checkpoints/model_250k.ckpt\n",
      "prod_left (1, 496, 720, 129)\n",
      "prod_left (1, 496, 720, 129)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# data_path = '/media/sansii/Software/san_projects/Major_project/KITTI_dataset/2015/training/'\n",
    "path_check= '/media/sansii/Software/san_projects/Major_project/Final_checkpoints/'\n",
    "left =  ndimage.imread(\"/home/sansii/Downloads/Compressed/MiddEval3-data-Q/MiddEval3/trainingQ/Adirondack/im0.png\")\n",
    "right = ndimage.imread(\"/home/sansii/Downloads/Compressed/MiddEval3-data-Q/MiddEval3/trainingQ/Adirondack/im1.png\") \n",
    "#gt = load_disp(\"/home/sansii/Downloads/Compressed/MiddEval3/trainingQ/Adirondack/disp0.png\")\n",
    "\n",
    "\n",
    "max_disp = 128\n",
    "batch_size = 1\n",
    "img_h = 496\n",
    "img_w = 720\n",
    "resize_shape = [img_h , img_w]\n",
    "num_classes = max_disp + 1\n",
    "left_shape =  [batch_size, img_h, img_w,  3]\n",
    "right_shape = [batch_size, img_h, img_w,  3]\n",
    "gt_shape = [batch_size,img_h,img_w]\n",
    "prod_left, prod_right, imgL, imgR = pred(processs_input_image(left), processs_input_image(right))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgL = np.array(cv2.cvtColor(imgL, cv2.COLOR_RGB2GRAY),dtype='uint32')\n",
    "imgR = np.array(cv2.cvtColor(imgR, cv2.COLOR_RGB2GRAY),dtype='uint32')\n",
    "\n",
    "cost_agg =CBCA(9, 15)\n",
    "matching_cost_left = cost_agg.find_cbca(imgL, prod_left[0])\n",
    "matching_cost_right = cost_agg.find_cbca(imgR, prod_right[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: TkAgg\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f7cd0090898>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disp_img_L = np.argmax(matching_cost_left,-1)\n",
    "disp_img_R = np.argmax(matching_cost_right,-1)\n",
    "%matplotlib\n",
    "plt.figure(0)\n",
    "plt.imshow(disp_img_L, cmap = 'jet')\n",
    "plt.figure(1)\n",
    "plt.imshow(disp_img_R, cmap = 'jet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def left_right_consistency(left_disp, right_disp):\n",
    "    matched_disparity = np.zeros_like(left_disp)\n",
    "    width = left_disp.shape[1]\n",
    "    height = left_disp.shape[0]\n",
    "    for y in range(height):\n",
    "        for x in range(width):\n",
    "            if x - left_disp[y,x] >= 0:\n",
    "                matched_disparity[y,x] = np.abs( left_disp[y,x] - right_disp[y, x - left_disp[y,x]] )\n",
    "            else:\n",
    "                matched_disparity[y,x] = 10\n",
    "                \n",
    "                \n",
    "    bad_disparity = np.argwhere(matched_disparity>2)\n",
    "    mask_good_bad = (matched_disparity <= 2)\n",
    "    repaired_disparity = left_disp.copy()\n",
    "   \n",
    "\n",
    "    for loc in bad_disparity:\n",
    "        sel_disp_right = None\n",
    "        sel_disp_left = None\n",
    "        val = 1\n",
    "        #searching in right for non_occluded pixels\n",
    "        while True:\n",
    "            x_pos = loc[1] + val\n",
    "            if (x_pos < width):\n",
    "                if mask_good_bad[loc[0], x_pos]:\n",
    "                    sel_disp_right = x_pos\n",
    "                    break;\n",
    "                else:\n",
    "                    val = val + 1\n",
    "                    \n",
    "            else:\n",
    "                break;\n",
    "                \n",
    "        #searching in left for non_occluded pixels \n",
    "        val = 1\n",
    "        while True:\n",
    "            x_pos = loc[1] - val\n",
    "            if (x_pos > 0): \n",
    "                if mask_good_bad[loc[0], x_pos]:\n",
    "                    sel_disp_left =  x_pos\n",
    "                    break;\n",
    "                else:\n",
    "                    val = val + 1\n",
    "                    \n",
    "            else:\n",
    "                break;\n",
    "                \n",
    "        \n",
    "        if sel_disp_left == None and sel_disp_right == None:\n",
    "            pass\n",
    "        \n",
    "        elif sel_disp_right == None:\n",
    "            repaired_disparity[loc[0] , loc[1]] = left_disp[loc[0], sel_disp_left]\n",
    "            \n",
    "        elif sel_disp_left == None:\n",
    "            repaired_disparity[loc[0] , loc[1]] = left_disp[loc[0], sel_disp_right]\n",
    "\n",
    "        else:\n",
    "            repaired_disparity[loc[0] , loc[1]] = np.minimum(left_disp[loc[0], sel_disp_right], \n",
    "                                                         left_disp[loc[0], sel_disp_left])\n",
    "                \n",
    "            \n",
    "    return repaired_disparity\n",
    "\n",
    "\n",
    "    \n",
    "        \n",
    "# imgL = np.array([[0, 2, 20, 50, 3,  5, 3, 20],\n",
    "#                     [21, 22, 0,  50,  50,  50, 51,  4],\n",
    "#                     [23,  0, 50, 51, 100, 100,  0,  6],\n",
    "#                     [0,  55, 55, 2,  60, 4, 100, 100],\n",
    "#                     [50, 50, 50, 1,  50,  50, 50,  50]])\n",
    "    \n",
    "# imgR = np.array([[5,0, 2, 3, 3, 200,  20, 20 ],\n",
    "#                 [10,21, 22, 4,  50,  50,  50, 51  ],\n",
    "#                 [20,6,  0, 50, 51, 100, 100,  0  ],\n",
    "#                 [20,2, 0,  55, 55, 50,  60, 200,  ],\n",
    "#                 [55,40, 1, 50, 50, 50,  50,  50, ]])\n",
    "\n",
    "\n",
    "# repaired_disparity, mask_good_bad = left_right_consistency(imgL, imgR)\n",
    "# print(repaired_disparity)\n",
    "# print(mask_good_bad)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "repaired_disparity = left_right_consistency(disp_img_L, disp_img_R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(496, 720)\n",
      "(496, 720)\n",
      "int64\n"
     ]
    }
   ],
   "source": [
    "filtred_repaired_disparity = cv2.medianBlur(np.array(repaired_disparity, dtype='uint8'), 5 )\n",
    "bilateral_filtred  = cv2.bilateralFilter(filtred_repaired_disparity, 10, 75, 75)\n",
    "guided_image = cv2.cvtColor(cv2.resize(left,(img_w, img_h)), cv2.COLOR_RGB2GRAY)\n",
    "print(guided_image.shape)\n",
    "print(filtred_repaired_disparity.shape)\n",
    "fgsf = cv2.ximgproc.fastGlobalSmootherFilter(guided_image, filtred_repaired_disparity, 400, 10)\n",
    "print(repaired_disparity.dtype)\n",
    "plt.figure(0)\n",
    "plt.title(\"Left_right\")\n",
    "plt.imshow(repaired_disparity, cmap = 'jet')\n",
    "plt.figure(1)\n",
    "plt.title(\"Median_filter\")\n",
    "plt.imshow(filtred_repaired_disparity, cmap='jet')\n",
    "plt.figure(2)\n",
    "plt.title(\"Left_CBCA\")\n",
    "plt.imshow(disp_img_L, cmap = 'jet')\n",
    "plt.figure(3)\n",
    "plt.title(\"Right_CBCA\")\n",
    "plt.imshow(disp_img_R, cmap = 'jet')\n",
    "\n",
    "plt.figure(4)\n",
    "plt.title(\"Bilateral_filtered\")\n",
    "plt.imshow(bilateral_filtred, cmap = 'jet')\n",
    "plt.figure(5)\n",
    "plt.title(\"FGSF\")\n",
    "plt.imshow(fgsf, cmap = 'jet')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lmbda = 80000\n",
    "sigma = 1.2\n",
    "window_size = 5              # wsize default 3; 5; 7 for SGBM reduced size image; 15 for SGBM full size image (1300px and above); 5 Works nicely\n",
    "minDisparity= 0\n",
    "numDisparities= 128 - minDisparity\n",
    "left_matcher = cv2.StereoSGBM_create(\n",
    "    minDisparity=minDisparity,\n",
    "    numDisparities=numDisparities,             # max_disp has to be dividable by 16 f. E. HH 192, 256\n",
    "    blockSize=5,\n",
    "    P1=8 * 3 * window_size ** 2,    # wsize default 3; 5; 7 for SGBM reduced size image; 15 for SGBM full size image (1300px and above); 5 Works nicely\n",
    "    P2=32 * 3 * window_size ** 2,\n",
    "    disp12MaxDiff=1,\n",
    "    uniquenessRatio=15,\n",
    "    speckleWindowSize=0,\n",
    "    speckleRange=2,\n",
    "    preFilterCap=63,\n",
    "    mode=cv2.STEREO_SGBM_MODE_HH\n",
    ")\n",
    "\n",
    "wls_filter = cv2.ximgproc.createDisparityWLSFilter(matcher_left=left_matcher)\n",
    "wls_filter.setLambda(lmbda)\n",
    "wls_filter.setSigmaColor(sigma)\n",
    "filteredImg = wls_filter.filter(disp_img_L, cv2.cvtColor(esized,cv2.COLOR_RGB2GRAY), None, disp_img_R)  # important to put \"imgL\" here!!!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib\n",
    "\n",
    "plt.figure(0)\n",
    "plt.imshow(filteredImg, cmap = 'jet')\n",
    "plt.figure(1)\n",
    "plt.imshow(disp_l, cmap = 'jet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgL = np.array(cv2.cvtColor(imgL[0], cv2.COLOR_RGB2GRAY),dtype='uint32')\n",
    "# imgR = np.array(cv2.cvtColor(imgR[0], cv2.COLOR_RGB2GRAY),dtype='uint32')\n",
    "if __name__ == '__main__':\n",
    "    cost_agg =CBCA(7, 10)\n",
    "    matching_cost = cost_agg.find_cbca(imgL, prod[0])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out =np.argmax(matching_cost, -1)\n",
    "err = error(out, gt[0],threshold=3)\n",
    "print(err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib\n",
    "\n",
    "out = cv2.normalize(src=out, dst=None, beta=0, alpha=255, norm_type=cv2.NORM_MINMAX);\n",
    "out = np.uint8(out)\n",
    "plt.figure(0)\n",
    "plt.imshow(out,cmap='jet')\n",
    "plt.figure(1)\n",
    "plt.imshow(np.argmax(prod[0], -1),cmap='jet')\n",
    "# plt.figure(2)\n",
    "# plt.imshow(gt[0],cmap='jet')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "disp = cv2.imread('disp.png',0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib\n",
    "plt.imshow(np.argmax(matching_cost,-1), cmap ='jet')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = Paths()\n",
    "parameters = Parameters(max_disparity=128, P1=10, P2=120, csize=(7, 7), bsize=(3, 3))\n",
    "# left, right = load_images(data_path+\"image_2/000010_10.png\", data_path+\"image_3/000010_10.png\", parameters)\n",
    "# left_cost_volume, right_cost_volume = compute_costs(left, right, parameters, save_images=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod.shape\n",
    "del left_aggregation_volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_aggregation_volume = aggregate_costs(matching_cost, parameters, paths)\n",
    "# left_disparity_map = np.uint8(normalize(select_disparity(left_aggregation_volume), parameters))\n",
    "# left_disparity_map = cv2.medianBlur(left_disparity_map, parameters.bsize[0])\n",
    "# %matplotlib\n",
    "# plt.figure(0)\n",
    "# plt.imshow(left_disparity_map,cmap='jet')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib\n",
    "plt.figure(0)\n",
    "volume = np.sum(left_aggregation_volume, axis=3)\n",
    "plt.imshow(np.argmax(volume, -1),cmap='jet')\n",
    "plt.figure(1)\n",
    "plt.imshow(np.argmax(prod,-1)[0],cmap='jet')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib\n",
    "plt.figure(1)\n",
    "plt.imshow(np.argmin(left_cost_volume,-1),cmap='jet')\n",
    "plt.figure(2)\n",
    "plt.imshow(left_disparity_map,cmap='jet')\n",
    "plt.figure(0)\n",
    "plt.imshow(np.argmax(prod,-1)[0],cmap='jet')\n",
    "plt.show()\n",
    "print(prod.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def disparity(imgL, imgR):\n",
    "    # SGBM Parameters -----------------\n",
    "    \n",
    "    imgL = np.uint8(imgL)\n",
    "    imgR = np.uint8(imgR)\n",
    "    window_size = 3                     # wsize default 3; 5; 7 for SGBM reduced size image; 15 for SGBM full size image (1300px and above); 5 Works nicely\n",
    "    minDisparity= 11\n",
    "    numDisparities= 171 - minDisparity\n",
    "    left_matcher = cv2.StereoSGBM_create(\n",
    "        minDisparity=minDisparity,\n",
    "        numDisparities=numDisparities,             # max_disp has to be dividable by 16 f. E. HH 192, 256\n",
    "        blockSize=5,\n",
    "        P1=8 * 3 * window_size ** 2,    # wsize default 3; 5; 7 for SGBM reduced size image; 15 for SGBM full size image (1300px and above); 5 Works nicely\n",
    "        P2=32 * 3 * window_size ** 2,\n",
    "        disp12MaxDiff=1,\n",
    "        uniquenessRatio=15,\n",
    "        speckleWindowSize=0,\n",
    "        speckleRange=2,\n",
    "        preFilterCap=63,\n",
    "        mode=cv2.STEREO_SGBM_MODE_HH\n",
    "    )\n",
    "\n",
    "    right_matcher = cv2.ximgproc.createRightMatcher(left_matcher)\n",
    "\n",
    "    # FILTER Parameters\n",
    "    lmbda = 80000\n",
    "    sigma = 1.2\n",
    "    visual_multiplier = 1.0\n",
    "\n",
    "    wls_filter = cv2.ximgproc.createDisparityWLSFilter(matcher_left=left_matcher)\n",
    "    wls_filter.setLambda(lmbda)\n",
    "    wls_filter.setSigmaColor(sigma)\n",
    "\n",
    "    displ = left_matcher.compute(imgR, imgL).astype(np.float32)/16\n",
    "    dispr = right_matcher.compute(imgR, imgL).astype(np.float32)/16\n",
    "    displ = np.int16(displ)\n",
    "    dispr = np.int16(dispr)\n",
    "    filteredImg = wls_filter.filter(displ, cv2.cvtColor(imgL,cv2.COLOR_RGB2GRAY), None, dispr)  # important to put \"imgL\" here!!!\n",
    "    #filteredImg = cv2.normalize(src=filteredImg, dst=filteredImg, beta=0, alpha=255, norm_type=cv2.NORM_MINMAX);\n",
    "    #filteredImg = np.uint8(filteredImg)\n",
    "   \n",
    "    return filteredImg, displ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dis = disparity(left, right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib\n",
    "plt.figure(0)\n",
    "plt.imshow(output_dis[0], cmap = 'jet')\n",
    "plt.figure(1)\n",
    "plt.imshow(output_dis[1],cmap='jet')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_parameters(path):\n",
    "    with h5py.File(path+\"/Calibration/stereo_mapping.h5py\",\"r\") as hdf:\n",
    "        mapx1 = np.array(hdf[\"stereo_mapping/mapx1\"])\n",
    "        mapy1 = np.array(hdf[\"stereo_mapping/mapy1\"])\n",
    "        mapx2 = np.array(hdf[\"stereo_mapping/mapx2\"])\n",
    "        mapy2 = np.array(hdf[\"stereo_mapping/mapy2\"])\n",
    "        roi1 = np.array(hdf[\"stereo_mapping/roi1\"])\n",
    "        roi2 = np.array(hdf[\"stereo_mapping/roi2\"])\n",
    "        \n",
    "    with h5py.File(cal_path+\"/Calibration/Stereo_rectify.h5py\",\"r\") as hdf:\n",
    "        Q = np.array(hdf[\"Stereo_rectify/Q\"])\n",
    "        \n",
    "    return (mapx1, mapy1, mapx2, mapy2, roi1, roi2, Q)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 3                     # wsize default 3; 5; 7 for SGBM reduced size image; 15 for SGBM full size image (1300px and above); 5 Works nicely\n",
    "minDisparity= 11\n",
    "numDisparities= 171 - minDisparity\n",
    "left_matcher = cv2.StereoSGBM_create(\n",
    "    minDisparity=minDisparity,\n",
    "    numDisparities=numDisparities,             # max_disp has to be dividable by 16 f. E. HH 192, 256\n",
    "    blockSize=5,\n",
    "    P1=8 * 3 * window_size ** 2,    # wsize default 3; 5; 7 for SGBM reduced size image; 15 for SGBM full size image (1300px and above); 5 Works nicely\n",
    "    P2=32 * 3 * window_size ** 2,\n",
    "    disp12MaxDiff=1,\n",
    "    uniquenessRatio=15,\n",
    "    speckleWindowSize=0,\n",
    "    speckleRange=2,\n",
    "    preFilterCap=63,\n",
    "    mode=cv2.STEREO_SGBM_MODE_HH\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.random.randint(0,10,(5,5,3))\n",
    "b = np.random.randint(0,20,(5,5,3))\n",
    "c= np.random.randint(0,30,(5,5,3))\n",
    "d= np.random.randint(0,40,(5,5,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack = np.stack((a,b,c,d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(stack.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(a[:,:,0], stack[0][:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.random.randint(0,10,size = (5,2))\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (a != [0,10]).all():\n",
    "    print(\"not_equal_to_any\")\n",
    "else:\n",
    "    print(\"It is equal to\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = [i==[0,0] for i in a.tolist()]\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print((a==True).any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
