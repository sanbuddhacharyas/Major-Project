{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.compat.v1 as tf1\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import ndimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d(input_images, weight):\n",
    "    return tf.nn.conv2d(input_images, weight ,strides=[1,1,1,1], padding='SAME',name=\"conv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_pool(x):\n",
    "    return tf.nn.max_pool(x,[1,2,2,1],[1,2,2,1], padding='VALID',name='maxpool')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_bn_relu(input_layer, bias_shape, kernel_shape,scope ,reuse =False ):\n",
    "    with tf.compat.v1.variable_scope(scope, reuse = reuse):\n",
    "        W = tf.compat.v1.get_variable(\"weight\", kernel_shape, initializer=tf1.glorot_uniform_initializer())\n",
    "        b = tf.compat.v1.get_variable(\"biases\", bias_shape ,initializer=tf1.glorot_uniform_initializer())\n",
    "        conv = conv2d(input_layer, W)\n",
    "        output = tf.nn.bias_add(conv, b)\n",
    "        normal = tf.compat.v1.layers.batch_normalization(output)\n",
    "        out = tf.nn.relu(normal)\n",
    "    return out\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv(input_layer, bias_shape, kernel_shape,scope, reuse=False):\n",
    "    with tf.compat.v1.variable_scope(scope,reuse = reuse):\n",
    "        W = tf.compat.v1.get_variable(\"weight\", kernel_shape, initializer=tf1.glorot_uniform_initializer())\n",
    "        b = tf.compat.v1.get_variable(\"biases\", bias_shape ,initializer=tf1.glorot_uniform_initializer())\n",
    "        conv = conv2d(input_layer, W)\n",
    "        out = tf.nn.bias_add(conv, b)\n",
    "        \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deconv(input_layer, bias_shape, kernel_shape, output_shape, scope ,reuse =False):\n",
    "    with tf.compat.v1.variable_scope(scope, reuse = reuse):\n",
    "        W = tf.compat.v1.get_variable(\"weight\", kernel_shape, initializer=tf1.glorot_uniform_initializer())\n",
    "        b = tf.compat.v1.get_variable(\"bias\", bias_shape, initializer=tf1.glorot_uniform_initializer())\n",
    "        deconv = tf.nn.conv2d_transpose(input_layer, W, output_shape, strides = [1,2,2,1])\n",
    "        out = tf.nn.bias_add(deconv, b)\n",
    "        \n",
    "        return out\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inner_product(left, right, disp, width):\n",
    "    disp_vol = []\n",
    "    for i in range(disp):\n",
    "        output = tf.reduce_sum(tf.multiply(left, right[:,:,disp-i-1:disp -1 -i + width,: ]),axis =3)\n",
    "        disp_vol.append(output)\n",
    "        logits = tf.transpose(tf.stack(disp_vol),[1,2,3,0])\n",
    "        \n",
    "    return logits\n",
    "\n",
    "def compute_loss(y_truth, y_pre):\n",
    "\n",
    "    num_classes = 129\n",
    "    valid_pixels = tf.not_equal(y_truth, 0)\n",
    "    labels = tf.reshape(tf.boolean_mask(y_truth, valid_pixels),[-1])\n",
    "    logits = tf.reshape(tf.boolean_mask(y_pre, valid_pixels),[-1, 129])\n",
    "    loss = tf.nn.sparse_softmax_cross_entropy_with_logits(labels, logits)\n",
    "    cross_entropy = tf.reduce_mean(loss)\n",
    "  \n",
    "    return cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def network_4(input_image, n_channels, n_filters, batch_size, H,W, reuse=False):\n",
    "    n1 = conv_bn_relu(input_image,bias_shape=[n_filters], kernel_shape=[3,3,n_channels,n_filters],scope ='conv1',reuse = reuse )\n",
    "    n2 = conv_bn_relu(n1, bias_shape=[n_filters], kernel_shape=[3, 3, n_filters, n_filters],scope = 'conv2',reuse=reuse )\n",
    "    n2 = max_pool(n2)\n",
    "    n3 = conv_bn_relu(n2, [n_filters], kernel_shape=[3,3,n_filters,n_filters],scope ='conv3',reuse=reuse)\n",
    "    n4 = conv(n3,[n_filters],[3,3,n_filters,n_filters],'conv4',reuse= reuse)\n",
    "    n5 = deconv(n4, [n_filters], [3, 3, n_filters, n_filters],[batch_size , H, W, n_filters],'deconv1',reuse = reuse)\n",
    "    \n",
    "    return n5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def network_7(input_image, n_channels, n_filters, batch_size, H,W, reuse=False):\n",
    "    \n",
    "    n1 = conv_bn_relu(input_image, bias_shape=[n_filters], kernel_shape=[3, 3, n_channels,n_filters],scope ='conv1',reuse = reuse )\n",
    "    n2 = conv_bn_relu(n1, [n_filters], kernel_shape = [3, 3, n_filters, n_filters], scope = 'conv2', reuse=reuse )\n",
    "    \n",
    "    n2 = max_pool(n2)\n",
    "    \n",
    "    n3 = conv_bn_relu(n2, [n_filters], kernel_shape = [3, 3, n_filters, n_filters], scope = 'conv3', reuse=reuse)\n",
    "    n4 = conv_bn_relu(n3, [n_filters], kernel_shape = [3, 3, n_filters, n_filters], scope = 'conv4', reuse=reuse)\n",
    "    \n",
    "    n4 = max_pool(n4)\n",
    "    \n",
    "    n5 = conv_bn_relu(n4, [n_filters], kernel_shape = [3, 3, n_filters, n_filters], scope = 'conv5', reuse=reuse)\n",
    "    n6 = conv_bn_relu(n5, [n_filters], kernel_shape = [3, 3, n_filters, n_filters], scope = 'conv6', reuse=reuse)\n",
    "    \n",
    "    n7 = conv(n6,[n_filters],[3,3,n_filters,n_filters],'conv7',reuse= reuse)\n",
    "    \n",
    "    n8 = deconv(n7, [n_filters], [3, 3, n_filters, n_filters],[batch_size , int(H /2), int(W /2), n_filters],'deconv1',reuse = reuse)\n",
    "    n9 = deconv(n8, [n_filters], [3, 3, n_filters, n_filters],[batch_size , H, W, n_filters],'deconv2',reuse = reuse)\n",
    "    \n",
    "    return n9\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_disp = 128\n",
    "rec_field = 28\n",
    "patch_right = rec_field + max_disp\n",
    "batch_size = 8\n",
    "num_classes = max_disp + 1\n",
    "left_shape = [batch_size, rec_field, rec_field, 3]\n",
    "right_shape = [batch_size, rec_field, patch_right,3]\n",
    "\n",
    "gt_shape = [batch_size, rec_field, rec_field]\n",
    "\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "image_left  = tf.compat.v1.placeholder(tf.float32, left_shape,  name='image_left' )\n",
    "image_right = tf.compat.v1.placeholder(tf.float32, right_shape, name='image_right')\n",
    "im_gt = tf.compat.v1.placeholder(tf.int32, gt_shape, name='groud_truth')\n",
    "\n",
    "with tf.compat.v1.name_scope(\"stereo_matching\") as scope:\n",
    "    left_network =  network_7(image_left,  3, 64, batch_size, rec_field, rec_field)\n",
    "    right_network = network_7(image_right, 3, 64, batch_size, rec_field, patch_right,reuse=True)\n",
    "    output = inner_product(left_network, right_network, num_classes, rec_field)\n",
    "writer = tf1.summary.FileWriter('./graphs',graph=tf1.get_default_graph())\n",
    "loss = compute_loss(im_gt,output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_step = tf.Variable(0, trainable=False)\n",
    "starter_learning_rate = 0.1\n",
    "learning_rate = tf.compat.v1.train.exponential_decay(starter_learning_rate,\n",
    "                                                     global_step, 100000, 0.96, staircase=True)\n",
    "train_network = tf.compat.v1.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss,global_step=global_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/media/sansii/Software/san_projects/Major_project/KITTI_dataset/numpy'\n",
    "epoch = 1000\n",
    "left = np.load(path+'/image_left_2.npy')\n",
    "left = left.astype('float32')\n",
    "right = np.load(path+'/image_right_2.npy')\n",
    "right = right.astype('float32')\n",
    "gt = np.load(path+'/im_gt_2.npy')\n",
    "variable_init = tf1.global_variables_initializer()\n",
    "with tf1.Session() as sess:\n",
    "    sess.run(variable_init)\n",
    "    for i in range(epoch):\n",
    "        for j in range(int(left.shape[0] / batch_size)):\n",
    "            a = j * batch_size\n",
    "            b = a + batch_size\n",
    "            _, L = sess.run([train_network, loss],feed_dict = {image_left: left[a:b,:,:,:],\n",
    "                                                                  image_right: right[a:b,:,:,:],\n",
    "                                                                  im_gt: gt[a:b,:,:]})\n",
    "            if j%20 == 0 :\n",
    "                print('\\r',\"Epoch:\",str(i),\" Step:\",str(j),\" Loss:\",'{:.5}'.format(str(L)),end='')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.random.randint(0,20,size=(8,28,28))\n",
    "b = np.random.randint(0,20,size=(8,28,28))\n",
    "\n",
    "def error(output,y_,threshold=5):\n",
    "    errors = np.abs(output-y_)\n",
    "    valid_pixels = errors[y_!=0]\n",
    "    n_err   = np.sum(valid_pixels > threshold)\n",
    "    n_total = len(valid_pixels)\n",
    "    return float(n_err)/float(n_total) , n_err, valid_pixels.shape\n",
    "    \n",
    "print(error(a,b))\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d(input_images, weight):\n",
    "    return tf.nn.conv2d(input_images, weight ,strides=[1,1,1,1], padding='SAME',name=\"conv\")\n",
    "\n",
    "def max_pool(x):\n",
    "    return tf.nn.max_pool(x,[1,2,2,1],[1,2,2,1], padding='VALID',name='maxpool')\n",
    "\n",
    "def conv_bn_relu(input_layer, bias_shape, kernel_shape, phase, scope ,reuse =False ):\n",
    "    with tf.compat.v1.variable_scope(scope, reuse = reuse):\n",
    "        W = tf.compat.v1.get_variable(\"weight\", kernel_shape, initializer=tf1.glorot_uniform_initializer())\n",
    "        b = tf.compat.v1.get_variable(\"biases\", bias_shape ,initializer=tf1.glorot_uniform_initializer())\n",
    "        conv = conv2d(input_layer, W)\n",
    "        output = tf.nn.bias_add(conv, b)\n",
    "        normal = tf.compat.v1.layers.batch_normalization(output, training = phase)\n",
    "        out = tf.nn.relu(normal)\n",
    "    return out\n",
    "\n",
    "def conv(input_layer, bias_shape, kernel_shape,scope, reuse=False):\n",
    "    with tf.compat.v1.variable_scope(scope,reuse = reuse):\n",
    "        W = tf.compat.v1.get_variable(\"weight\", kernel_shape, initializer=tf1.glorot_uniform_initializer())\n",
    "        b = tf.compat.v1.get_variable(\"biases\", bias_shape ,initializer=tf1.glorot_uniform_initializer())\n",
    "        conv = conv2d(input_layer, W)\n",
    "        out = tf.nn.bias_add(conv, b)\n",
    "        \n",
    "    return out\n",
    "\n",
    "def deconv(input_layer, bias_shape, kernel_shape, output_shape, scope ,reuse =False):\n",
    "    with tf.compat.v1.variable_scope(scope, reuse = reuse):\n",
    "        W = tf.compat.v1.get_variable(\"weight\", kernel_shape, initializer=tf1.glorot_uniform_initializer())\n",
    "        b = tf.compat.v1.get_variable(\"bias\", bias_shape, initializer=tf1.glorot_uniform_initializer())\n",
    "        deconv = tf.nn.conv2d_transpose(input_layer, W, output_shape, strides = [1,2,2,1])\n",
    "        out = tf.nn.bias_add(deconv, b)\n",
    "        \n",
    "        return out\n",
    "def inner_product(left, right, disp, width):\n",
    "    disp_vol = []\n",
    "    for i in range(disp):\n",
    "        output = tf.reduce_sum(tf.multiply(left, right[:,:,disp-i-1:disp -1 -i + width,: ]),axis =3)\n",
    "        disp_vol.append(output)\n",
    "        logits = tf.transpose(tf.stack(disp_vol),[1,2,3,0])\n",
    "        \n",
    "    return logits\n",
    "\n",
    "def compute_loss(y_truth, y_pre):\n",
    "\n",
    "    num_classes = 129\n",
    "    valid_pixels = tf.not_equal(y_truth, 0)\n",
    "    labels = tf.reshape(tf.boolean_mask(y_truth, valid_pixels),[-1])\n",
    "    logits = tf.reshape(tf.boolean_mask(y_pre, valid_pixels),[-1, 129])\n",
    "    loss = tf.nn.sparse_softmax_cross_entropy_with_logits(labels, logits)\n",
    "    cross_entropy = tf.reduce_mean(loss)\n",
    "  \n",
    "    return cross_entropy\n",
    "def network_4(input_image, n_channels, n_filters, batch_size, H,W, phase , reuse=False):\n",
    "    n1 = conv_bn_relu(input_image,bias_shape=[n_filters], kernel_shape=[3,3,n_channels,n_filters], phase = phase, scope ='conv1',reuse = reuse )\n",
    "    n2 = conv_bn_relu(n1, bias_shape=[n_filters], kernel_shape=[3, 3, n_filters, n_filters], phase = phase, scope = 'conv2',reuse=reuse )\n",
    "    n2 = max_pool(n2)\n",
    "    n3 = conv_bn_relu(n2, [n_filters], kernel_shape=[3,3,n_filters,n_filters], phase = phase, scope ='conv3',reuse=reuse)\n",
    "    n4 = conv(n3,[n_filters],[3,3,n_filters,n_filters],'conv4',reuse= reuse)\n",
    "    n5 = deconv(n4, [n_filters], [3, 3, n_filters, n_filters],[batch_size , H, W, n_filters],'deconv1',reuse = reuse)\n",
    "    \n",
    "    return n5\n",
    "\n",
    "def accuracy_calculate(Y_truth, Y_pre):\n",
    "    compare = tf.equal(Y_truth, tf.cast(tf.argmax(Y_pre,-1), tf.int32))\n",
    "    accuracy = tf.reduce_mean(tf.cast(compare,\"float\")) \n",
    "    return accuracy\n",
    "\n",
    "def error(output,y_,threshold=5):\n",
    "    errors = np.abs(output-y_)\n",
    "    valid_pixels = errors[y_!=0]\n",
    "    n_err   = np.sum(valid_pixels > threshold)\n",
    "    n_total = len(valid_pixels)\n",
    "    return float(n_err)/float(n_total)\n",
    "\n",
    "def network_7(input_image, n_channels, n_filters, batch_size, H, W, phase, reuse=False):\n",
    "    \n",
    "    n1 = conv_bn_relu(input_image, [n_filters], kernel_shape=[3, 3, n_channels,n_filters], phase = phase, scope ='conv1',reuse = reuse )\n",
    "    n2 = conv_bn_relu(n1, [n_filters], kernel_shape = [3, 3, n_filters, n_filters], phase = phase,  scope = 'conv2', reuse=reuse )\n",
    "    \n",
    "    n2 = max_pool(n2)\n",
    "    \n",
    "    n3 = conv_bn_relu(n2, [n_filters], kernel_shape = [3, 3, n_filters, n_filters], phase = phase, scope = 'conv3', reuse=reuse)\n",
    "    n4 = conv_bn_relu(n3, [n_filters], kernel_shape = [3, 3, n_filters, n_filters], phase = phase, scope = 'conv4', reuse=reuse)\n",
    "    \n",
    "    n4 = max_pool(n4)\n",
    "    \n",
    "    n5 = conv_bn_relu(n4, [n_filters], kernel_shape = [3, 3, n_filters, n_filters], phase = phase, scope = 'conv5', reuse=reuse)\n",
    "    n6 = conv_bn_relu(n5, [n_filters], kernel_shape = [3, 3, n_filters, n_filters], phase = phase, scope = 'conv6', reuse=reuse)\n",
    "    \n",
    "    n7 = conv(n6,[n_filters],[3,3,n_filters,n_filters],'conv7',reuse= reuse)\n",
    "    \n",
    "    n8 = deconv(n7, [n_filters], [3, 3, n_filters, n_filters],[batch_size , int(H /2), int(W /2), n_filters],'deconv1',reuse = reuse)\n",
    "    n9 = deconv(n8, [n_filters], [3, 3, n_filters, n_filters],[batch_size , H, W, n_filters],'deconv2',reuse = reuse)\n",
    "    \n",
    "    return n9\n",
    "    \n",
    "def init_placeholder():\n",
    "    tf1.disable_eager_execution()\n",
    "    tf1.reset_default_graph()\n",
    "    phase = tf1.placeholder(tf1.bool)\n",
    "    with tf1.name_scope(\"Im_left\"):\n",
    "        image_left  = tf.compat.v1.placeholder(tf.float32, left_shape,  name='image_left' )\n",
    "    with tf1.name_scope(\"Im_right\"):\n",
    "        image_right = tf.compat.v1.placeholder(tf.float32, right_shape, name='image_right')\n",
    "    with tf1.name_scope(\"Im_gt\"):\n",
    "        im_gt = tf.compat.v1.placeholder(tf.int32, gt_shape, name='groud_truth')\n",
    "\n",
    "    return phase, image_left, image_right, im_gt\n",
    "\n",
    "\n",
    "def make_architecture(phase, image_left, image_right, im_gt):\n",
    " \n",
    "    with tf.compat.v1.name_scope(\"stereo_matching\") as scope:\n",
    "        left_network =  network_7(image_left,  3, 64,batch_size, rec_field, rec_field, phase = phase)\n",
    "        right_network = network_7(image_right, 3, 64,batch_size, rec_field, patch_right,phase=phase, reuse=True)\n",
    "\n",
    "    with tf1.name_scope(\"Model\"):\n",
    "        output = inner_product(left_network, right_network, num_classes, rec_field)\n",
    "\n",
    "\n",
    "    with tf1.name_scope(\"Loss\"):\n",
    "        loss = compute_loss(im_gt,output)\n",
    "\n",
    "\n",
    "    global_step = tf.Variable(0, trainable=False)\n",
    "    starter_learning_rate = 0.00001\n",
    "    learning_rate = tf.compat.v1.train.exponential_decay(starter_learning_rate,\n",
    "                                                      global_step, 4000, 0.96, staircase=True)\n",
    "    update_ops = tf1.get_collection(tf1.GraphKeys.UPDATE_OPS)\n",
    "    with tf1.control_dependencies(update_ops):\n",
    "        train_network = tf.compat.v1.train.AdamOptimizer(learning_rate = learning_rate).minimize(loss,global_step=global_step)\n",
    "\n",
    "    return loss, output, train_network\n",
    "\n",
    "\n",
    "def inner_product_test(h9_left, h9_right,batch_size,rows, cols, n_classes):\n",
    "    prod=np.ones((batch_size,rows,cols,n_classes))*(-1e9)\n",
    "    start=0\n",
    "    end = cols\n",
    "\n",
    "    while start<cols-1:\n",
    "        for disp in range(n_classes):\n",
    "            if (end-disp  > 0):\n",
    "                if (cols > start-disp ):\n",
    "\n",
    "                    left_features = h9_left[:,:,max(start,disp):min(end,cols),:]\n",
    "                    right_features = h9_right[:,:,max(0,start-disp ):min(end-disp ,cols-disp),:]\n",
    "                    \n",
    "                    multiplication = np.multiply(left_features,right_features)\n",
    "                    inner_product = np.sum(multiplication,axis=3)\n",
    "                    prod[:,:,max(start,disp):min(end,cols),disp]=inner_product\n",
    "        \n",
    "        start = end\n",
    "        end += cols\n",
    "\n",
    "    return prod\n",
    "\n",
    "\n",
    "def processs_input_image(image):\n",
    "    image=np.array(image,dtype=np.float32)\n",
    "    image=(image-np.mean(image))/np.std(image)\n",
    "    return image\n",
    "  \n",
    "def train(left_images,right_images,disp_images):\n",
    "\n",
    "    phase, image_left, image_right, im_gt = init_placeholder()\n",
    "    loss, output, train_network = make_architecture(phase, image_left, image_right, im_gt)\n",
    "    log_dir = '/content/drive/My Drive/Colab Notebooks/log_dirs'\n",
    "    saver = tf1.train.Saver()\n",
    "    tf1.summary.scalar(\"Loss\", loss)\n",
    "    merged_summary_op = tf1.summary.merge_all() \n",
    "    writer = tf1.summary.FileWriter('./graphs',graph=tf1.get_default_graph())\n",
    "\n",
    "    variable_init = tf1.global_variables_initializer()\n",
    "    with tf1.Session() as sess:\n",
    "      #sess.run(variable_init)\n",
    "        saver.restore(sess, path_check_1+\"/model_1.ckpt\")\n",
    "        for i in range(epoch):\n",
    "            left, right, gt=load_random_patch(left_images,right_images,disp_images,rec_field,right_left,max_disp,batch_size,valid_pixels_train)\n",
    "\n",
    "            left = left.astype('float32') / 255\n",
    "            right = right.astype('float32') / 255\n",
    "            _, summ = sess.run([train_network, merged_summary_op],feed_dict = {image_left: left ,\n",
    "                                                                  image_right: right,\n",
    "                                                                  im_gt: gt,\n",
    "                                                                  phase : True})\n",
    "            writer.add_summary(summ, i)\n",
    "\n",
    "            if i%50 == 0 :\n",
    "\n",
    "                L_train, out_train = sess.run([loss, output], feed_dict={image_left: left,\n",
    "                                                            image_right: right,\n",
    "                                                            im_gt: gt, \n",
    "                                                            phase : False})\n",
    "                err_train = error(np.argmax(out_train,-1), gt)\n",
    "\n",
    "\n",
    "\n",
    "                print('\\r',\"Epoch:\",str(i),\" Loss:\",'{:.5}'.format(str(L_train)), \"Error:\",'{:.5}'.format(str(err_train)), end='')\n",
    "\n",
    "\n",
    "            if i % 500 == 0:\n",
    "                saver.save(sess, path_check_2+\"/model_2.ckpt\")\n",
    "\n",
    "def test(im_left, im_right):\n",
    "  \n",
    "    \n",
    "    tf1.disable_eager_execution()\n",
    "    phase, image_left, image_right, im_gt = init_placeholder()\n",
    "    with tf.compat.v1.name_scope(\"stereo_matching\") as scope:\n",
    "        n9_left =  network_7(image_left,  3, 64, batch_size, img_h, img_w, phase = phase)\n",
    "        n9_right = network_7(image_right, 3, 64, batch_size, img_h, img_w, phase = phase, reuse=True)\n",
    "    \n",
    "    \n",
    "    sess = tf1.Session()\n",
    "    saver = tf1.train.Saver()\n",
    "    saver.restore(sess, path_check_1+'model_1.ckpt')\n",
    "\n",
    "    #Adding axis to image\n",
    "    left =  im_left [np.newaxis,...].astype('float') / 255\n",
    "    right = im_right[np.newaxis,...].astype('float') / 255\n",
    "    \n",
    "    #Resize image\n",
    "    left_resized  = tf1.image.resize_images(left,  resize_shape)\n",
    "    right_resized = tf1.image.resize_images(right, resize_shape)\n",
    "\n",
    "\n",
    "    \n",
    "    left_, right_ = sess.run([left_resized, right_resized])\n",
    "\n",
    "    left_vol, right_vol = sess.run([n9_left, n9_right],feed_dict={ image_left : left_,\n",
    "                                                                   image_right: right_,\n",
    "                                                                   phase : False})\n",
    "    \n",
    "    prod = inner_product_test(left_vol, right_vol, batch_size, img_h, img_w, num_classes)\n",
    "    \n",
    "    #out_disp = np.argmax(prod, 3)[0,:,:]\n",
    "    \n",
    "    return prod\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /media/sansii/Software/san_projects/Major_project/Checkpoints_1/model_1.ckpt\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data_path = '/media/sansii/Software/san_projects/Major_project/KITTI_dataset/2015/training/'\n",
    "path_check_1 = '/media/sansii/Software/san_projects/Major_project/Checkpoints_1/'\n",
    "left =  ndimage.imread(data_path+\"image_2/000008_10.png\")\n",
    "right = ndimage.imread(data_path+\"image_3/000008_10.png\") \n",
    "gt = ndimage.imread(data_path+\"disp_noc_0/000005_10.png\") \n",
    "max_disp = 128\n",
    "batch_size = 1\n",
    "img_h = 376\n",
    "img_w = 1240\n",
    "resize_shape = [img_h , img_w]\n",
    "num_classes = max_disp + 1\n",
    "left_shape =  [batch_size, img_h, img_w,  3]\n",
    "right_shape = [batch_size, img_h, img_w,  3]\n",
    "gt_shape =    [batch_size, img_h, img_w]\n",
    "\n",
    "out = test(left, right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: TkAgg\n"
     ]
    }
   ],
   "source": [
    "%matplotlib\n",
    "plt.figure(0)\n",
    "plt.imshow(out,cmap='jet')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
