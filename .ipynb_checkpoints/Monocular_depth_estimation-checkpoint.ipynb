{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.compat.v1 as tf1\n",
    "from scipy import ndimage\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d(input_images, weight, stride = 1):\n",
    "    return tf.nn.conv2d(input_images, weight ,strides=[1,stride, stride,1], padding='VALID',name=\"conv\")\n",
    "        \n",
    "\n",
    "def conv_elu(input_layer, k, in_filter, ou_filter, stride, scope, activation = tf.nn.elu, reuse=False):\n",
    "    \n",
    "    with tf.compat.v1.variable_scope(scope, reuse = reuse):\n",
    "        W = tf.compat.v1.get_variable(\"weight\", kernel_shape, initializer=tf1.glorot_uniform_initializer())\n",
    "        b = tf.compat.v1.get_variable(\"biases\", bias_shape ,initializer=tf1.glorot_uniform_initializer())\n",
    "        \n",
    "        #we need pyrimad which output is half of its input so, need to pad input.\n",
    "        p = np.floor((kernel_shape[0] - 1) / 2).astype('int32')\n",
    "        padding = tf.constant([[0,0],[p, p],[p, p],[0,0]])\n",
    "        p_x = tf.pad(input_layer, padding)\n",
    "        \n",
    "        #padded input\n",
    "        conv = conv2d(input_layer, W)\n",
    "        output = tf.nn.bias_add(conv, b)\n",
    "        out = activation(output)\n",
    "        \n",
    "    return out\n",
    "\n",
    "\n",
    "def upsampling(input_layer, factor):    \n",
    "    return tf.keras.layers.UpSampling2D(size=(factor, factor))(input_layer)\n",
    "    \n",
    "             \n",
    "\n",
    "def upconv(input_layer, k, in_filter, ou_filter, scope, reuse=False):\n",
    "    \n",
    "    with tf.compat.v1.variable_scope(scope, reuse = reuse):    \n",
    "        #Upsampling\n",
    "        upsample = upsampling(input_layer, 2)\n",
    "        out = conv_elu(upsample, k, in_filter, ou_filter, scope)\n",
    "        return out\n",
    "\n",
    "\n",
    "def conv_block(input_layer, k, in_filter, ou_filter, scope):\n",
    "    \n",
    "    c1 = conv_elu(input_layer, [ou_filter], [k, k, in_filter, ou_filter], 1, scope=scope )\n",
    "    c2 = conv_elu(c1, [ou_filter], [k ,k, ou_filter, ou_filter], 2, scope=scope+'b')\n",
    "    \n",
    "    return c2\n",
    "    \n",
    "def get_disp(x, in_filter,scope):\n",
    "    disp = 0.3 * conv_elu(x, [2], [3, 3, in_filter, 2], 1, scope = scope, activation = tf.nn.sigmoid)\n",
    "    return disp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_architecture(input_layers, ):\n",
    "    \n",
    "    with tf1.name_scope(\"encoder\"):\n",
    "        conv1 = conv_block(input_layers, 7,  3,  32, 'conv1')\n",
    "        conv2 = conv_block(conv1,        5, 32,  64, 'conv2')\n",
    "        conv3 = conv_block(conv2,        3, 64, 128, 'conv3')\n",
    "        conv4 = conv_block(conv3,        3, 128,256, 'conv4')\n",
    "        conv5 = conv_block(conv4,        3, 256,512, 'conv5')\n",
    "        conv6 = conv_block(conv5,        3, 512,512, 'conv6')\n",
    "        conv7 = conv_block(conv6,        3, 512,512, 'conv7')\n",
    "        \n",
    "        \n",
    "    with tf1.name_scope(\"decoder\"):\n",
    "        #upsampling 7\n",
    "        upconv7 = upconv(conv7,     3,  512,  512, scope =  'upconv7')\n",
    "        concat7 = tf.concat([upconv7, conv6], axis=-1)\n",
    "        iconv7  = conv_elu(concat7, 3, 1024,  512, 1, scope= 'iconv7')\n",
    "        \n",
    "        #upsampling 6\n",
    "        upconv6 = upconv(iconv7,    3,  512,  512, scope =  'upconv6')\n",
    "        concat6 = tf.concat([upconv6, conv5], axis=-1)\n",
    "        iconv6  = conv_elu(concat6, 3, 1024,  512, 1, scope= 'iconv6')\n",
    "        \n",
    "        #upsampling 5\n",
    "        upconv5 = upconv(iconv6,    3,  512,  256, scope =  'upconv5')\n",
    "        concat5 = tf.concat([upconv5, conv4], axis=-1)\n",
    "        iconv5  = conv_elu(concat5, 3, 512,   256, 1, scope= 'iconv5')\n",
    "        \n",
    "        #upsampling 4\n",
    "        upconv4 = upconv(iconv5,    3,   256,  128, scope = 'upconv4')\n",
    "        concat4 = tf.concat([upconv4, conv3], axis=-1)\n",
    "        iconv4  = conv_elu(concat4, 3, 256,  128, 1, scope= 'iconv4')\n",
    "        disp4   = get_disp(iconv4, 128, scope= 'disp4')\n",
    "        updisp4 = upsampling(disp4, 2)\n",
    "        \n",
    "        #upsampling 3\n",
    "        upconv3 = upconv(iconv4,    3,  128,  64, scope = 'upconv3')\n",
    "        concat3 = tf.concat([upconv3, conv2, updisp4], axis=-1)\n",
    "        iconv3  = conv_elu(concat3, 3, 130,  64, 1, scope= 'iconv4')\n",
    "        disp3   = get_disp(icon3,  64, scope = 'disp3')\n",
    "        updisp3 = upsampling(disp3, 2)\n",
    "        \n",
    "        #upsampling 2\n",
    "        upconv2 = upconv(iconv3,    3,  64,   32, scope = 'upconv2')\n",
    "        concat2 = tf.concat([upconv2, conv1, updisp3], axis=-1)\n",
    "        iconv2  = conv_elu(concat2, 3,  66,   32, 1, scope= 'iconv2')\n",
    "        disp2   = get_disp(icon3,  32, scope = 'disp2')\n",
    "        updisp2 = upsampling(disp2, 2)\n",
    "        \n",
    "        #upsampling 1\n",
    "        upconv1 = upconv(iconv2,    3,  32,   16, scope = 'upconv1')\n",
    "        concat1 = tf.concat([upconv1, updisp2], axis=-1)\n",
    "        iconv1  = conv_elu(concat2, 3,  18,   16, 1, scope= 'iconv1')\n",
    "        disp1   = get_disp(icon3,  16, scope = 'disp2')\n",
    "        \n",
    "    return disp1, disp2, disp3 ,disp4\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(input):\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf1.disable_eager_execution()\n",
    "tf1.reset_default_graph()\n",
    "n_filters = 64\n",
    "n_channels = 3\n",
    "kernel_shape = [7, 7, n_channels,n_filters]\n",
    "bias_shape = [n_filters]\n",
    "W = tf.compat.v1.get_variable(\"weight\", kernel_shape, initializer=tf1.glorot_uniform_initializer())\n",
    "data_path = '/media/sansii/Software/san_projects/Major_project/KITTI_dataset/2015/testing/'\n",
    "left = ndimage.imread(data_path+\"image_2/000083_10.png\")\n",
    "\n",
    "left_shape = (1, left.shape[0], left.shape[1], 3)\n",
    "input_layer  = tf.compat.v1.placeholder(tf.float32, left_shape,  name='image_left' )\n",
    "p = np.floor((kernel_shape[0] - 1) / 2).astype('int32')\n",
    "padding = tf.constant([[0,0],[p, p],[p, p],[0,0]])\n",
    "p_x = tf.pad(input_layer, padding)\n",
    "conv = conv2d(p_x, W, stride = 2)\n",
    "conv = tf.nn.elu(conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(375, 1242, 3)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "left.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 375, 1242, 3)\n",
      "(1, 188, 621, 64)\n"
     ]
    }
   ],
   "source": [
    "var = tf1.global_variables_initializer()\n",
    "with tf1.Session() as sess:\n",
    "    sess.run(var)\n",
    "    left_ = left[np.newaxis,...]\n",
    "    print(left_.shape)\n",
    "    out = sess.run(conv, feed_dict={input_layer: left_})\n",
    "   \n",
    "    print(out.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])?  y\n"
     ]
    }
   ],
   "source": [
    "%reset_selective conv2d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.random.randint(0,5,size=(2,2,5)).astype('int')\n",
    "b = np.random.randint(0,5,size=(2,2,5)).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 2, 10)\n"
     ]
    }
   ],
   "source": [
    "c = np.concatenate((a,b), axis=-1)\n",
    "print(c.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
