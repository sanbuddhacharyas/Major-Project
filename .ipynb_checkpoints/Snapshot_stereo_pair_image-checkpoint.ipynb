{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.widgets import RectangleSelector\n",
    "from camera_calibrate import StereoCalibration\n",
    "import h5py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#path = \"E:/san_projects/Major_project\"\n",
    "path = \"/media/sansii/Software/san_projects/Major_project/Stereo_images\"\n",
    "criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "Width = 1280\n",
    "Height = 720\n",
    "#Camera setting for webcam 1 and 2\n",
    "capL = cv2.VideoCapture(2)\n",
    "capR = cv2.VideoCapture(1)\n",
    "if (capL.isOpened()):\n",
    "    print(\"opened capL video device\")\n",
    "    \n",
    "if (capR.isOpened()):\n",
    "     print(\"opened capR video device\")\n",
    "\n",
    "# #Set Resolution of camera 1\n",
    "capL.set(cv2.CAP_PROP_FRAME_WIDTH, Width)\n",
    "capL.set(cv2.CAP_PROP_FRAME_HEIGHT, Height)\n",
    "\n",
    "\n",
    "# #Set Resolution of camera 2 \n",
    "capR.set(cv2.CAP_PROP_FRAME_WIDTH, Width)\n",
    "capR.set(cv2.CAP_PROP_FRAME_HEIGHT,Height)\n",
    "\n",
    "\n",
    "i =0;\n",
    "i = np.array(glob.glob(path+'/set1/Left/*.jpg')).size\n",
    "print(i)\n",
    "while True:\n",
    "    retL, frameL  = capL.read(cv2.IMREAD_COLOR)\n",
    "    retR, frameR  = capR.read(cv2.IMREAD_COLOR)\n",
    "        \n",
    "    #im_h = cv2.hconcat([frameL,frameR])\n",
    "#     cv2.namedWindow('Left_camera                 Right_camera',cv2.WINDOW_NORMAL)\n",
    "#     cv2.resizeWindow('Left_camera                 Right_camera',2000 ,720)\n",
    "#     cv2.imshow('Left_camera                 Right_camera',im_h)\n",
    "    cv2.imshow(\"Left\", frameL)\n",
    "    cv2.imshow(\"Right\",frameR)\n",
    "  \n",
    "    K = cv2.waitKey(1)\n",
    "    if K == 27:\n",
    "        capL.release()\n",
    "        capR.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        break\n",
    "    if K == 115:\n",
    "        cv2.imwrite(path+'/set1/Left/'+str(i)+'.jpg',frameL)\n",
    "        cv2.imwrite(path+'/set1/Right/'+str(i)+'.jpg',frameR)\n",
    "        i = i+1\n",
    "        \n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def find_disparity(imgL, imgR):\n",
    "    # disparity range is tuned for 'aloe' image pair\n",
    "    window_size = 3\n",
    "    min_disp = 8\n",
    "    num_disp = 50\n",
    "    stereo = cv2.StereoSGBM_create(minDisparity = min_disp,\n",
    "        numDisparities = num_disp,\n",
    "        blockSize = 16,\n",
    "        P1 = 8*3*window_size**2,\n",
    "        P2 = 32*3*window_size**2,\n",
    "        disp12MaxDiff = 1,\n",
    "        uniquenessRatio = 10,\n",
    "        speckleWindowSize = 100,\n",
    "        speckleRange = 32,\n",
    "        mode = cv2.STEREO_SGBM_MODE_SGBM_3WAY\n",
    "        \n",
    "    )\n",
    "    \n",
    "    disparity = stereo.compute(cv2.cvtColor(imgL,cv2.COLOR_BGR2GRAY), cv2.cvtColor(imgR,cv2.COLOR_BGR2GRAY)).astype(np.float32) / 16.0\n",
    "    # Normalize the image for representation\n",
    "#     min_ = disparity.min()\n",
    "#     max_ = disparity.max()\n",
    "#     disparity = np.uint8(255 * ((disparity - min_) / (max_ - min_)))\n",
    "#     print(\"disparity_max\",disparity.max())\n",
    "#     print(\"Shpae\",disparity.shape)\n",
    "#     fig, ax = plt.subplots(figsize=(16,9))\n",
    "#     ax.imshow(disparity, cmap ='jet')\n",
    "#     fig.show()\n",
    "    return disparity\n",
    "\n",
    "    \n",
    "#     return stereo.compute(left_image, right_image).astype(np.float32) / 16.0\n",
    "\n",
    "def load_parameters(path):\n",
    "    with h5py.File(path+\"/Calibration/stereo_mapping.h5py\",\"r\") as hdf:\n",
    "        mapx1 = np.array(hdf[\"stereo_mapping/mapx1\"])\n",
    "        mapy1 = np.array(hdf[\"stereo_mapping/mapy1\"])\n",
    "        mapx2 = np.array(hdf[\"stereo_mapping/mapx2\"])\n",
    "        mapy2 = np.array(hdf[\"stereo_mapping/mapy2\"])\n",
    "        roi1 = np.array(hdf[\"stereo_mapping/roi1\"])\n",
    "        roi2 = np.array(hdf[\"stereo_mapping/roi2\"])\n",
    "        \n",
    "    with h5py.File(cal_path+\"/Calibration/Stereo_rectify.h5py\",\"r\") as hdf:\n",
    "        Q = np.array(hdf[\"Stereo_rectify/Q\"])\n",
    "        \n",
    "    return (mapx1, mapy1, mapx2, mapy2, roi1, roi2, Q)\n",
    "\n",
    "def depth(disp, q):\n",
    "    points = cv2.reprojectImageTo3D(disp, q)\n",
    "    #Z = np.array(points[:,:,2])\n",
    "    #dep = (1448.9 * 13)*(1 / disp)\n",
    "#     colors = image.reshape(-1, 3)\n",
    "    return points[:,:,2]#dep #remove_invalid(disp.reshape(-1), points, colors) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ".setpath = \"/media/sansii/Software/san_projects/Major_project\"\n",
    "#path = \"E:/san_projects/Major_project\"\n",
    "cam_calibrate = StereoCalibration(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam_calibrate.calibrate_camera(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam_calibrate.stereo_rectify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam_calibrate.stereo_undistor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/media/sansii/Software/san_projects/Major_project\"\n",
    "#path = \"E:/san_projects/Major_project\"\n",
    "img_l = cv2.imread(path+\"/Stereo_images/Left/\"+str(0)+\".jpg\")\n",
    "img_r = cv2.imread(path+\"/Stereo_images/Right/\"+str(0)+\".jpg\")\n",
    "\n",
    "with h5py.File(path+\"/Calibration/stereo_mapping.h5py\",\"r\") as hdf:\n",
    "    mapx1 = np.array(hdf[\"stereo_mapping/mapx1\"])\n",
    "    mapy1 = np.array(hdf[\"stereo_mapping/mapy1\"])\n",
    "    mapx2 = np.array(hdf[\"stereo_mapping/mapx2\"])\n",
    "    mapy2 = np.array(hdf[\"stereo_mapping/mapy2\"])\n",
    "    roi1 = np.array(hdf[\"stereo_mapping/roi1\"])\n",
    "    roi2 = np.array(hdf[\"stereo_mapping/roi2\"])\n",
    "    \n",
    "    \n",
    "with h5py.File(path+\"/Calibration/Camera_parameters.h5py\",\"r\") as hdf:\n",
    "    M1 = np.array(hdf[\"/Camera_parameter/M1\"])\n",
    "    dist1 = np.array(hdf[\"/Camera_parameter/dist1\"])\n",
    "    r1 = np.array(hdf[\"/Camera_parameter/r1\"])\n",
    "    t1 = np.array(hdf[\"/Camera_parameter/t1\"])\n",
    "    \n",
    "    M2 = np.array(hdf[\"/Camera_parameter/M2\"])\n",
    "    dist2 = np.array(hdf[\"/Camera_parameter/dist2\"])\n",
    "    r2 = np.array(hdf[\"/Camera_parameter/r2\"])\n",
    "    t2 = np.array(hdf[\"/Camera_parameter/t2\"])\n",
    "    \n",
    "with h5py.File(path+\"/Calibration/Stereo_parameters.h5py\",\"r\") as hdf:\n",
    "    R = np.array(hdf[\"Stereo_parameters/R\"])\n",
    "    T = np.array(hdf[\"Stereo_parameters/T\"])\n",
    "    F = np.array(hdf[\"Stereo_parameters/F\"])\n",
    "    E = np.array(hdf[\"Stereo_parameters/E\"])\n",
    "    \n",
    "with h5py.File(path+\"/Calibration1/Stereo_rectify.h5py\",\"r\") as hdf:\n",
    "    Q = np.array(hdf[\"Stereo_rectify/Q\"])\n",
    "\n",
    "print(Q)\n",
    "# img_rect1 = cv2.remap(img_l, mapx1, mapy1, cv2.INTER_LINEAR)\n",
    "# img_rect2 = cv2.remap(img_r, mapx2, mapy2, cv2.INTER_LINEAR)\n",
    "\n",
    "# #x1,y1,w1,h1 = roi1\n",
    "# print(\"roi1\",roi1)\n",
    "# print(\"roi2\",roi2)\n",
    "# x2,y2,w2,h2 = roi2\n",
    "# img_rect1 = img_rect1[y2:y2+h2, x2:x2+w2]\n",
    "# img_rect2 = img_rect2[y2:y2+h2, x2:x2+w2]\n",
    "# dim = (1280, 720)\n",
    "\n",
    "# L_resized = cv2.resize(img_rect1, dim, interpolation = cv2.INTER_AREA)\n",
    "# R_resized = cv2.resize(img_rect2, dim, interpolation = cv2.INTER_AREA)\n",
    "\n",
    "# img_rect = cv2.hconcat([L_resized, R_resized ])\n",
    "# img_unrect = cv2.hconcat([img_l, img_r])\n",
    "# thickness = 1\n",
    "# color = (0, 255, 0) \n",
    "# y = 0\n",
    "# for i in range(15):\n",
    "#     start_point = (0, y)\n",
    "#     end_point = (2560, y) \n",
    "#     y += 50\n",
    "\n",
    "#     image = cv2.line(img_rect, start_point, end_point, color, thickness)\n",
    "#     image = cv2.line(img_unrect, start_point, end_point, color, thickness)\n",
    "\n",
    "\n",
    "# disparity range is tuned for 'aloe' image pair\n",
    "# disparity range is tuned for 'aloe' image pair\n",
    "# window_size = 12\n",
    "# min_disp = 0\n",
    "# num_disp = 32-min_disp\n",
    "# stereo = cv2.StereoSGBM_create(minDisparity = min_disp,\n",
    "#     numDisparities = num_disp,\n",
    "#     blockSize = 16,\n",
    "#     P1 = 8*3*window_size**2,\n",
    "#     P2 = 32*3*window_size**2,\n",
    "#     disp12MaxDiff = 1,\n",
    "#     uniquenessRatio = 10,\n",
    "#     speckleWindowSize = 100,\n",
    "#     speckleRange = 32\n",
    "# )\n",
    "# disparity = stereo.compute(cv2.cvtColor(img_rect1,cv2.COLOR_BGR2GRAY), cv2.cvtColor(img_rect2,cv2.COLOR_BGR2GRAY))\n",
    "# fig, ax = plt.subplots(figsize=(10,6))\n",
    "# ax.imshow(disparity, cmap ='jet')\n",
    "# plt.show()\n",
    "# cv2.namedWindow('Rectifited',cv2.WINDOW_NORMAL)\n",
    "# cv2.resizeWindow(\"Rectifited\",2560, 720)\n",
    "# cv2.imshow(\"Rectifited\",img_rect)\n",
    "# cv2.imshow(\"Unrectifited_image\",img_unrect)\n",
    "\n",
    "\n",
    "# cv2.waitKey()\n",
    "# cv2.destroyAllWindows()\n",
    "print(Q.shape)\n",
    "print(M1)\n",
    "print(M2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path = \"/media/sansii/Software/san_projects/Major_project\"\n",
    "path = \"E:/san_projects/Major_project\"\n",
    "img = cv2.imread(path+\"/Stereo_images/Left/\"+str(35)+\".jpg\")\n",
    "h,  w = img.shape[:2]\n",
    "print(w, h)\n",
    "M1 = np.array([[1434.2, 0, 641.4986],\n",
    "                [0, 1452.8, 353.1153],\n",
    "                [0, 0, 1]])\n",
    "dist1 = np.array([[0.0234, 0.4622, -1.05552976e-02 , 2.28002928e-02, 0]])\n",
    "\n",
    "newcameramtx,roi =cv2.getOptimalNewCameraMatrix(M2,dist2,(w,h),1,(w,h))\n",
    "# undistort\n",
    "dst = cv2.undistort(img, M1, dist1, None, newcameramtx)\n",
    "cv2.imshow(\"dst\",dst)\n",
    "# crop the image\n",
    "x,y,w,h = roi\n",
    "print(roi)\n",
    "dst = dst[y:y+h, x:x+w]\n",
    "cv2.imshow(\"after_dst\",dst)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M1 = np.array([[1434.62292,0,0],\n",
    "               [0,1453.195716,0],\n",
    "               [641.0198149,353.0956503,1]]).T\n",
    "\n",
    "dist1 = np.array([[0.007316433, 0.73206921, 0, 0, -1.427660389]])\n",
    "\n",
    "M2 = np.array([[1429.371545, 0,0],\n",
    "               [0,1445.10764,0],\n",
    "               [636.2557695,346.8882958,1]]).T\n",
    "dist2 = np.array([[-0.062003374,1.236685272, 0, 0, -3.136518693]])\n",
    "\n",
    "R = np.array([[0.999990192,0.004377623,-0.000672034],\n",
    "[-0.004383103, 0.999955266, -0.008381846],\n",
    "[0.000635312, 0.008384709, 0.999964646]]).T\n",
    "\n",
    "T = np.array([[-131.8616357, -0.09697448, -4.248546157 ]]).T\n",
    "\n",
    "F = np.array([[9.10E-09,2.05E-06,-0.00077107],\n",
    "[-2.09E-06, -5.17E-07, 0.092765559],\n",
    "[0.000385134, -0.091857384, -0.541412544]])\n",
    "\n",
    "camera_model = dict([(\"M1\",M1), (\"M2\",M2), (\"dist1\",dist1), (\"dist2\",dist2), (\"R\",R),\n",
    "                    (\"T\", T) , (\"F\",F)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(camera_model[\"T\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stereo_rectify(camera_model, dims, cal_path):\n",
    "    \n",
    "    #perform the rectification\n",
    "    R1, R2, P1, P2, Q, roi1, roi2 = cv2.stereoRectify(camera_model[\"M1\"], camera_model[\"dist1\"],\n",
    "                                                    camera_model[\"M2\"], camera_model[\"dist2\"], dims,\n",
    "                                                    camera_model[\"R\"], camera_model[\"T\"], alpha= 1)\n",
    "\n",
    "    with h5py.File(cal_path+\"/Calibration/Stereo_rectify.h5py\",\"w\") as hdf:\n",
    "        #Creating group name camera_parameters\n",
    "        stereo_rectify = hdf.create_group(\"Stereo_rectify\")\n",
    "        #Creating data set in group\n",
    "        stereo_rectify.create_dataset(\"R1\",data = R1)\n",
    "        stereo_rectify.create_dataset(\"R2\",data = R2 )\n",
    "        stereo_rectify.create_dataset(\"P1\",data = P1 )\n",
    "        stereo_rectify.create_dataset(\"P2\",data = P2 )\n",
    "        stereo_rectify.create_dataset(\"Q\",data =  Q )\n",
    "        stereo_rectify.create_dataset(\"roi1\",data = roi1 )\n",
    "        stereo_rectify.create_dataset(\"roi2\",data = roi2 )\n",
    "\n",
    "    newcameramtx_1, roi_1 = cv2.getOptimalNewCameraMatrix(camera_model[\"M1\"], camera_model[\"dist1\"], \n",
    "                                                            img_shape, 1, img_shape)\n",
    "    newcameramtx_2, roi_2 = cv2.getOptimalNewCameraMatrix(camera_model[\"M2\"], camera_model[\"dist2\"], \n",
    "                                                            img_shape, 1, img_shape)\n",
    "\n",
    "    mapx1, mapy1 = cv2.initUndistortRectifyMap(camera_model[\"M1\"], camera_model[\"dist1\"], \n",
    "                                                R1, newcameramtx_1, img_shape, cv2.CV_32F)\n",
    "\n",
    "    mapx2, mapy2 = cv2.initUndistortRectifyMap(camera_model[\"M2\"], camera_model[\"dist2\"], R2, newcameramtx_2,\n",
    "                                               img_shape, cv2.CV_32F)\n",
    "\n",
    "\n",
    "    with h5py.File(cal_path+\"/Calibration/stereo_mapping.h5py\",\"w\") as hdf:\n",
    "        stereo_map = hdf.create_group(\"stereo_mapping\")\n",
    "        stereo_map.create_dataset(\"mapx1\",data= mapx1)\n",
    "        stereo_map.create_dataset(\"mapy1\",data= mapy1)\n",
    "        stereo_map.create_dataset(\"mapx2\",data= mapx2)\n",
    "        stereo_map.create_dataset(\"mapy2\",data= mapy2)\n",
    "        stereo_map.create_dataset(\"roi1\",data= roi1)\n",
    "        stereo_map.create_dataset(\"roi2\",data= roi2)\n",
    "\n",
    "    print(\"Calibrated sucessfull\")\n",
    "\n",
    "    img_l = cv2.imread(cal_path+'/Stereo_images/Left/'+str(0)+'.jpg')\n",
    "    img_r = cv2.imread(cal_path+'/Stereo_images/Right/'+str(0)+'.jpg')\n",
    "    img_rect1 = cv2.remap(img_l, mapx1, mapy1, cv2.INTER_NEAREST)\n",
    "    img_rect2 = cv2.remap(img_r, mapx2, mapy2, cv2.INTER_NEAREST)\n",
    "\n",
    "    x1,y1,w1,h1 = roi1\n",
    "    x2,y2,w2,h2 = roi2\n",
    "    img_rect1 = img_rect1[y1:y1+h1, x1:x1+w1]\n",
    "    img_rect2 = img_rect2[y2:y2+h2, x2:x2+w2]\n",
    "    dim = (1280, 720)\n",
    "\n",
    "    L_resized = cv2.resize(img_rect1, dim, interpolation = cv2.INTER_AREA)\n",
    "    R_resized = cv2.resize(img_rect2, dim, interpolation = cv2.INTER_AREA)\n",
    "    \n",
    "    img = cv2.hconcat([L_resized, R_resized])\n",
    "    thickness = 1\n",
    "    color = (0, 255, 0) \n",
    "    y = 0\n",
    "    for i in range(15):\n",
    "        start_point = (0, y)\n",
    "        end_point = (2560, y) \n",
    "        y += 50\n",
    "\n",
    "        image = cv2.line(img, start_point, end_point, color, thickness) \n",
    "\n",
    "    cv2.namedWindow('image',cv2.WINDOW_NORMAL)\n",
    "    cv2.resizeWindow(\"image\",2560, 720)\n",
    "    cv2.imshow(\"image\",img)\n",
    "\n",
    "    cv2.waitKey()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/media/sansii/Software/san_projects/Major_project\"\n",
    "img = cv2.imread(path+\"/Stereo_images/Left/\"+str(0)+\".jpg\")\n",
    "gray_l = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "img_shape = gray_l.shape[::-1]\n",
    "path = \"/media/sansii/Software/san_projects/Major_project\"\n",
    "#path = \"E:/san_projects/Major_project\"\n",
    "stereo_rectify(camera_model,img_shape , path )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calibrate_camera(cal_path):\n",
    "    flags = 0;\n",
    "    flags |= 8\n",
    "    imgpoints_l = []\n",
    "    objpoints = []\n",
    "    num_detected_board = 0\n",
    "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "    number_cal_pair = np.array(glob.glob(cal_path+'/Stereo_images/Left/*.jpg')).size\n",
    "    \n",
    "    objp = np.zeros((6*8, 3), np.float32)\n",
    "    objp[:, :2] = np.mgrid[0:8, 0:6].T.reshape(-1, 2)\n",
    "    objp = 30 * objp\n",
    "\n",
    "    for i in range(number_cal_pair):\n",
    "\n",
    "        img_l = cv2.imread(cal_path+'/Stereo_images/Left/'+str(i)+'.jpg')\n",
    "      \n",
    "        gray_l = cv2.cvtColor(img_l, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # Find the chess board corners\n",
    "        ret_l, corners_l = cv2.findChessboardCorners(gray_l, (8, 6), None)\n",
    "\n",
    "        if ret_l is True:\n",
    "\n",
    "            #If corner is detected with different order then rotate detected points to match with object \n",
    "            # points order(0,0,0), (1,0,0)...\n",
    "#             if (corners_l[0][0][0] > corners_l[47][0][0]):\n",
    "#                 corners_l = np.rot90(corners_l,2).reshape(48,1,2)\n",
    "#                 corners_l = np.array(corners_l)\n",
    "\n",
    "            #Find subPixel of left camera and add image points\n",
    "            cv2.cornerSubPix(gray_l, corners_l, (11, 11), (-1, -1), criteria)\n",
    "\n",
    "\n",
    "\n",
    "            # Draw and display the corners Left image\n",
    "            ret_l = cv2.drawChessboardCorners(img_l, (8, 6),corners_l, ret_l)\n",
    "            cv2.imshow(\"Left\"+str(i), img_l)\n",
    "\n",
    "        \n",
    "            key = cv2.waitKey()\n",
    "            if key == 115:\n",
    "                imgpoints_l.append(corners_l)\n",
    "                #Add object points(Object World point)\n",
    "                objpoints.append(objp)\n",
    "\n",
    "                #Num of pair chess board_pair detected\n",
    "                num_detected_board += 1\n",
    "\n",
    "            cv2.destroyAllWindows()\n",
    "           \n",
    "    #Transpose image shape\n",
    "    img_shape = gray_l.shape[::-1]\n",
    "    #assert(self.num_detected_board == np.array(self.imgpoints_l).size)\n",
    "    print(\"Numbers of Chess detected\" , num_detected_board, \"Img _points\", np.array(imgpoints_l).shape)\n",
    "    #Determine the camera parameters\n",
    "    rt, M1, d1, r1, t1 = cv2.calibrateCamera(objpoints, imgpoints_l, img_shape, None, None,flags = flags)\n",
    "\n",
    "    camera_parameters = {   \"M1\": M1,\n",
    "                            \"dist1\": d1,\n",
    "                            \"r1\": r1,\n",
    "                            \"t1\":t1\n",
    "                        }\n",
    "    print(camera_parameters)\n",
    "    return (camera_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"E:/san_projects/Major_project\"\n",
    "calibrate_camera(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objp = np.zeros((6*8, 3), np.float32)\n",
    "objp[:, :2] = np.mgrid[0:8, 0:6].T.reshape(-1, 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import argparse\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# size calib array\n",
    "numEdgeX = 10\n",
    "numEdgeY = 7\n",
    "\n",
    "# preface\n",
    "exitCode = 0\n",
    "\n",
    "\n",
    "cal_path = \"/media/sansii/Software/san_projects/Major_project\"\n",
    "\n",
    "\n",
    "images_right = glob.glob(cal_path + '/Stereo_images/set1/Left/*.jpg')\n",
    "images_left = glob.glob(cal_path + '/Stereo_images/set1/Right/*.jpg')\n",
    "images_left.sort()\n",
    "images_right.sort()\n",
    "\n",
    "# termination criteria\n",
    "criteria = (cv2.TermCriteria_EPS +\n",
    "                    cv2.TermCriteria_MAX_ITER, 30, 0.001)\n",
    "criteria_cal = (cv2.TermCriteria_EPS +\n",
    "                    cv2.TermCriteria_MAX_ITER, 30, 1e-5)\n",
    "\n",
    "# prepare object points, like (0,0,0); (1,0,0); ...; (6,5,0)\n",
    "objp = np.zeros((numEdgeX*numEdgeY, 3), np.float32)\n",
    "objp[:, :2] = np.mgrid[0:numEdgeX, 0:numEdgeY].T.reshape(-1, 2)\n",
    "\n",
    "objpoints = []     # 3d points in real world space\n",
    "imgpoints_l = []   # 2d points in image plane for calibration\n",
    "imgpoints_r = []   # 2d points in image plane for calibration\n",
    "\n",
    "for i, fname in enumerate(images_right):\n",
    "        #print(str(i+1) + \" out of \" + str(len(images_right)))\n",
    "        frame_L = cv2.imread(images_left[i])\n",
    "        frame_R = cv2.imread(images_right[i])\n",
    "\n",
    "        # convert to cv2\n",
    "        img_l = cv2.cvtColor(frame_L, cv2.COLOR_BGR2GRAY)\n",
    "        img_r = cv2.cvtColor(frame_R, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # find the chess board corners\n",
    "        ret_l, corners_l = cv2.findChessboardCorners(img_l, (numEdgeX, numEdgeY), None)\n",
    "        ret_r, corners_r = cv2.findChessboardCorners(img_r, (numEdgeX, numEdgeY), None)\n",
    "\n",
    "        \n",
    "\n",
    "        if ret_l is True and ret_r is True:\n",
    "            if (corners_l[0][0][0] > corners_l[numEdgeX*numEdgeY -1 ][0][0]):\n",
    "                    corners_l = np.rot90(corners_l,2).reshape(numEdgeX * numEdgeY,1,2)\n",
    "                    corners_l = np.array(corners_l)\n",
    "\n",
    "            if (corners_r[0][0][0] > corners_r[numEdgeX*numEdgeY -1][0][0]):\n",
    "                corners_r = np.rot90(corners_r,2).reshape(numEdgeX * numEdgeY,1,2)\n",
    "                corners_r = np.array(corners_r)\n",
    "            print(\"image \" + str(i+1) + \"left - io\")\n",
    "            \n",
    "            rt = cv2.cornerSubPix(img_l, corners_l, (11, 11),\n",
    "                                  (-1, -1), criteria)\n",
    "        \n",
    "       \n",
    "            print(\"image \" + str(i+1) + \"right - io\")\n",
    "            rt = cv2.cornerSubPix(img_r, corners_r, (11, 11),\n",
    "                                  (-1, -1), criteria)\n",
    "            \n",
    "            # Draw and display the corners Left image\n",
    "            #ret_l = cv2.drawChessboardCorners(frame_L, (numEdgeX,numEdgeY),corners_l, ret_l)\n",
    "            #cv2.imshow(\"Left\"+str(i), img_l)\n",
    "\n",
    "            # Draw and display the corners Right image\n",
    "            #ret_r = cv2.drawChessboardCorners(frame_R, (numEdgeX,numEdgeY) ,corners_r, ret_r)\n",
    "#             cv2.imshow(\"Left\" , frame_L )\n",
    "#             cv2.imshow(\"Right\" ,frame_R )\n",
    "            #key = cv2.waitKey()\n",
    "            #if key == 115:\n",
    "            imgpoints_l.append(corners_l)\n",
    "            imgpoints_r.append(corners_r)\n",
    "            objpoints.append(objp)\n",
    "\n",
    "\n",
    "        # get shape\n",
    "        img_shape = img_l.shape[::-1]\n",
    "\n",
    "\n",
    "### CALIBRATION ###\n",
    "# calibrate left camera\n",
    "rt, M1, d1, r1, t1 = cv2.calibrateCamera(\n",
    "objpoints, imgpoints_l, img_shape, None, None)\n",
    "\n",
    "# calibrate right camera\n",
    "rt, M2, d2, r2, t2 = cv2.calibrateCamera(\n",
    "objpoints, imgpoints_r, img_shape, None, None)\n",
    "\n",
    "# stereo calibration\n",
    "flags = (cv2.CALIB_FIX_K5 + cv2.CALIB_FIX_K6)\n",
    "\n",
    "stereocalib_criteria = (cv2.TERM_CRITERIA_MAX_ITER +\n",
    "                    cv2.TERM_CRITERIA_EPS, 100, 1e-5)\n",
    "\n",
    "#flags = 0\n",
    "#flags = cv2.CALIB_USE_INTRINSIC_GUESS\n",
    "#flags = cv2.CALIB_FIX_PRINCIPAL_POINT\n",
    "#flags = cv2.CALIB_FIX_ASPECT_RATIO\n",
    "#flags = cv2.CALIB_ZERO_TANGENT_DIST\n",
    "#flags = cv2.CALIB_FIX_INTRINSIC   \n",
    "#flags = cv2.CALIB_FIX_FOCAL_LENGTH\n",
    "#flags = cv2.CALIB_FIX_K1...6\n",
    "#flags = cv2.CALIB_RATIONAL_MODEL\n",
    "#flags = cv2.CALIB_THIN_PRISM_MODEL\n",
    "#flags = cv2.CALIB_SAME_FOCAL_LENGTH\n",
    "#flags = cv2.CALIB_FIX_S1_S2_S3_S4\n",
    "\n",
    "flags = (cv2.CALIB_FIX_PRINCIPAL_POINT | cv2.CALIB_FIX_ASPECT_RATIO | cv2.CALIB_FIX_FOCAL_LENGTH |\n",
    "         cv2.CALIB_FIX_INTRINSIC | cv2.CALIB_FIX_K3 | cv2.CALIB_FIX_K4 | cv2.CALIB_FIX_K5 |\n",
    "         cv2.CALIB_FIX_K6)\n",
    "\n",
    "T = np.zeros((3, 1), dtype=np.float64)\n",
    "R = np.eye(3, dtype=np.float64)\n",
    "\n",
    "ret, M1, d1, M2, d2, R, T, E, F = cv2.stereoCalibrate(\n",
    "        objpoints, imgpoints_l,\n",
    "        imgpoints_r, M1, d1, M2,\n",
    "        d2, img_shape,\n",
    "        criteria = stereocalib_criteria)\n",
    "\n",
    "# get new optimal camera matrix\n",
    "newCamMtx1, roi1 = cv2.getOptimalNewCameraMatrix(M1, d1, img_shape, 0, img_shape)\n",
    "newCamMtx2, roi2 = cv2.getOptimalNewCameraMatrix(M2, d2, img_shape, 0, img_shape)\n",
    "\n",
    "# rectification and undistortion maps which can be used directly to correct the stereo pair\n",
    "(rectification_l, rectification_r, projection_l,\n",
    "    projection_r, disparityToDepthMap, ROI_l, ROI_r) = cv2.stereoRectify(\n",
    "        M1, d1, M2, d2, img_shape, R, T,\n",
    "        None, None, None, None, None,\n",
    "        #cv2.CALIB_ZERO_DISPARITY,                  # principal points of each camera have the same pixel coordinates in rect views\n",
    "        alpha=0)                                   # alpha=1 no pixels lost, alpha=0 pixels lost\n",
    "\n",
    "leftMapX, leftMapY = cv2.initUndistortRectifyMap(\n",
    "    M1, d1, rectification_l, projection_l,\n",
    "    img_shape, cv2.CV_32FC1)\n",
    "rightMapX, rightMapY = cv2.initUndistortRectifyMap(\n",
    "    M2, d2, rectification_r, projection_r,\n",
    "    img_shape, cv2.CV_32FC1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### REMAPPING ###\n",
    "# load images and convert to cv2 format\n",
    "img_l = cv2.imread(cal_path+\"/Stereo_images/Left/\"+str(0)+\".jpg\")\n",
    "img_r = cv2.imread(cal_path+\"/Stereo_images/Right/\"+str(0)+\".jpg\")\n",
    "\n",
    "\n",
    "# remap\n",
    "imglCalRect = cv2.remap(img_l, leftMapX, leftMapY, cv2.INTER_LINEAR)\n",
    "imgrCalRect = cv2.remap(img_r, rightMapX, rightMapY, cv2.INTER_LINEAR)\n",
    "numpyHorizontalCalibRect = cv2.hconcat([imglCalRect, imgrCalRect])\n",
    "\n",
    "  \n",
    "\n",
    "\n",
    "thickness = 1\n",
    "color = (0, 255, 0) \n",
    "y = 0\n",
    "for i in range(15):\n",
    "    start_point = (0, y)\n",
    "    end_point = (2560, y) \n",
    "    y += 50\n",
    "\n",
    "    image = cv2.line(numpyHorizontalCalibRect, start_point, end_point, color, thickness) \n",
    "\n",
    "cv2.namedWindow('image',cv2.WINDOW_NORMAL)\n",
    "cv2.resizeWindow(\"image\",1800, 720)\n",
    "cv2.imshow(\"image\",numpyHorizontalCalibRect)\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "#find_disparity(imglCalRect, imgrCalRect)\n",
    "\n",
    "# except(IOError, ValueError):\n",
    "#     print(\"An I/O error or a ValueError occurred\")\n",
    "# except:\n",
    "#     print(\"An unexpected error occurred\")\n",
    "# raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(cal_path+\"/Calibration/stereo_mapping.h5py\",\"r\") as hdf:\n",
    "    mapx1 = np.array(hdf[\"stereo_mapping/mapx1\"])\n",
    "    mapy1 = np.array(hdf[\"stereo_mapping/mapy1\"])\n",
    "    mapx2 = np.array(hdf[\"stereo_mapping/mapx2\"])\n",
    "    mapy2 = np.array(hdf[\"stereo_mapping/mapy2\"])\n",
    "    roi1 = np.array(hdf[\"stereo_mapping/roi1\"])\n",
    "    roi2 = np.array(hdf[\"stereo_mapping/roi2\"])\n",
    "\n",
    "img_l = cv2.imread(cal_path+\"/Stereo_images/set1/Left/\"+str(0)+\".jpg\")\n",
    "img_r = cv2.imread(cal_path+\"/Stereo_images/set1/Right/\"+str(0)+\".jpg\")\n",
    "imgL = cv2.remap(img_l, mapx1, mapy1, cv2.INTER_LINEAR)\n",
    "imgR = cv2.remap(img_r, mapx2, mapy2, cv2.INTER_LINEAR)\n",
    "numpyHorizontalCalibRect = cv2.hconcat([imgL, imgR])\n",
    "thickness = 1\n",
    "color = (0, 255, 0) \n",
    "y = 0\n",
    "for i in range(15):\n",
    "    start_point = (0, y)\n",
    "    end_point = (2560, y) \n",
    "    y += 50\n",
    "\n",
    "    image = cv2.line(numpyHorizontalCalibRect, start_point, end_point, color, thickness) \n",
    "\n",
    "cv2.namedWindow('image',cv2.WINDOW_NORMAL)\n",
    "cv2.resizeWindow(\"image\",1800, 720)\n",
    "cv2.imshow(\"image\",numpyHorizontalCalibRect)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "#find_disparity(imgL, imgR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate distance of object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: TkAgg\n",
      "opened capL video device\n",
      "opened capR video device\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.2.0) /io/opencv/modules/imgproc/src/imgwarp.cpp:668: error: (-215:Assertion failed) !ssize.empty() in function 'remapBilinear'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-fd7dc03c3bf1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m     \u001b[0mimg_rect1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframeL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapy1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mINTER_LINEAR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m     \u001b[0mimg_rect2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframeR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapy2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mINTER_LINEAR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.2.0) /io/opencv/modules/imgproc/src/imgwarp.cpp:668: error: (-215:Assertion failed) !ssize.empty() in function 'remapBilinear'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "x_top = 0\n",
    "y_top = 0\n",
    "x_bottom = 0\n",
    "y_bottom = 0\n",
    "global disp\n",
    "%matplotlib\n",
    "\n",
    "def disparity(imgL, imgR):\n",
    "    # SGBM Parameters -----------------\n",
    "    window_size = 3                     # wsize default 3; 5; 7 for SGBM reduced size image; 15 for SGBM full size image (1300px and above); 5 Works nicely\n",
    "\n",
    "    left_matcher = cv2.StereoSGBM_create(\n",
    "        minDisparity=11,\n",
    "        numDisparities=171,             # max_disp has to be dividable by 16 f. E. HH 192, 256\n",
    "        blockSize=5,\n",
    "        P1=8 * 3 * window_size ** 2,    # wsize default 3; 5; 7 for SGBM reduced size image; 15 for SGBM full size image (1300px and above); 5 Works nicely\n",
    "        P2=32 * 3 * window_size ** 2,\n",
    "        disp12MaxDiff=1,\n",
    "        uniquenessRatio=15,\n",
    "        speckleWindowSize=0,\n",
    "        speckleRange=2,\n",
    "        preFilterCap=63,\n",
    "        mode=cv2.STEREO_SGBM_MODE_HH\n",
    "    )\n",
    "\n",
    "    right_matcher = cv2.ximgproc.createRightMatcher(left_matcher)\n",
    "\n",
    "    # FILTER Parameters\n",
    "    lmbda = 80000\n",
    "    sigma = 1.2\n",
    "    visual_multiplier = 1.0\n",
    "\n",
    "    wls_filter = cv2.ximgproc.createDisparityWLSFilter(matcher_left=left_matcher)\n",
    "    wls_filter.setLambda(lmbda)\n",
    "    wls_filter.setSigmaColor(sigma)\n",
    "\n",
    "    displ = left_matcher.compute(cv2.cvtColor(imgL,cv2.COLOR_BGR2GRAY), cv2.cvtColor(imgR,cv2.COLOR_BGR2GRAY)).astype(np.float32)/16\n",
    "    dispr = right_matcher.compute(imgR, imgL).astype(np.float32)/16\n",
    "    displ = np.int16(displ)\n",
    "    dispr = np.int16(dispr)\n",
    "    filteredImg = wls_filter.filter(displ, cv2.cvtColor(imgL,cv2.COLOR_BGR2GRAY), None, dispr)  # important to put \"imgL\" here!!!\n",
    "    #filteredImg = cv2.normalize(src=filteredImg, dst=filteredImg, beta=0, alpha=255, norm_type=cv2.NORM_MINMAX);\n",
    "    #filteredImg = np.uint8(filteredImg)\n",
    "   \n",
    "    return filteredImg\n",
    "\n",
    "def find_disparity(imgL, imgR):\n",
    "    # disparity range is tuned for 'aloe' image pair\n",
    "    window_size = 3\n",
    "    min_disp = 11\n",
    "    num_disp = 171\n",
    "    stereo = cv2.StereoSGBM_create(minDisparity = min_disp,\n",
    "        numDisparities = num_disp,\n",
    "        blockSize = 7,\n",
    "        P1 = 8*3*window_size**2,\n",
    "        P2 = 32*3*window_size**2,\n",
    "        disp12MaxDiff = 1,\n",
    "        uniquenessRatio = 10,\n",
    "        speckleWindowSize = 100,\n",
    "        speckleRange = 32,\n",
    "        mode = cv2.STEREO_SGBM_MODE_HH\n",
    "        \n",
    "    )\n",
    "    \n",
    "    disparity = stereo.compute(cv2.cvtColor(imgL,cv2.COLOR_BGR2GRAY), cv2.cvtColor(imgR,cv2.COLOR_BGR2GRAY)).astype(np.float32) / 16.0\n",
    "    return disparity\n",
    "\n",
    "    \n",
    "#     return stereo.compute(left_image, right_image).astype(np.float32) / 16.0\n",
    "\n",
    "def load_parameters(path):\n",
    "    with h5py.File(path+\"/Calibration/stereo_mapping.h5py\",\"r\") as hdf:\n",
    "        mapx1 = np.array(hdf[\"stereo_mapping/mapx1\"])\n",
    "        mapy1 = np.array(hdf[\"stereo_mapping/mapy1\"])\n",
    "        mapx2 = np.array(hdf[\"stereo_mapping/mapx2\"])\n",
    "        mapy2 = np.array(hdf[\"stereo_mapping/mapy2\"])\n",
    "        roi1 = np.array(hdf[\"stereo_mapping/roi1\"])\n",
    "        roi2 = np.array(hdf[\"stereo_mapping/roi2\"])\n",
    "        \n",
    "    with h5py.File(cal_path+\"/Calibration/Stereo_rectify.h5py\",\"r\") as hdf:\n",
    "        Q = np.array(hdf[\"Stereo_rectify/Q\"])\n",
    "        \n",
    "    return (mapx1, mapy1, mapx2, mapy2, roi1, roi2, Q)\n",
    "\n",
    "def depth(disp, q):\n",
    "    points = cv2.reprojectImageTo3D(disp, q)\n",
    "    #Z = np.array(points[:,:,2])\n",
    "    #dep = (1448.9 * 13)*(1 / disp)\n",
    "#     colors = image.reshape(-1, 3)\n",
    "    return points[:,:,2]#dep #remove_invalid(disp.reshape(-1), points, colors) \n",
    "def line_select_callback(clk ,rls):\n",
    "  \n",
    "    global x_top, x_bottom ,y_top,y_bottom\n",
    "    global disp\n",
    "    \n",
    "    (x_top, y_top) = (int(clk.xdata), int(clk.ydata))\n",
    "    (x_bottom, y_bottom) = (int(rls.xdata), int(rls.ydata))\n",
    "    \n",
    "    print(x_top, y_top,end=\"\\r\")\n",
    "    print(x_bottom, y_bottom,end=\"\\r\")\n",
    "    \n",
    "    Z = depth(disp,Q)\n",
    "    print(Z[y_top:y_bottom, x_top : x_bottom],end = \"\\r\")\n",
    "    \n",
    "def toggle_selector(event):\n",
    "    toggle_selector.RS.set_active(True)\n",
    "    \n",
    "\n",
    "    \n",
    "cal_path = \"/media/sansii/Software/san_projects/Major_project\"\n",
    "mapx1, mapy1, mapx2, mapy2, roi1, roi2, Q = load_parameters(cal_path)\n",
    "    \n",
    "Width = 1280\n",
    "Height = 720\n",
    "#Camera setting for webcam 1 and 2\n",
    "capL = cv2.VideoCapture(1)\n",
    "capR = cv2.VideoCapture(2)\n",
    "if (capL.isOpened()):\n",
    "    print(\"opened capL video device\")\n",
    "    \n",
    "if (capR.isOpened()):\n",
    "     print(\"opened capR video device\")\n",
    "\n",
    "# #Set Resolution of camera 1\n",
    "capL.set(cv2.CAP_PROP_FRAME_WIDTH, Width)\n",
    "capL.set(cv2.CAP_PROP_FRAME_HEIGHT, Height)\n",
    "\n",
    "\n",
    "# #Set Resolution of camera 2 \n",
    "capR.set(cv2.CAP_PROP_FRAME_WIDTH, Width)\n",
    "capR.set(cv2.CAP_PROP_FRAME_HEIGHT,Height)\n",
    "fig, ax = plt.subplots(figsize=(16,9))\n",
    "fig.show()\n",
    "while True:\n",
    "    retL, frameL  = capL.read(cv2.IMREAD_COLOR)\n",
    "    retR, frameR  = capR.read(cv2.IMREAD_COLOR)\n",
    "    \n",
    "    \n",
    "    img_rect1 = cv2.remap(frameL, mapx1, mapy1, cv2.INTER_LINEAR)\n",
    "    img_rect2 = cv2.remap(frameR, mapx2, mapy2, cv2.INTER_LINEAR)\n",
    "\n",
    "    #x1,y1,w1,h1 = roi1\n",
    "\n",
    "    x2,y2,w2,h2 = roi2\n",
    "    img_rect1 = img_rect1[y2:y2+h2, x2:x2+w2]\n",
    "    img_rect2 = img_rect2[y2:y2+h2, x2:x2+w2]\n",
    "#     cv2.imshow(\"Left\", img_rect1)\n",
    "#     cv2.imshow(\"Right\", img_rect2)\n",
    "    \n",
    "    dim = (1280, 720)\n",
    "\n",
    "    L_resized = cv2.resize(img_rect1, dim, interpolation = cv2.INTER_AREA)\n",
    "    R_resized = cv2.resize(img_rect2, dim, interpolation = cv2.INTER_AREA)\n",
    "    \n",
    "    \n",
    "\n",
    "    img_rect = cv2.hconcat([img_rect1, img_rect2 ])\n",
    "    img_unrec = cv2.hconcat([frameL, frameR])\n",
    "    thickness = 1\n",
    "    color = (0, 255, 0) \n",
    "    y = 0\n",
    "    for i in range(15):\n",
    "        start_point = (0, y)\n",
    "        end_point = (2560, y) \n",
    "        y += 50\n",
    "\n",
    "        image = cv2.line(img_rect, start_point, end_point, color, thickness)\n",
    "        image = cv2.line(img_unrec, start_point, end_point, color, thickness)\n",
    "   \n",
    "    \n",
    "\n",
    "    cv2.namedWindow('Rectified_image',cv2.WINDOW_NORMAL)\n",
    "    cv2.resizeWindow(\"Rectified_image\",1800, 720)\n",
    "    cv2.imshow(\"Rectified_image\",img_rect)\n",
    "    \n",
    "    cv2.namedWindow('UnRectified_image',cv2.WINDOW_NORMAL)\n",
    "    cv2.resizeWindow(\"UnRectified_image\",1800, 720)\n",
    "    \n",
    "    cv2.imshow(\"Rectified_image\",img_rect)\n",
    "    cv2.imshow(\"UnRectified_image\",img_unrec)\n",
    "    key = cv2.waitKey(1)\n",
    "    if key == 27 :\n",
    "        cv2.destroyAllWindows()\n",
    "        capL.release()\n",
    "        capR.release()\n",
    "        break\n",
    "    \n",
    "    if key == 115:\n",
    "        cv2.imwrite(cal_path+\"/resultL.jpg\", img_rect1)\n",
    "        cv2.imwrite(cal_path+\"/resultR.jpg\", img_rect2)\n",
    "        disp = disparity(img_rect1, img_rect2)\n",
    "        Z = depth(disp,Q)\n",
    "\n",
    "        fig, ax = plt.subplots(2,2,figsize=(16,9))\n",
    "        Z = Z / 1000\n",
    "        Z = Z * (Z < 30)\n",
    "        Z = Z * (Z > 0)\n",
    "        cv2.normalize(src=disp, dst=disp, beta=0, alpha=255, norm_type=cv2.NORM_MINMAX);\n",
    "        cv2.normalize(src=Z, dst=Z, beta=0, alpha=255, norm_type=cv2.NORM_MINMAX);\n",
    "        ax[0][0].imshow(cv2.cvtColor(img_rect1, cv2.COLOR_BGR2RGB))\n",
    "        ax[0][1].imshow(cv2.cvtColor(img_rect2, cv2.COLOR_BGR2RGB))\n",
    "        ax[1][0].imshow(disp,cmap = 'jet')\n",
    "        pos = ax[1][1].imshow(Z,cmap = 'jet')\n",
    "        cbar = fig.colorbar(pos, ax=ax, orientation=\"vertical\")\n",
    "\n",
    "        cbar.set_label('Meter(m)', rotation=90)\n",
    "        fig.show()\n",
    "        cv2.destroyAllWindows()\n",
    "        capL.release()\n",
    "        capR.release()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()\n",
    "capL.release()\n",
    "capR.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tkinter as tk\n",
    "from tkinter import *\n",
    "from matplotlib import gridspec\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.figure import Figure\n",
    "from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg\n",
    "from PIL import Image,ImageTk\n",
    "from matplotlib.widgets import RectangleSelector\n",
    "import cv2\n",
    "import h5py\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_disparity(imgL, imgR):\n",
    "    # disparity range is tuned for 'aloe' image pair\n",
    "    window_size = 3\n",
    "    min_disp = 10\n",
    "    num_disp = 122 -min_disp\n",
    "    stereo = cv2.StereoSGBM_create(minDisparity = min_disp,\n",
    "        numDisparities = num_disp,\n",
    "        blockSize = 16,\n",
    "        P1 = 8*3*window_size**2,\n",
    "        P2 = 32*3*window_size**2,\n",
    "        disp12MaxDiff = 1,\n",
    "        uniquenessRatio = 10,\n",
    "        speckleWindowSize = 100,\n",
    "        speckleRange = 32,\n",
    "        \n",
    "    )\n",
    "    disparity = stereo.compute(cv2.cvtColor(imgL,cv2.COLOR_BGR2GRAY), cv2.cvtColor(imgR,cv2.COLOR_BGR2GRAY)).astype(np.float32) / 16.0\n",
    "\n",
    "    return disparity\n",
    "def disparity(imgL, imgR):\n",
    "    # SGBM Parameters -----------------\n",
    "    window_size = 3                     # wsize default 3; 5; 7 for SGBM reduced size image; 15 for SGBM full size image (1300px and above); 5 Works nicely\n",
    "\n",
    "    left_matcher = cv2.StereoSGBM_create(\n",
    "        minDisparity=0,\n",
    "        numDisparities=160,             # max_disp has to be dividable by 16 f. E. HH 192, 256\n",
    "        blockSize=5,\n",
    "        P1=8 * 3 * window_size ** 2,    # wsize default 3; 5; 7 for SGBM reduced size image; 15 for SGBM full size image (1300px and above); 5 Works nicely\n",
    "        P2=32 * 3 * window_size ** 2,\n",
    "        disp12MaxDiff=1,\n",
    "        uniquenessRatio=15,\n",
    "        speckleWindowSize=0,\n",
    "        speckleRange=2,\n",
    "        preFilterCap=63,\n",
    "        mode=cv2.STEREO_SGBM_MODE_HH\n",
    "    )\n",
    "\n",
    "    right_matcher = cv2.ximgproc.createRightMatcher(left_matcher)\n",
    "\n",
    "    # FILTER Parameters\n",
    "    lmbda = 80000\n",
    "    sigma = 1.2\n",
    "    visual_multiplier = 1.0\n",
    "\n",
    "    wls_filter = cv2.ximgproc.createDisparityWLSFilter(matcher_left=left_matcher)\n",
    "    wls_filter.setLambda(lmbda)\n",
    "    wls_filter.setSigmaColor(sigma)\n",
    "\n",
    "    displ = left_matcher.compute(cv2.cvtColor(imgL,cv2.COLOR_BGR2GRAY), cv2.cvtColor(imgR, cv2.COLOR_BGR2GRAY)).astype(np.float32)/16\n",
    "    dispr = right_matcher.compute(imgR, imgL).astype(np.float32)/16\n",
    "    displ = np.int16(displ)\n",
    "    dispr = np.int16(dispr)\n",
    "    filteredImg = wls_filter.filter(displ, imgL, None, dispr)  # important to put \"imgL\" here!!!\n",
    "    filteredImg = cv2.normalize(src=filteredImg, dst=filteredImg, beta=0, alpha=255, norm_type=cv2.NORM_MINMAX);\n",
    "    filteredImg = np.uint8(filteredImg)\n",
    "   \n",
    "    return filteredImg\n",
    "    \n",
    "#     return stereo.compute(left_image, right_image).astype(np.float32) / 16.0\n",
    "\n",
    "def load_parameters(path):\n",
    "    with h5py.File(path+\"/Calibration/stereo_mapping.h5py\",\"r\") as hdf:\n",
    "        mapx1 = np.array(hdf[\"stereo_mapping/mapx1\"])\n",
    "        mapy1 = np.array(hdf[\"stereo_mapping/mapy1\"])\n",
    "        mapx2 = np.array(hdf[\"stereo_mapping/mapx2\"])\n",
    "        mapy2 = np.array(hdf[\"stereo_mapping/mapy2\"])\n",
    "        roi1 = np.array(hdf[\"stereo_mapping/roi1\"])\n",
    "        roi2 = np.array(hdf[\"stereo_mapping/roi2\"])\n",
    "        \n",
    "    with h5py.File(cal_path+\"/Calibration/Stereo_rectify.h5py\",\"r\") as hdf:\n",
    "        Q = np.array(hdf[\"Stereo_rectify/Q\"])\n",
    "        \n",
    "    return (mapx1, mapy1, mapx2, mapy2, roi1, roi2, Q)\n",
    "\n",
    "def depth(disp, q):\n",
    "    points = cv2.reprojectImageTo3D(disp, q)\n",
    "    #Z = np.array(points[:,:,2])\n",
    "    #dep = (1448.9 * 13)*(1 / disp)\n",
    "#     colors = image.reshape(-1, 3)\n",
    "    return points[:,:,2]#dep #remove_invalid(disp.reshape(-1), points, colors) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cal_path = \"/media/sansii/Software/san_projects/Major_project\"\n",
    "_geom='1024x800'\n",
    "\n",
    "global disp\n",
    "def toggle_geom(event):\n",
    "    geom=master.winfo_geometry()\n",
    "    master.geometry(_geom)\n",
    "    _geom=geom\n",
    "    \n",
    "def line_select_callback(clk ,rls):\n",
    "  \n",
    "    global x_top, x_bottom ,y_top,y_bottom\n",
    "    global disp\n",
    "    \n",
    "    (x_top, y_top) = (int(clk.xdata), int(clk.ydata))\n",
    "    (x_bottom, y_bottom) = (int(rls.xdata), int(rls.ydata))\n",
    "    \n",
    "    print(x_top, y_top,end=\"\\r\")\n",
    "    print(x_bottom, y_bottom,end=\"\\r\")\n",
    "    \n",
    "    Z = depth(disp,Q)\n",
    "    print(Z[y_top:y_bottom, x_top : x_bottom],end = \"\\r\")\n",
    "    \n",
    "def toggle_selector(event):\n",
    "    toggle_selector.RS.set_active(True)\n",
    "\n",
    "def onclick(event):\n",
    "    print('%s click: button=%d, x=%d, y=%d, xdata=%f, ydata=%f' %\n",
    "          ('double' if event.dblclick else 'single', event.button,\n",
    "           event.x, event.y, event.xdata, event.ydata))\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "master=Tk() \n",
    "\n",
    "pad=3\n",
    "master.geometry(\"{0}x{1}+0+0\".format( master.winfo_screenwidth()-pad, master.winfo_screenheight()-pad))\n",
    "\n",
    "master.bind('<Escape>', toggle_geom)\n",
    "master.title(\"Stereo Vision\")\n",
    "canvas = Canvas(master, width = master.winfo_screenwidth(),height = master.winfo_screenheight(), bg = \"blue\") \n",
    "gs = gridspec.GridSpec(2,2)\n",
    "fig = plt.figure(figsize = (30,28))  \n",
    "ax0 = fig.add_subplot(gs[0])# for ECG\n",
    "ax1 = fig.add_subplot(gs[1])\n",
    "ax2 = fig.add_subplot(gs[2])\n",
    "ax3 = fig.add_subplot(gs[3])\n",
    "#fig.canvas.mpl_connect('button_press_event', onclick)\n",
    "# figure, ax = plt.subplots(figsize=(19,9))\n",
    "# figure.show()\n",
    "mapx1, mapy1, mapx2, mapy2, roi1, roi2, Q = load_parameters(cal_path)\n",
    "Width = 1280\n",
    "Height = 720\n",
    "#Camera setting for webcam 1 and 2\n",
    "capL = cv2.VideoCapture(2)\n",
    "capR = cv2.VideoCapture(1)\n",
    "if (capL.isOpened()):\n",
    "    print(\"opened capL video device\")\n",
    "    \n",
    "if (capR.isOpened()):\n",
    "     print(\"opened capR video device\")\n",
    "\n",
    "# #Set Resolution of camera 1\n",
    "capL.set(cv2.CAP_PROP_FRAME_WIDTH, Width)\n",
    "capL.set(cv2.CAP_PROP_FRAME_HEIGHT, Height)\n",
    "\n",
    "\n",
    "# #Set Resolution of camera 2 \n",
    "capR.set(cv2.CAP_PROP_FRAME_WIDTH, Width)\n",
    "capR.set(cv2.CAP_PROP_FRAME_HEIGHT,Height)\n",
    "san = FigureCanvasTkAgg(fig, master=master)\n",
    "san.draw()\n",
    "san.get_tk_widget().pack()\n",
    "a = True\n",
    "while True:\n",
    "    retL, frameL  = capL.read(cv2.IMREAD_COLOR)\n",
    "    retR, frameR  = capR.read(cv2.IMREAD_COLOR)\n",
    "    \n",
    "    img_rect1 = cv2.remap(frameL, mapx1, mapy1, cv2.INTER_LINEAR)\n",
    "    img_rect2 = cv2.remap(frameR, mapx2, mapy2, cv2.INTER_LINEAR)\n",
    "\n",
    "    #x1,y1,w1,h1 = roi1\n",
    "\n",
    "    x2,y2,w2,h2 = roi2\n",
    "    img_rect1 = img_rect1[y2:y2+h2, x2:x2+w2]\n",
    "    img_rect2 = img_rect2[y2:y2+h2, x2:x2+w2]\n",
    "    \n",
    "    img_rect = cv2.hconcat([img_rect1, img_rect2 ])\n",
    "    thickness = 1\n",
    "    color = (0, 255, 0) \n",
    "    y = 0\n",
    "    for i in range(15):\n",
    "        start_point = (0, y)\n",
    "        end_point = (2560, y) \n",
    "        y += 50\n",
    "\n",
    "        image = cv2.line(img_rect, start_point, end_point, color, thickness) \n",
    "        \n",
    "    disp = disparity(img_rect1, img_rect2)\n",
    "    Z = depth(disp,Q)\n",
    "    Z = Z / 1000\n",
    "    Z = Z * (Z < 4)\n",
    "    posd = ax2.imshow(disp, cmap ='jet')\n",
    "    posD = ax3.imshow(Z, cmap ='jet')\n",
    "    if a == True:\n",
    "        \n",
    "        cbard = fig.colorbar(posd, ax=ax2, orientation=\"vertical\")\n",
    "        cbard.set_label('Disparity pixels', rotation=90)\n",
    "        \n",
    "        cbarD = fig.colorbar(posD, ax=ax3, orientation=\"vertical\")\n",
    "        cbarD.set_label('Meter(m)', rotation=90)\n",
    "        a= False\n",
    "\n",
    "    \n",
    "    ax0.imshow(img_rect1)\n",
    "    ax1.imshow(img_rect2,cmap='jet')\n",
    "    fig.canvas.draw()   \n",
    "    \n",
    "master.mainloop()\n",
    "capL.release()\n",
    "capR.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "capL.release()\n",
    "capR.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cal_path = \"/media/sansii/Software/san_projects/Major_project\"\n",
    "dim = (1280, 720)\n",
    "img_l = cv2.imread(cal_path+\"/Stereo_images/Left/\"+str(0)+\".jpg\")\n",
    "img_r = cv2.imread(cal_path+\"/Stereo_images/Right/\"+str(0)+\".jpg\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "mapx1, mapy1, mapx2, mapy2, roi1, roi2, Q = load_parameters(cal_path)\n",
    "\n",
    "# remap\n",
    "img_rect1 = cv2.remap(img_l, mapx1, mapy1, cv2.INTER_LINEAR)\n",
    "img_rect2 = cv2.remap(img_r, mapx2, mapy2, cv2.INTER_LINEAR)\n",
    "x2,y2,w2,h2 = roi2\n",
    "print(roi1)\n",
    "print(roi2)\n",
    "img_rect1 = img_rect1[y2:y2+h2, x2:x2+w2]\n",
    "img_rect2 = img_rect2[y2:y2+h2, x2:x2+w2]\n",
    "\n",
    "# img_l = img_l[y2:y2+h2, x2:x2+w2]\n",
    "# img_r = img_r[y2:y2+h2, x2:x2+w2]\n",
    "\n",
    "# L_resized = cv2.resize(img_rect1, dim, interpolation = cv2.INTER_AREA)\n",
    "# R_resized = cv2.resize(img_rect2, dim, interpolation = cv2.INTER_AREA)\n",
    "\n",
    "concat_rec = cv2.hconcat([img_rect1, img_rect2])\n",
    "concat_unrec = cv2.hconcat([img_l, img_r])\n",
    "disparity = find_disparity(img_l, img_r);\n",
    "#points = calc_point_cloud(img_rect1, disparity, Q)\n",
    "#print(points[0][10][2])\n",
    "#colour.reshape(img_rect1.shape)\n",
    "fig, ax = plt.subplots(figsize=(16,9))\n",
    "ax.imshow(disparity, cmap ='jet')\n",
    "fig.show()\n",
    "#fig.show()\n",
    "# print(disparity.max())\n",
    "thickness = 1\n",
    "color = (0, 255, 0) \n",
    "y = 0\n",
    "for i in range(15):\n",
    "    start_point = (0, y)\n",
    "    end_point = (2560, y) \n",
    "    y += 50\n",
    "\n",
    "    image = cv2.line(concat_rec, start_point, end_point, color, thickness) \n",
    "    image = cv2.line(concat_unrec, start_point, end_point, color, thickness) \n",
    "    \n",
    "cv2.imwrite(\"left.jpg\",img_rect1)\n",
    "cv2.imwrite(\"Right.jpg\",img_rect2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = cv2.imread(\"/media/sansii/Software/san_projects/Major_project/semi-global-matching/left_disparity_map.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(c,cmap='jet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code is has a filter which takes displ and disp right into account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import normalize\n",
    "import cv2\n",
    "print(cv2.__version__)\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib\n",
    "def load_parameters(path):\n",
    "    with h5py.File(path+\"/Calibration/stereo_mapping.h5py\",\"r\") as hdf:\n",
    "        mapx1 = np.array(hdf[\"stereo_mapping/mapx1\"])\n",
    "        mapy1 = np.array(hdf[\"stereo_mapping/mapy1\"])\n",
    "        mapx2 = np.array(hdf[\"stereo_mapping/mapx2\"])\n",
    "        mapy2 = np.array(hdf[\"stereo_mapping/mapy2\"])\n",
    "        roi1 = np.array(hdf[\"stereo_mapping/roi1\"])\n",
    "        roi2 = np.array(hdf[\"stereo_mapping/roi2\"])\n",
    "        \n",
    "    with h5py.File(cal_path+\"/Calibration/Stereo_rectify.h5py\",\"r\") as hdf:\n",
    "        Q = np.array(hdf[\"Stereo_rectify/Q\"])\n",
    "        \n",
    "    return (mapx1, mapy1, mapx2, mapy2, roi1, roi2, Q)\n",
    "\n",
    "def find_disparity(imgL, imgR):\n",
    "    # disparity range is tuned for 'aloe' image pair\n",
    "    window_size = 3\n",
    "    min_disp = 0\n",
    "    num_disp = 160\n",
    "    stereo = cv2.StereoSGBM_create(minDisparity = min_disp,\n",
    "        numDisparities = num_disp,\n",
    "        blockSize = 16,\n",
    "        P1 = 8*3*window_size**2,\n",
    "        P2 = 32*3*window_size**2,\n",
    "        disp12MaxDiff = 1,\n",
    "        uniquenessRatio = 10,\n",
    "        speckleWindowSize = 100,\n",
    "        speckleRange = 32,\n",
    "        mode=cv2.STEREO_SGBM_MODE_HH\n",
    "           \n",
    "    )\n",
    "    \n",
    "    disparity = stereo.compute(cv2.cvtColor(imgL,cv2.COLOR_BGR2GRAY), cv2.cvtColor(imgR,cv2.COLOR_BGR2GRAY)).astype(np.float32) / 16.0\n",
    "    #disparity = cv2.normalize(src=disparity, dst=disparity, beta=0, alpha=255, norm_type=cv2.NORM_MINMAX);\n",
    "    #disparity = np.uint8(disparity)\n",
    "\n",
    "    return disparity\n",
    "\n",
    "cal_path = \"/media/sansii/Software/san_projects/Major_project\"\n",
    "dim = (1280, 720)\n",
    "img_l = cv2.imread(cal_path+\"/Stereo_images/Left/\"+str(0)+\".jpg\")\n",
    "img_r = cv2.imread(cal_path+\"/Stereo_images/Right/\"+str(0)+\".jpg\")\n",
    "\n",
    "mapx1, mapy1, mapx2, mapy2, roi1, roi2, Q = load_parameters(cal_path)\n",
    "\n",
    "# remap\n",
    "img_rect1 = cv2.remap(img_l, mapx1, mapy1, cv2.INTER_LINEAR)\n",
    "img_rect2 = cv2.remap(img_r, mapx2, mapy2, cv2.INTER_LINEAR)\n",
    "x2,y2,w2,h2 = roi2\n",
    "\n",
    "imgL = img_rect1[y2:y2+h2, x2:x2+w2]\n",
    "imgR = img_rect2[y2:y2+h2, x2:x2+w2]\n",
    "\n",
    "def disparity(imgL, imgR):\n",
    "    # SGBM Parameters -----------------\n",
    "    window_size = 3                     # wsize default 3; 5; 7 for SGBM reduced size image; 15 for SGBM full size image (1300px and above); 5 Works nicely\n",
    "\n",
    "    left_matcher = cv2.StereoSGBM_create(\n",
    "        minDisparity=0,\n",
    "        numDisparities=160,             # max_disp has to be dividable by 16 f. E. HH 192, 256\n",
    "        blockSize=5,\n",
    "        P1=8 * 3 * window_size ** 2,    # wsize default 3; 5; 7 for SGBM reduced size image; 15 for SGBM full size image (1300px and above); 5 Works nicely\n",
    "        P2=32 * 3 * window_size ** 2,\n",
    "        disp12MaxDiff=1,\n",
    "        uniquenessRatio=15,\n",
    "        speckleWindowSize=0,\n",
    "        speckleRange=2,\n",
    "        preFilterCap=63,\n",
    "        mode=cv2.STEREO_SGBM_MODE_HH\n",
    "    )\n",
    "\n",
    "    right_matcher = cv2.ximgproc.createRightMatcher(left_matcher)\n",
    "\n",
    "    # FILTER Parameters\n",
    "    lmbda = 80000\n",
    "    sigma = 1.2\n",
    "    visual_multiplier = 1.0\n",
    "\n",
    "    wls_filter = cv2.ximgproc.createDisparityWLSFilter(matcher_left=left_matcher)\n",
    "    wls_filter.setLambda(lmbda)\n",
    "    wls_filter.setSigmaColor(sigma)\n",
    "\n",
    "    displ = left_matcher.compute(cv2.cvtColor(imgL,cv2.COLOR_BGR2GRAY), cv2.cvtColor(imgR,cv2.COLOR_BGR2GRAY))#.astype(np.float32) / 16  # .astype(np.float32)/16\n",
    "    dispr = right_matcher.compute(imgR, imgL)#.astype(np.float32)/16\n",
    "    displ = np.int16(displ)\n",
    "    dispr = np.int16(dispr)\n",
    "    filteredImg = wls_filter.filter(displ, imgL, None, dispr)  # important to put \"imgL\" here!!!\n",
    "    filteredImg = cv2.normalize(src=filteredImg, dst=filteredImg, beta=0, alpha=255, norm_type=cv2.NORM_MINMAX);\n",
    "#     filteredImg = np.uint8(filteredImg)\n",
    "   \n",
    "    return filteredImg\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disp_filt = disparity(imgL, imgR);\n",
    "disp = find_disparity(imgL,imgR);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z_filt = depth(disp_filt, Q)\n",
    "Z_unfilt = depth(disp, Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(0)\n",
    "plt.imshow(disp_filt, cmap = 'jet')\n",
    "plt.figure(1)\n",
    "plt.imshow(disp, cmap ='jet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
