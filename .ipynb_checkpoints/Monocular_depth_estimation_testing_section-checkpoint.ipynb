{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.compat.v1 as tf1\n",
    "from scipy import ndimage\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d(input_images, weight, stride = 1):\n",
    "    return tf.nn.conv2d(input_images, weight ,strides=[1,stride, stride,1], padding='VALID',name=\"conv\")\n",
    "        \n",
    "\n",
    "def conv_elu(input_layer, k, in_filter, ou_filter, stride, scope, activation = tf.nn.elu, reuse=False):\n",
    "    \n",
    "    with tf.compat.v1.variable_scope(scope, reuse = reuse):\n",
    "        W = tf.compat.v1.get_variable(\"weight\", [k, k, in_filter, ou_filter], initializer=tf1.glorot_uniform_initializer())\n",
    "        b = tf.compat.v1.get_variable(\"biases\", [ou_filter],initializer=tf1.glorot_uniform_initializer())\n",
    "        \n",
    "        #we need pyrimad which output is half of its input so, need to pad input.\n",
    "        p = np.floor((k - 1) / 2).astype('int32')\n",
    "        padding = tf.constant([[0,0],[p, p],[p, p],[0,0]])\n",
    "        p_x = tf.pad(input_layer, padding)\n",
    "        \n",
    "        #padded input\n",
    "        conv = conv2d(p_x, W, stride = stride)\n",
    "        output = tf.nn.bias_add(conv, b)\n",
    "        out = activation(output)\n",
    "        \n",
    "    return out\n",
    "\n",
    "\n",
    "def upsampling(input_layer, factor):    \n",
    "    return tf.keras.layers.UpSampling2D(size=(factor, factor))(input_layer)\n",
    "    \n",
    "             \n",
    "\n",
    "def upconv(input_layer, k, in_filter, ou_filter, scope, reuse=False):\n",
    "    \n",
    "    with tf.compat.v1.variable_scope(scope, reuse = reuse):    \n",
    "        #Upsampling\n",
    "        upsample = upsampling(input_layer, 2)\n",
    "        out = conv_elu(upsample, k, in_filter, ou_filter, 1, scope='conv_elu')\n",
    "        return out\n",
    "\n",
    "\n",
    "def conv_block(input_layer, k, in_filter, ou_filter, scope):\n",
    "    \n",
    "    c1 = conv_elu(input_layer, k,  in_filter, ou_filter,  1, scope=scope )\n",
    "    c2 = conv_elu(c1,          k,  ou_filter, ou_filter,  2, scope=scope+'b')\n",
    "    \n",
    "    return c2\n",
    "    \n",
    "def get_disp(x, in_filter,scope):\n",
    "    disp = 0.3 * conv_elu(x, 3, in_filter, 2, 1, scope = scope, activation = tf.nn.sigmoid)\n",
    "    return disp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_placeholder():\n",
    "    \n",
    "    tf1.disable_eager_execution()\n",
    "    tf1.reset_default_graph()\n",
    "    \n",
    "    with tf1.name_scope(\"Input_image\"):\n",
    "        input_layer = tf1.placeholder('float', shape = input_shape)\n",
    "        \n",
    "    return input_layer\n",
    "\n",
    "\n",
    "def make_architecture(input_layers):\n",
    "    \n",
    "    with tf1.name_scope(\"ENCNN\"):\n",
    "    \n",
    "        with tf1.name_scope(\"encoder\"):\n",
    "            conv1 = conv_block(input_layers, 7,  3,  32, 'conv1')#2\n",
    "            conv2 = conv_block(conv1,        5, 32,  64, 'conv2')#4\n",
    "            conv3 = conv_block(conv2,        3, 64, 128, 'conv3')#8\n",
    "            conv4 = conv_block(conv3,        3, 128,256, 'conv4')#16\n",
    "            conv5 = conv_block(conv4,        3, 256,512, 'conv5')#32\n",
    "                conv6 = conv_block(conv5,        3, 512,512, 'conv6')#64\n",
    "            conv7 = conv_block(conv6,        3, 512,512, 'conv7')#128\n",
    "            \n",
    "            \n",
    "            \n",
    "\n",
    "\n",
    "        with tf1.name_scope(\"decoder\"):\n",
    "            #upsampling 7\n",
    "            upconv7 = upconv(conv7,     3,  512,  512, scope =  'upconv7')\n",
    "            concat7 = tf.concat([upconv7, conv6], axis=-1, name = 'concat7')\n",
    "            iconv7  = conv_elu(concat7, 3, 1024,  512, 1, scope= 'iconv7')\n",
    "\n",
    "            #upsampling 6\n",
    "            upconv6 = upconv(iconv7,    3,  512,  512, scope =  'upconv6')\n",
    "            concat6 = tf.concat([upconv6, conv5], axis=-1, name = 'concat6')\n",
    "            iconv6  = conv_elu(concat6, 3, 1024,  512, 1, scope= 'iconv6')\n",
    "\n",
    "            #upsampling 5\n",
    "            upconv5 = upconv(iconv6,    3,  512,  256, scope =  'upconv5')\n",
    "            concat5 = tf.concat([upconv5, conv4], axis=-1, name= 'concat5')\n",
    "            iconv5  = conv_elu(concat5, 3,  512,  256, 1, scope= 'iconv5')\n",
    "\n",
    "            #upsampling 4\n",
    "            upconv4 = upconv(iconv5,    3,   256,  128, scope = 'upconv4')\n",
    "            concat4 = tf.concat([upconv4, conv3], axis=-1, name ='concat4')\n",
    "            iconv4  = conv_elu(concat4, 3, 256,  128, 1, scope= 'iconv4')\n",
    "            disp4   = get_disp(iconv4, 128, scope= 'disp4')\n",
    "            updisp4 = upsampling(disp4, 2)\n",
    "\n",
    "            #upsampling 3\n",
    "            upconv3 = upconv(iconv4,    3,  128,  64, scope = 'upconv3')\n",
    "            concat3 = tf.concat([upconv3, conv2, updisp4], axis=-1, name='concat3')\n",
    "            iconv3  = conv_elu(concat3, 3, 130,  64, 1, scope= 'iconv3')\n",
    "            disp3   = get_disp(iconv3,  64, scope = 'disp3')\n",
    "            updisp3 = upsampling(disp3, 2)\n",
    "\n",
    "            #upsampling 2\n",
    "            upconv2 = upconv(iconv3,    3,  64,   32, scope = 'upconv2')\n",
    "            concat2 = tf.concat([upconv2, conv1, updisp3], axis=-1, name='concat2')\n",
    "            iconv2  = conv_elu(concat2, 3,  66,   32, 1, scope= 'iconv2')\n",
    "            disp2   = get_disp(iconv2,  32, scope = 'disp2')\n",
    "            updisp2 = upsampling(disp2, 2)\n",
    "\n",
    "            #upsampling 1\n",
    "            upconv1 = upconv(iconv2,    3,  32,   16, scope = 'upconv1')\n",
    "            concat1 = tf.concat([upconv1, updisp2], axis=-1, name='convat1')\n",
    "            iconv1  = conv_elu(concat1, 3,  18,   16, 1, scope= 'iconv1')\n",
    "            disp1   = get_disp(iconv1,  16, scope = 'disp1')\n",
    "        \n",
    "    return disp1, disp2, disp3 ,disp4\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_input_image):\n",
    "    logdir = '/media/sansii/Software/san_projects/Major_project/Moncular_depth_estimation_data/'\n",
    "    input_layer = init_placeholder()\n",
    "    \n",
    "    disp1, disp2, disp3 , disp4 = make_architecture(input_layer)\n",
    "    \n",
    "    writer = tf1.summary.FileWriter(logdir+'./graph' , graph=tf1.get_default_graph())\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "img_h = 256\n",
    "img_w = 512\n",
    "input_shape = [batch_size, img_h, img_w, 3]\n",
    "train(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Testing Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf1.disable_eager_execution()\n",
    "tf1.reset_default_graph()\n",
    "n_filters = 64\n",
    "n_channels = 3\n",
    "kernel_shape = [7, 7, n_channels,n_filters]\n",
    "bias_shape = [n_filters]\n",
    "W = tf.compat.v1.get_variable(\"weight\", kernel_shape, initializer=tf1.glorot_uniform_initializer())\n",
    "data_path = '/media/sansii/Software/san_projects/Major_project/KITTI_dataset/2015/testing/'\n",
    "left = ndimage.imread(data_path+\"image_2/000083_10.png\")\n",
    "\n",
    "left_shape = (1, left.shape[0], left.shape[1], 3)\n",
    "input_layer  = tf.compat.v1.placeholder(tf.float32, left_shape,  name='image_left' )\n",
    "p = np.floor((kernel_shape[0] - 1) / 2).astype('int32')\n",
    "padding = tf.constant([[0,0],[p, p],[p, p],[0,0]])\n",
    "p_x = tf.pad(input_layer, padding)\n",
    "conv = conv2d(p_x, W, stride = 2)\n",
    "conv = tf.nn.elu(conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = tf1.global_variables_initializer()\n",
    "with tf1.Session() as sess:\n",
    "    sess.run(var)\n",
    "    left_ = left[np.newaxis,...]\n",
    "    print(left_.shape)\n",
    "    out = sess.run(conv, feed_dict={input_layer: left_})\n",
    "   \n",
    "    print(out.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset_selective conv2d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class STN:\n",
    "    def interpolate(self, img, x, y):\n",
    "        #bilinear_interpolation\n",
    "\n",
    "        #For corner pixel there is no either left or right / top or down pixels so padding is necessary\n",
    "        img = tf.pad(img, paddings= ((0,0),(1,1),(1,1),(0,0)))\n",
    "        \n",
    "        x = tf.clip_by_value(x, 0.0, tf.cast(self.width,tf.float32)+1.0)\n",
    "\n",
    "        #since we have padded we need to add plus 1 for our transformed coordinates\n",
    "        x = x + 1\n",
    "        y = y + 1\n",
    "\n",
    "        #since the values are in fraction we need to take floor value which selects left pixels\n",
    "        x_float   = tf.floor(x)\n",
    "        y_float   = tf.floor(y)\n",
    "        x_1_float = x_float + 1\n",
    "        \n",
    "        x_1_float = tf.minimum(x_1_float, tf.cast(self.width,tf.float32)+1.0 )\n",
    "        \n",
    "        #Since,the index are in integer we convert float into integer\n",
    "        x_int = tf.cast(x_float, tf.int32)\n",
    "        y_int = tf.cast(y_float, tf.int32)\n",
    "        x_1_int = tf.cast(x_1_float, tf.int32)\n",
    "        \n",
    "        #we required total dimention for reshaping \n",
    "        dim_y  = self.width + 2 * 1#padding\n",
    "        dim_xy = (self.width + 2) * (self.height + 2)\n",
    "\n",
    "        #There are number of images with there individual coordinate space now we need to convert\n",
    "        #individual coordinate space into a single coordinate space\n",
    "        #eg: x = [ [0,1,2,3], [0,1,2,3], [0,1,2,3]] \n",
    "        # y= [[0,0,0,0],[1,1,1,1],[2,2,2,2]]into [0 ,1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
    "        #Converting 2d spatial dimention into 1d vector\n",
    "        \n",
    "        base = tf.tile(tf.expand_dims(tf.range(self.num_batches),1) * dim_xy, [1, self.width * self.height])\n",
    "        base = tf.reshape(base, [-1])\n",
    "    \n",
    "        x_l = x_int   + (base + y_int * dim_y)\n",
    "        x_r = x_1_int + (base + y_int * dim_y)\n",
    "        \n",
    "        print(x_l.numpy())\n",
    "        #Flattering input image\n",
    "        img_flat = tf.reshape(img, [-1, self.num_channels]) \n",
    "        \n",
    "        #tf.gather selects pixels of img from coordinate x_l and x_r\n",
    "        #Therefore pixel_l and pixel_r contains only selected coordinates pixels from img\n",
    "        pixel_l = tf.gather(img_flat, x_l)\n",
    "        pixel_r = tf.gather(img_flat, x_r)\n",
    "        \n",
    "        #Now for bilinear interpolation each left and right pixel must be associated with its respective weights.\n",
    "        weights_l = tf.expand_dims(x - x_float, 1)\n",
    "        weights_r = tf.expand_dims(x_1_float - x, 1)\n",
    "        \n",
    "        print(\"Weight\", weights_l.shape)\n",
    "        print(\"pixel_l\", pixel_l.shape)\n",
    "        \n",
    "        out = (weights_l * pixel_l) + (weights_r * pixel_r)\n",
    "\n",
    "        return tf.reshape(out, [self.num_batches, self.height, self.width, self.num_channels])\n",
    "\n",
    "    def bilinear_sampling(self, img, disparity):\n",
    "        self.img = img\n",
    "        self.width       = tf.shape(img)[2]\n",
    "        self.height      = tf.shape(img)[1]\n",
    "        self.num_batches = tf.shape(img)[0]\n",
    "        self.num_channels= tf.shape(img)[3]\n",
    "\n",
    "        width_f =  tf.cast(self.width , tf.float32)\n",
    "        height_f = tf.cast(self.height, tf.float32)\n",
    "\n",
    "        #Creating meshgrid which contains represents coordinates(x, y) of images\n",
    "        x_grid, y_grid = tf.cast(tf.meshgrid(tf.range(self.width), \n",
    "                                     tf.range(self.height)), tf.float32)\n",
    "\n",
    "        #Flatterning grids\n",
    "        x_flat = tf.reshape(x_grid, [-1])\n",
    "        y_flat = tf.reshape(y_grid, [-1])\n",
    "\n",
    "        #Since, there are num_batches so we need to add up grids for all batches\n",
    "        x_flat = tf.tile(x_flat, [self.num_batches])\n",
    "        y_flat = tf.tile(y_flat, [self.num_batches])\n",
    "\n",
    "        #Flatterning disparity size = (num_batches * weight * height)\n",
    "        disparity_flat = tf.reshape(disparity, [-1])\n",
    "\n",
    "        #Adding disparity to find / applying transformation\n",
    "        x_transf = x_flat + (disparity_flat * width_f) #Since the out of sigmoid funtion in 0 -1 so we muliply with width\n",
    "\n",
    "        #Transformed coordinates are in fraction since, there is no fraction pixel so we interplate\n",
    "        out = self.interpolate(img, x_transf, y_flat)\n",
    "\n",
    "\n",
    "\n",
    "        return out\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 9  9 12 12 12 14 17 24 17 24 17 24 27 25 32 25 32 28 49 51 49 49 54 56\n",
      " 57 61 64 64 57 57 65 72 67 65 65 65]\n",
      "Weight (36, 1)\n",
      "pixel_l (36, 1)\n"
     ]
    }
   ],
   "source": [
    "stn = STN()\n",
    "a = np.random.randint(0, 10 , size =(2,3,6,1))\n",
    "b = np.random.randn(2,3,6)\n",
    "img = tf.constant(a)\n",
    "disparity = tf.constant(b)\n",
    "img = tf.cast(img, tf.float32)\n",
    "disparity = tf.cast(disparity, tf.float32)\n",
    "out = stn.bilinear_sampling(img, disparity)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0. 1. 2.]\n",
      " [0. 1. 2.]\n",
      " [0. 1. 2.]], shape=(3, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "x_grid, y_grid = tf.cast(tf.meshgrid(tf.range(3), \n",
    "                                 tf.range(3)), tf.float32)\n",
    "print(x_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SSIM(image, pred_image, block_size):\n",
    "    \n",
    "    C1 = 0.01 ** 2\n",
    "    C2 = 0.03 ** 2\n",
    "    \n",
    "    u_x = tf.nn.avg_pool2d(image      ,block_size, strides=1, padding='SAME')\n",
    "    u_y = tf.nn.avg_pool2d(pred_image ,block_size, strides=1, padding='SAME')\n",
    "\n",
    "    sigma_x  = tf.nn.avg_pool2d(image**2           ,block_size, strides=1, padding='SAME') - u_x**2\n",
    "    sigma_y  = tf.nn.avg_pool2d(pred_image**2      ,block_size, strides=1, padding='SAME') - u_y**2\n",
    "    sigma_xy = tf.nn.avg_pool2d(image * pred_image ,block_size, strides=1, padding='SAME') - u_x * u_y\n",
    "    \n",
    "    SSIM_num = ((2 * u_x * u_y + C1)   * (2 * sigma_x * sigma_y   + C2)) \n",
    "    SSIM_den = ((u_x**2 + u_y**2 + C1) * (sigma_x**2 + sigma_y**2 + C2))\n",
    "    \n",
    "    SSIM = SSIM_num / SSIM_den\n",
    "    \n",
    "    return tf.clip_by_value((1 - SSIM) / 2, 0, 1)\n",
    "\n",
    "def apperance_matching_loss(image, pred_image):\n",
    "    alpha = 0.85\n",
    "    L1_error = tf.abs(image - pred_image)\n",
    "    ssim_error = SSIM(image, pred_image, 3)\n",
    "    \n",
    "    C_ap = tf.reduce_mean((alpha * ssim_error + (1 - alpha) * L1_error))\n",
    "    \n",
    "    return apperance_matching_loss\n",
    "\n",
    "\n",
    "def disparity_smoothness_loss(disp, image):\n",
    "    \n",
    "    disp_gradient_y , disp_gradient_x  = tf.image.image_gradients(disp)\n",
    "    image_gradient_y, image_gradient_x = tf.image.image_gradients(image)\n",
    "\n",
    "    im_dx = -tf.reduce_mean(tf.abs(image_gradient_x),axis=-1, keepdims=True)\n",
    "    im_dy = -tf.reduce_mean(tf.abs(image_gradient_y),axis=-1, keepdims=True)\n",
    "    \n",
    "    loss_dx = tf.multiply(tf.abs(disp_gradient_x), tf.math.exp(im_dx))\n",
    "    loss_dy = tf.multiply(tf.abs(disp_gradient_y), tf.math.exp(im_dy))\n",
    "    \n",
    "    disp_smoothness_loss = tf.reduce_mean((loss_dx + loss_dy))\n",
    "    \n",
    "    \n",
    "    return disp_smoothness_loss\n",
    "\n",
    "\n",
    "def left_right_consistency_loss(disp_left, disp_right):\n",
    "    \n",
    "     \n",
    "        \n",
    "\n",
    "\n",
    "def training_loss(image, pred_image):\n",
    "    #Apperance Loss\n",
    "    alpha = 0.85\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = tf.constant([[1., 2,  3], [4,  5,  6]])\n",
    "t2 = tf.clip_by_value(t, clip_value_min=-1, clip_value_max=1)\n",
    "\n",
    "exp = tf.math.exp(t)\n",
    "with tf1.Session() as sess:\n",
    "    e = sess.run(exp)\n",
    "    print(e)\n",
    "    \n",
    "t2.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1\n",
    "IMAGE_HEIGHT = 5\n",
    "IMAGE_WIDTH = 5\n",
    "CHANNELS = 1\n",
    "image = tf.reshape(tf.range(IMAGE_HEIGHT * IMAGE_WIDTH * CHANNELS,\n",
    "  delta=1, dtype=tf.float32),\n",
    "  shape=(BATCH_SIZE, IMAGE_HEIGHT, IMAGE_WIDTH, CHANNELS))\n",
    "dx, dy = tf.image.image_gradients(image)\n",
    "exp = \n",
    "with tf1.Session() as sess:\n",
    "    d_y, d_x = sess.run([dx, dy])\n",
    "    print(d_y)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dCost_dW.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Comparision_Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def disparity_smoothness_loss(disp, image):\n",
    "    \n",
    "    disp_gradient_y , disp_gradient_x  = tf.image.image_gradients(disp)\n",
    "    image_gradient_y, image_gradient_x = tf.image.image_gradients(image)\n",
    "\n",
    "    im_dx = -tf.reduce_mean(tf.abs(image_gradient_x),axis=-1, keepdims=True)\n",
    "    im_dy = -tf.reduce_mean(tf.abs(image_gradient_y),axis=-1, keepdims=True)\n",
    "    \n",
    "    loss_dx = tf.multiply(tf.abs(disp_gradient_x), tf.math.exp(im_dx))\n",
    "    loss_dy = tf.multiply(tf.abs(disp_gradient_y), tf.math.exp(im_dy))\n",
    "    \n",
    "    disp_smoothness_loss = tf.reduce_mean((loss_dx + loss_dy))\n",
    "    \n",
    "    \n",
    "    return disp_smoothness_loss, loss_dx, loss_dy\n",
    "\n",
    "\n",
    "class smoothness_losses:\n",
    "    \n",
    "    def gradient_x(self, img):\n",
    "        gx = img[:,:,:-1,:] - img[:,:,1:,:]\n",
    "        return tf.pad(gx,paddings = ((0,0),(0,0),(0,1),(0,0)))\n",
    "\n",
    "    def gradient_y(self, img):\n",
    "        gy = img[:,:-1,:,:] - img[:,1:,:,:]\n",
    "        return tf.pad(gy,paddings=((0,0),(0,1),(0,0),(0,0)))\n",
    "\n",
    "    def get_disparity_smoothness(self, disp, pyramid):\n",
    "        disp_gradients_x = [self.gradient_x(d) for d in disp]\n",
    "        disp_gradients_y = [self.gradient_y(d) for d in disp]\n",
    "\n",
    "        image_gradients_x = [self.gradient_x(img) for img in pyramid]\n",
    "        image_gradients_y = [self.gradient_y(img) for img in pyramid]\n",
    "\n",
    "        weights_x = [tf.exp(-tf.reduce_mean(tf.abs(g), 3, keepdims=True)) for g in image_gradients_x]\n",
    "        weights_y = [tf.exp(-tf.reduce_mean(tf.abs(g), 3, keepdims=True)) for g in image_gradients_y]\n",
    "\n",
    "        smoothness_x = [tf.abs(disp_gradients_x[i]) * weights_x[i] for i in range(1)]\n",
    "        smoothness_y = [tf.abs(disp_gradients_y[i]) * weights_y[i] for i in range(1)]\n",
    "        return tf.reduce_mean((smoothness_x[0] + smoothness_y[0])) , smoothness_x[0], smoothness_y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "paper = smoothness_losses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_disp  = np.random.randint(0, 20, size=(1, 1, 5, 10, 1))\n",
    "num_image = np.random.randint(0, 30, size=(1, 1, 5, 10, 3))\n",
    "disp  = tf.constant(num_disp,dtype=tf.float32)\n",
    "image = tf.constant(num_image, dtype=tf.float32)\n",
    "loss_smooth_ours, dx_our, dd_our = disparity_smoothness_loss(disp[0], image[0])\n",
    "loss_smooth,dx, dd                 = paper.get_disparity_smoothness(disp, image)\n",
    "\n",
    "\n",
    "print((dx_our.numpy()==\n",
    "       dx.numpy()))\n",
    "print(loss_smooth.numpy(), loss_smooth_ours.numpy())\n",
    "# with tf1.Session() as sess:\n",
    "    \n",
    "#     sess.run([loss_smooth_ours])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = np.zeros_like(num_disp)\n",
    "out[:,:,:-1,:] = num_disp[:,:,:-1,:] - num_disp[:,:,1:,:]\n",
    "print(out[:,:,-1:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_t, y_t = np.meshgrid(np.linspace(-1, 1, 5), np.linspace(-1, 1, 5))\n",
    "theta = np.array([[0.7, -0.7, 0], [0.7, 0.7, 0]])\n",
    "theta = np.array([[2, 0, 1], [0, 1, 0]])\n",
    "grid = np.array([x_t, y_t, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = np.dot(theta, grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grid)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(x_t, y_t)\n",
    "plt.axis([-3,3,-3,3])\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(out[0], out[1])\n",
    "plt.axis([-3,3,-3,3])\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.random.randint(0, 10, size =(3, 5))\n",
    "i = tf.constant(a)\n",
    "    index = [0,1]\n",
    "    out = tf.gather(i, index,axis=-1)\n",
    "    out = tf.gather(out, index, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(i)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.random.randint(0, 10, size =(2, 5, 10))\n",
    "b = np.random.randn(2, 5, 10)\n",
    "print(b.shape)\n",
    "img = tf.constant(a)\n",
    "img = tf.cast(img, tf.float32)\n",
    "x_offset = tf.constant(b)\n",
    "x_offset = tf.cast(x_offset, tf.float32)\n",
    "_height = tf.shape(img)[1]\n",
    "_width = tf.shape(img)[2]\n",
    "_height_f  = tf.cast(_height, tf.float32)\n",
    "_width_f  = tf.cast(_width,  tf.float32)\n",
    "_num_batch = tf.shape(img)[0]\n",
    "\n",
    "def _transform(input_images, x_offset):\n",
    "    with tf1.variable_scope('transform'):\n",
    "        # grid of (x_t, y_t, 1), eq (1) in ref [1]\n",
    "        x_t, y_t = tf.meshgrid(tf.linspace(0.0,   _width_f - 1.0,  _width),\n",
    "                               tf.linspace(0.0 , _height_f - 1.0 , _height))\n",
    "\n",
    "        x_t_flat = tf.reshape(x_t, (1, -1))\n",
    "        y_t_flat = tf.reshape(y_t, (1, -1))\n",
    "        \n",
    "        stack = tf.stack([_num_batch,1])\n",
    "\n",
    "        x_t_flat = tf.tile(x_t_flat, tf.stack([_num_batch, 1]))\n",
    "        y_t_flat = tf.tile(y_t_flat, tf.stack([_num_batch, 1]))\n",
    "\n",
    "        x_t_flat = tf.reshape(x_t_flat, [-1])\n",
    "        y_t_flat = tf.reshape(y_t_flat, [-1])\n",
    "        \n",
    "        print(x_t_flat.dtype)\n",
    "        print(x_offset.dtype)\n",
    "\n",
    "        #x_t_flat = x_t_flat + tf.reshape(x_offset, [-1]) * _width_f\n",
    "\n",
    "#         input_transformed = _interpolate(input_images, x_t_flat, y_t_flat)\n",
    "\n",
    "#         output = tf.reshape(\n",
    "#             input_transformed, tf.stack([_num_batch, _height, _width, _num_channels]))\n",
    "        return x_t_flat, y_t_flat, stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_t, y_t, stack = _transform(img, x_offset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = tf.tile(tf.expand_dims(tf.range(_num_batch)* (_height * _width), 1 ),[1,( _height * _width)])\n",
    "base = tf.reshape(base, [-1])\n",
    "base = tf.cast(base, tf.int32)\n",
    "y_t  = tf.cast(y_t, tf.int32)\n",
    "x_t  = tf.cast(x_t, tf.int32)\n",
    "print(base)\n",
    "print(x_t.numpy() + (base + y_t * 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.random.randint(0, 5,  size =(3, 3))\n",
    "a = [[0],[50]]\n",
    "img = tf.constant(a)\n",
    "#img = tf.reshape(img, [1,-1])\n",
    "out = tf.tile(img,[2,1])\n",
    "print(img)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack = tf.stack([_num_batch])\n",
    "print(stack.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.random.randint(0, 5,  size =(3, 3))\n",
    "img = tf.constant(a)\n",
    "img = tf.reshape(img,[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
