{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.compat.v1 as tf1\n",
    "from scipy import ndimage\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d(input_images, weight, stride = 1):\n",
    "    return tf.nn.conv2d(input_images, weight ,strides=[1,stride, stride,1], padding='VALID',name=\"conv\")\n",
    "        \n",
    "\n",
    "def conv_elu(input_layer, k, in_filter, ou_filter, stride, scope, activation = tf.nn.elu, reuse=False):\n",
    "    \n",
    "    with tf.compat.v1.variable_scope(scope, reuse = reuse):\n",
    "        W = tf.compat.v1.get_variable(\"weight\", [k, k, in_filter, ou_filter], initializer=tf1.glorot_uniform_initializer())\n",
    "        b = tf.compat.v1.get_variable(\"biases\", [ou_filter],initializer=tf1.glorot_uniform_initializer())\n",
    "        \n",
    "        #we need pyrimad which output is half of its input so, need to pad input.\n",
    "        p = np.floor((k - 1) / 2).astype('int32')\n",
    "        padding = tf.constant([[0,0],[p, p],[p, p],[0,0]])\n",
    "        p_x = tf.pad(input_layer, padding)\n",
    "        \n",
    "        #padded input\n",
    "        conv = conv2d(p_x, W, stride = stride)\n",
    "        output = tf.nn.bias_add(conv, b)\n",
    "        out = activation(output)\n",
    "        \n",
    "    return out\n",
    "\n",
    "\n",
    "def upsampling(input_layer, factor):    \n",
    "    return tf.keras.layers.UpSampling2D(size=(factor, factor))(input_layer)\n",
    "    \n",
    "             \n",
    "\n",
    "def upconv(input_layer, k, in_filter, ou_filter, scope, reuse=False):\n",
    "    \n",
    "    with tf.compat.v1.variable_scope(scope, reuse = reuse):    \n",
    "        #Upsampling\n",
    "        upsample = upsampling(input_layer, 2)\n",
    "        out = conv_elu(upsample, k, in_filter, ou_filter, 1, scope='conv_elu')\n",
    "        return out\n",
    "\n",
    "\n",
    "def conv_block(input_layer, k, in_filter, ou_filter, scope):\n",
    "    \n",
    "    c1 = conv_elu(input_layer, k,  in_filter, ou_filter,  1, scope=scope )\n",
    "    c2 = conv_elu(c1,          k,  ou_filter, ou_filter,  2, scope=scope+'b')\n",
    "    \n",
    "    return c2\n",
    "    \n",
    "def get_disp(x, in_filter,scope):\n",
    "    disp = 0.3 * conv_elu(x, 3, in_filter, 2, 1, scope = scope, activation = tf.nn.sigmoid)\n",
    "    return disp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_placeholder():\n",
    "    \n",
    "    tf1.disable_eager_execution()\n",
    "    tf1.reset_default_graph()\n",
    "    \n",
    "    with tf1.name_scope(\"Input_image\"):\n",
    "        input_layer = tf1.placeholder('float', shape = input_shape)\n",
    "        \n",
    "    return input_layer\n",
    "\n",
    "\n",
    "def make_architecture(input_layers):\n",
    "    \n",
    "    with tf1.name_scope(\"ENCNN\"):\n",
    "    \n",
    "        with tf1.name_scope(\"encoder\"):\n",
    "            conv1 = conv_block(input_layers, 7,  3,  32, 'conv1')#2\n",
    "            conv2 = conv_block(conv1,        5, 32,  64, 'conv2')#4\n",
    "            conv3 = conv_block(conv2,        3, 64, 128, 'conv3')#8\n",
    "            conv4 = conv_block(conv3,        3, 128,256, 'conv4')#16\n",
    "            conv5 = conv_block(conv4,        3, 256,512, 'conv5')#32\n",
    "                conv6 = conv_block(conv5,        3, 512,512, 'conv6')#64\n",
    "            conv7 = conv_block(conv6,        3, 512,512, 'conv7')#128\n",
    "            \n",
    "            \n",
    "            \n",
    "\n",
    "\n",
    "        with tf1.name_scope(\"decoder\"):\n",
    "            #upsampling 7\n",
    "            upconv7 = upconv(conv7,     3,  512,  512, scope =  'upconv7')\n",
    "            concat7 = tf.concat([upconv7, conv6], axis=-1, name = 'concat7')\n",
    "            iconv7  = conv_elu(concat7, 3, 1024,  512, 1, scope= 'iconv7')\n",
    "\n",
    "            #upsampling 6\n",
    "            upconv6 = upconv(iconv7,    3,  512,  512, scope =  'upconv6')\n",
    "            concat6 = tf.concat([upconv6, conv5], axis=-1, name = 'concat6')\n",
    "            iconv6  = conv_elu(concat6, 3, 1024,  512, 1, scope= 'iconv6')\n",
    "\n",
    "            #upsampling 5\n",
    "            upconv5 = upconv(iconv6,    3,  512,  256, scope =  'upconv5')\n",
    "            concat5 = tf.concat([upconv5, conv4], axis=-1, name= 'concat5')\n",
    "            iconv5  = conv_elu(concat5, 3,  512,  256, 1, scope= 'iconv5')\n",
    "\n",
    "            #upsampling 4\n",
    "            upconv4 = upconv(iconv5,    3,   256,  128, scope = 'upconv4')\n",
    "            concat4 = tf.concat([upconv4, conv3], axis=-1, name ='concat4')\n",
    "            iconv4  = conv_elu(concat4, 3, 256,  128, 1, scope= 'iconv4')\n",
    "            disp4   = get_disp(iconv4, 128, scope= 'disp4')\n",
    "            updisp4 = upsampling(disp4, 2)\n",
    "\n",
    "            #upsampling 3\n",
    "            upconv3 = upconv(iconv4,    3,  128,  64, scope = 'upconv3')\n",
    "            concat3 = tf.concat([upconv3, conv2, updisp4], axis=-1, name='concat3')\n",
    "            iconv3  = conv_elu(concat3, 3, 130,  64, 1, scope= 'iconv3')\n",
    "            disp3   = get_disp(iconv3,  64, scope = 'disp3')\n",
    "            updisp3 = upsampling(disp3, 2)\n",
    "\n",
    "            #upsampling 2\n",
    "            upconv2 = upconv(iconv3,    3,  64,   32, scope = 'upconv2')\n",
    "            concat2 = tf.concat([upconv2, conv1, updisp3], axis=-1, name='concat2')\n",
    "            iconv2  = conv_elu(concat2, 3,  66,   32, 1, scope= 'iconv2')\n",
    "            disp2   = get_disp(iconv2,  32, scope = 'disp2')\n",
    "            updisp2 = upsampling(disp2, 2)\n",
    "\n",
    "            #upsampling 1\n",
    "            upconv1 = upconv(iconv2,    3,  32,   16, scope = 'upconv1')\n",
    "            concat1 = tf.concat([upconv1, updisp2], axis=-1, name='convat1')\n",
    "            iconv1  = conv_elu(concat1, 3,  18,   16, 1, scope= 'iconv1')\n",
    "            disp1   = get_disp(iconv1,  16, scope = 'disp1')\n",
    "        \n",
    "    return disp1, disp2, disp3 ,disp4\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_input_image):\n",
    "    logdir = '/media/sansii/Software/san_projects/Major_project/Moncular_depth_estimation_data/'\n",
    "    input_layer = init_placeholder()\n",
    "    \n",
    "    disp1, disp2, disp3 , disp4 = make_architecture(input_layer)\n",
    "    \n",
    "    writer = tf1.summary.FileWriter(logdir+'./graph' , graph=tf1.get_default_graph())\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "img_h = 256\n",
    "img_w = 512\n",
    "input_shape = [batch_size, img_h, img_w, 3]\n",
    "train(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Testing Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf1.disable_eager_execution()\n",
    "tf1.reset_default_graph()\n",
    "n_filters = 64\n",
    "n_channels = 3\n",
    "kernel_shape = [7, 7, n_channels,n_filters]\n",
    "bias_shape = [n_filters]\n",
    "W = tf.compat.v1.get_variable(\"weight\", kernel_shape, initializer=tf1.glorot_uniform_initializer())\n",
    "data_path = '/media/sansii/Software/san_projects/Major_project/KITTI_dataset/2015/testing/'\n",
    "left = ndimage.imread(data_path+\"image_2/000083_10.png\")\n",
    "\n",
    "left_shape = (1, left.shape[0], left.shape[1], 3)\n",
    "input_layer  = tf.compat.v1.placeholder(tf.float32, left_shape,  name='image_left' )\n",
    "p = np.floor((kernel_shape[0] - 1) / 2).astype('int32')\n",
    "padding = tf.constant([[0,0],[p, p],[p, p],[0,0]])\n",
    "p_x = tf.pad(input_layer, padding)\n",
    "conv = conv2d(p_x, W, stride = 2)\n",
    "conv = tf.nn.elu(conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = tf1.global_variables_initializer()\n",
    "with tf1.Session() as sess:\n",
    "    sess.run(var)\n",
    "    left_ = left[np.newaxis,...]\n",
    "    print(left_.shape)\n",
    "    out = sess.run(conv, feed_dict={input_layer: left_})\n",
    "   \n",
    "    print(out.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset_selective conv2d\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def STN(img, disparity):\n",
    "    \n",
    "    def interpolate(img, x, y):\n",
    "        #bilinear_interpolation\n",
    "\n",
    "        #For corner pixel there is no either left or right / top or down pixels so padding is necessary\n",
    "        img = tf.pad(img, paddings= ((0,0),(1,1),(1,1),(0,0)), mode='CONSTANT')\n",
    "\n",
    "        #since we have padded we need to add plus 1 for our transformed coordinates\n",
    "        x = x + 1\n",
    "        y = y + 1\n",
    "\n",
    "        x = tf.clip_by_value(x, 0.0, tf.cast(width,tf.float32)+1.0)\n",
    "        \n",
    "        #since the values are in fraction we need to take floor value which selects left pixels\n",
    "        x_float   = tf.floor(x)\n",
    "        y_float   = tf.floor(y)\n",
    "        x_1_float = x_float + 1\n",
    "        \n",
    "        #x_1_float = tf.minimum(x_1_float, tf.cast(width,tf.float32)+1.0 )\n",
    "        \n",
    "        #Since,the index are in integer we convert float into integer\n",
    "        x_int = tf.cast(x_float, tf.int32)\n",
    "        y_int = tf.cast(y_float, tf.int32)\n",
    "        x_1_int = tf.cast(x_1_float, tf.int32)\n",
    "        \n",
    "        #we required total dimention for reshaping \n",
    "        dim_y  = width + 2 * 1 #padding\n",
    "        dim_xy = (width + 2) * (height + 2)\n",
    "\n",
    "        #There are number of images with there individual coordinate space now we need to convert\n",
    "        #individual coordinate space into a single coordinate space\n",
    "        #eg: x = [ [0,1,2,3], [0,1,2,3], [0,1,2,3]] \n",
    "        # y= [[0,0,0,0],[1,1,1,1],[2,2,2,2]]into [0 ,1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
    "        #Converting 2d spatial dimention into 1d vector\n",
    "        \n",
    "        base = tf.tile(tf.expand_dims(tf.range(num_batches),1) * dim_xy, [1, width * height])\n",
    "        base = tf.reshape(base, [-1])\n",
    "    \n",
    "        x_l = x_int   + (base + y_int * dim_y)\n",
    "        x_r = x_1_int + (base + y_int * dim_y)\n",
    "        \n",
    "        #Flattering input image\n",
    "        img_flat = tf.reshape(img, [-1, num_channels]) \n",
    "        \n",
    "        #tf.gather selects pixels of img from coordinate x_l and x_r\n",
    "        #Therefore pixel_l and pixel_r contains only selected coordinates pixels from img\n",
    "        pixel_l = tf.gather(img_flat, x_l)\n",
    "        pixel_r = tf.gather(img_flat, x_r)\n",
    "        \n",
    "        #Now for bilinear interpolation each left and right pixel must be associated with its respective weights.\n",
    "        weights_l = tf.expand_dims(x_1_float - x, 1)#Since nearer pixel has greater weight\n",
    "        weights_r = tf.expand_dims(x - x_float, 1)\n",
    "        \n",
    "\n",
    "        \n",
    "        out = (weights_l * pixel_l) + (weights_r * pixel_r)\n",
    "\n",
    "        return tf.reshape(out, [num_batches, height, width, num_channels])\n",
    "    def bilinear_sampling(img, disparity):\n",
    "       \n",
    "\n",
    "        width_f =  tf.cast(width , tf.float32)\n",
    "        height_f = tf.cast(height, tf.float32)\n",
    "\n",
    "        #Creating meshgrid which contains represents coordinates(x, y) of images\n",
    "        x_grid, y_grid = tf.cast(tf.meshgrid(tf.range(width), \n",
    "                                     tf.range(height)), tf.float32)\n",
    "        \n",
    "        #Flatterning grids\n",
    "        x_flat = tf.reshape(x_grid, [-1])\n",
    "        y_flat = tf.reshape(y_grid, [-1])\n",
    "\n",
    "        #Since, there are num_batches so we need to add up grids for all batches\n",
    "        x_flat = tf.tile(x_flat, [num_batches])\n",
    "        y_flat = tf.tile(y_flat, [num_batches])\n",
    "\n",
    "        #Flatterning disparity size = (num_batches * weight * height)\n",
    "        disparity_flat = tf.reshape(disparity, [-1])\n",
    "    \n",
    "        #Adding disparity to find / applying transformation\n",
    "        x_transf = x_flat + (disparity_flat * width_f) #Since the out of sigmoid funtion in 0 -1 so we muliply with width\n",
    "\n",
    "        #Transformed coordinates are in fraction since, there is no fraction pixel so we interplate\n",
    "        out = interpolate(img, x_transf, y_flat)\n",
    "\n",
    "\n",
    "\n",
    "        return out\n",
    "    \n",
    "    with tf1.variable_scope(\"name\"):\n",
    "        width       = tf.shape(img)[2]\n",
    "        height      = tf.shape(img)[1]\n",
    "        num_batches = tf.shape(img)[0]\n",
    "        num_channels= tf.shape(img)[3]\n",
    "        out = bilinear_sampling(img, disparity)\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bilinear_sampler_1d_h(input_images, x_offset, wrap_mode='border', name='bilinear_sampler', **kwargs):\n",
    "    def _repeat(x, n_repeats):\n",
    "        rep = tf.tile(tf.expand_dims(x, 1), [1, n_repeats])\n",
    "        return tf.reshape(rep, [-1])\n",
    "\n",
    "    def _interpolate(im, x, y):\n",
    "        \n",
    "\n",
    "        # handle both texture border types\n",
    "        _edge_size = 0\n",
    "        if _wrap_mode == 'border':\n",
    "            _edge_size = 1\n",
    "            im = tf.pad(im, [[0, 0], [1, 1], [1, 1], [0, 0]], mode='CONSTANT')\n",
    "            x = x + _edge_size\n",
    "            y = y + _edge_size\n",
    "        elif _wrap_mode == 'edge':\n",
    "            _edge_size = 0\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "        x = tf.clip_by_value(x, 0.0,  _width_f - 1 + 2 * _edge_size)\n",
    "\n",
    "        x0_f = tf.floor(x)\n",
    "        y0_f = tf.floor(y)\n",
    "        x1_f = x0_f + 1\n",
    "\n",
    "        x0 = tf.cast(x0_f, tf.int32)\n",
    "        y0 = tf.cast(y0_f, tf.int32)\n",
    "        x1 = tf.cast(tf.minimum(x1_f,  _width_f - 1 + 2 * _edge_size), tf.int32)\n",
    "\n",
    "        dim2 = (_width + 2 * _edge_size)\n",
    "        dim1 = (_width + 2 * _edge_size) * (_height + 2 * _edge_size)\n",
    "        base = _repeat(tf.range(_num_batch) * dim1, _height * _width)\n",
    "        base_y0 = base + y0 * dim2\n",
    "        idx_l = base_y0 + x0\n",
    "        idx_r = base_y0 + x1\n",
    "\n",
    "        im_flat = tf.reshape(im, tf.stack([-1, _num_channels]))\n",
    "\n",
    "        pix_l = tf.gather(im_flat, idx_l)\n",
    "        pix_r = tf.gather(im_flat, idx_r)\n",
    "\n",
    "        weight_l = tf.expand_dims(x1_f - x, 1)\n",
    "        weight_r = tf.expand_dims(x - x0_f, 1)\n",
    "\n",
    "        return weight_l * pix_l + weight_r * pix_r\n",
    "\n",
    "    def _transform(input_images, x_offset):\n",
    "      \n",
    "        # grid of (x_t, y_t, 1), eq (1) in ref [1]\n",
    "        x_t, y_t = tf.meshgrid(tf.linspace(0.0,   _width_f - 1.0,  _width),\n",
    "                               tf.linspace(0.0 , _height_f - 1.0 , _height))\n",
    "\n",
    "        x_t_flat = tf.reshape(x_t, (1, -1))\n",
    "        y_t_flat = tf.reshape(y_t, (1, -1))\n",
    "\n",
    "        x_t_flat = tf.tile(x_t_flat, tf.stack([_num_batch, 1]))\n",
    "        y_t_flat = tf.tile(y_t_flat, tf.stack([_num_batch, 1]))\n",
    "\n",
    "        x_t_flat = tf.reshape(x_t_flat, [-1])\n",
    "        y_t_flat = tf.reshape(y_t_flat, [-1])\n",
    "\n",
    "        x_t_flat = x_t_flat + tf.reshape(x_offset, [-1]) * _width_f\n",
    "\n",
    "        input_transformed = _interpolate(input_images, x_t_flat, y_t_flat)\n",
    "\n",
    "        output = tf.reshape(\n",
    "            input_transformed, tf.stack([_num_batch, _height, _width, _num_channels]))\n",
    "        return output\n",
    "\n",
    "    with tf1.variable_scope(name):\n",
    "        _num_batch    = tf.shape(input_images)[0]\n",
    "        _height       = tf.shape(input_images)[1]\n",
    "        _width        = tf.shape(input_images)[2]\n",
    "        _num_channels = tf.shape(input_images)[3]\n",
    "\n",
    "        _height_f = tf.cast(_height, tf.float32)\n",
    "        _width_f  = tf.cast(_width,  tf.float32)\n",
    "\n",
    "        _wrap_mode = wrap_mode\n",
    "\n",
    "        output = _transform(input_images, x_offset)\n",
    "        return output\n",
    "def generate_image_left(img, disp):\n",
    "    out = bilinear_sampler_1d_h(img, -disp)\n",
    "    return tf.reduce_mean(tf.abs(out - disp))\n",
    "    \n",
    "def generate_image_right(img, disp):\n",
    "    out = bilinear_sampler_1d_h(img, disp)\n",
    "    return tf.reduce_mean(tf.abs(out - disp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'generate_image_left' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-c6ff418ce4a6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mdisp_right\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_pyramide_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdisp_right\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mleft\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_image_left\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdisp_right\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisp_left\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mright\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_image_right\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdisp_left\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisp_right\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'generate_image_left' is not defined"
     ]
    }
   ],
   "source": [
    "a = np.random.randint(0, 10 , size =(50,300,300,3))\n",
    "b = np.random.randn(50,300,300,1)\n",
    "\n",
    "d_left = np.random.randint(0, 20 , size =(1,256,256,1))\n",
    "d_right = np.random.randint(0,20 , size = (1,256,256,1))\n",
    "\n",
    "disp_left = tf.constant(d_left,dtype =tf.float32)\n",
    "disp_right = tf.constant(d_right, dtype = tf.float32)\n",
    "\n",
    "disp_left = make_pyramide_image(disp_left)\n",
    "disp_right = make_pyramide_image(disp_right)\n",
    "\n",
    "left = generate_image_left(disp_right, disp_left)\n",
    "right = generate_image_right(disp_left, disp_right)\n",
    "\n",
    "left_ = lr_consistency_loss_left(disp_left, disp_right)\n",
    "right_  = lr_consistency_loss_right(disp_left, disp_right)\n",
    "\n",
    "print(left.numpy(), left_.numpy())\n",
    "print(right.numpy(),right_.numpy())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training _LOSSES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SSIM(image, pred_image, block_size=3):\n",
    "    \n",
    "    C1 = 0.01 ** 2\n",
    "    C2 = 0.03 ** 2\n",
    "    \n",
    "    u_x = tf.nn.avg_pool2d(image      ,block_size, strides=1, padding='VALID')\n",
    "    u_y = tf.nn.avg_pool2d(pred_image ,block_size, strides=1, padding='VALID')\n",
    "\n",
    "    sigma_x  = tf.nn.avg_pool2d(image**2           ,block_size, strides=1, padding='VALID') - u_x**2\n",
    "    sigma_y  = tf.nn.avg_pool2d(pred_image**2      ,block_size, strides=1, padding='VALID') - u_y**2\n",
    "    sigma_xy = tf.nn.avg_pool2d(image * pred_image ,block_size, strides=1, padding='VALID') - u_x * u_y\n",
    "    \n",
    "    SSIM_num = ((2 * u_x * u_y + C1)   * (2 * sigma_x * sigma_y   + C2)) \n",
    "    SSIM_den = ((u_x**2 + u_y**2 + C1) * (sigma_x**2 + sigma_y**2 + C2))\n",
    "    \n",
    "    SSIM = SSIM_num / SSIM_den\n",
    "    \n",
    "    return tf.clip_by_value((1 - SSIM) / 2, 0, 1)\n",
    "\n",
    "\n",
    "\n",
    "def apperance_matching_loss(image, pred_image):\n",
    "    alpha = 0.85\n",
    "    L1_error = tf.abs(image - pred_image)\n",
    "    ssim_error = SSIM(image, pred_image, 3)\n",
    "    \n",
    "    C_ap = tf.reduce_mean((alpha * ssim_error)) + tf.reduce_mean((1 - alpha) * L1_error)\n",
    "    \n",
    "    return C_ap\n",
    "\n",
    "\n",
    "def disparity_smoothness_loss(disp, image):\n",
    "    \n",
    "    disp_gradient_y , disp_gradient_x  = tf.image.image_gradients(disp)\n",
    "    image_gradient_y, image_gradient_x = tf.image.image_gradients(image)\n",
    "\n",
    "    im_dx = -tf.reduce_mean(tf.abs(image_gradient_x),axis=-1, keepdims=True)\n",
    "    im_dy = -tf.reduce_mean(tf.abs(image_gradient_y),axis=-1, keepdims=True)\n",
    "    \n",
    "    loss_dx = tf.multiply(tf.abs(disp_gradient_x), tf.math.exp(im_dx))\n",
    "    loss_dy = tf.multiply(tf.abs(disp_gradient_y), tf.math.exp(im_dy))\n",
    "    \n",
    "    disp_smoothness_loss = tf.reduce_mean((loss_dx + loss_dy))\n",
    "    \n",
    "    \n",
    "    return disp_smoothness_loss\n",
    "\n",
    "\n",
    "def lr_consistency_loss_left(disp_left, disp_right):\n",
    "    disp_left_from_right = STN(disp_right,  -disp_left)\n",
    "    return tf.reduce_mean(tf.abs(disp_left - disp_left_from_right))\n",
    "    \n",
    "\n",
    "def lr_consistency_loss_right(disp_left, disp_right):\n",
    "    disp_right_from_left = STN(disp_left,  disp_right)\n",
    "    return tf.reduce_mean(tf.abs(disp_right- disp_right_from_left)) \n",
    "        \n",
    "\n",
    "\n",
    "def training_loss_each_scale(image_left,image_right, disp, r):\n",
    "\n",
    "    alpha_ap = 1\n",
    "    alpha_ds = (0.1 / 2 ** r)\n",
    "    alpha_lr = 1\n",
    "    \n",
    "    #predicted disparity\n",
    "    disp_left   = tf.expand_dims(disp[:,:,:,0], 3)\n",
    "    disp_right  = tf.expand_dims(disp[:,:,:,1], 3)\n",
    "\n",
    "    \n",
    "    #Sampling left images form right using left_disparity and vice-versa\n",
    "    pred_left   = STN(image_right, -disp_left)\n",
    "    pred_right  = STN(image_left , disp_right)\n",
    "    \n",
    "    #Apperance_matching_loss\n",
    "    C_ap_l = apperance_matching_loss(image_left,  pred_left)\n",
    "    C_ap_r = apperance_matching_loss(image_right, pred_right)\n",
    "    \n",
    "    #Disparity Smoothness Loss\n",
    "    C_ds_l = disparity_smoothness_loss(disp_left,  image_left)\n",
    "    C_ds_r = disparity_smoothness_loss(disp_right, image_right)\n",
    "    \n",
    "    #Left-Right Disparity Cosnsistency Loss\n",
    "    C_lr_l = lr_consistency_loss_left(disp_left, disp_right)\n",
    "    C_lr_r = lr_consistency_loss_right(disp_left, disp_right)\n",
    "    \n",
    "    loss = alpha_ap * (C_ap_l + C_ap_r) + alpha_ds * (C_ds_l + C_ds_r) + alpha_lr * (C_lr_l + C_lr_r)\n",
    "    \n",
    "    \n",
    "    return loss\n",
    "\n",
    "\n",
    "def total_loss(imgL, imgR, disp):\n",
    "    left_pyramide  = make_pyramide_image(imgL)\n",
    "    right_pyramide = make_pyramide_image(imgR)\n",
    "    disp           = make_pyramide_image(disp)\n",
    "    tot_loss = tf.constant([0.0])\n",
    "    \n",
    "    for i in range(4):\n",
    "        loss = training_loss_each_scale(left_pyramide[i], right_pyramide[i], disp[i], i + 1)\n",
    "        tot_loss = tf.add(tot_loss, loss)\n",
    "    \n",
    "    return tot_loss\n",
    "\n",
    "    \n",
    "def make_pyramide_image(img, num_scales =4):\n",
    "    scaled_imgs = [img]\n",
    "    s = tf.shape(img)\n",
    "    h = s[1]\n",
    "    w = s[2]\n",
    "    for i in range(num_scales - 1):\n",
    "        ratio = 2 ** (i + 1)\n",
    "        nh = h // ratio\n",
    "        nw = w // ratio\n",
    "        scaled_imgs.append(tf.image.resize(img, [nh, nw]))\n",
    "    return scaled_imgs\n",
    "        \n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = tf.constant([[1., 2,  3], [4,  5,  6]])\n",
    "t2 = tf.clip_by_value(t, clip_value_min=-1, clip_value_max=1)\n",
    "\n",
    "exp = tf.math.exp(t)\n",
    "with tf1.Session() as sess:\n",
    "    e = sess.run(exp)\n",
    "    print(e)\n",
    "    \n",
    "t2.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1\n",
    "IMAGE_HEIGHT = 5\n",
    "IMAGE_WIDTH = 5\n",
    "CHANNELS = 1\n",
    "image = tf.reshape(tf.range(IMAGE_HEIGHT * IMAGE_WIDTH * CHANNELS,\n",
    "  delta=1, dtype=tf.float32),\n",
    "  shape=(BATCH_SIZE, IMAGE_HEIGHT, IMAGE_WIDTH, CHANNELS))\n",
    "dx, dy = tf.image.image_gradients(image)\n",
    "exp = \n",
    "with tf1.Session() as sess:\n",
    "    d_y, d_x = sess.run([dx, dy])\n",
    "    print(d_y)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dCost_dW.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparision_Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ours\n",
    "def STN(img, disparity):\n",
    "    \n",
    "    def interpolate(img, x, y):\n",
    "        #bilinear_interpolation\n",
    "\n",
    "        #For corner pixel there is no either left or right / top or down pixels so padding is necessary\n",
    "        img = tf.pad(img, paddings= ((0,0),(1,1),(1,1),(0,0)), mode='CONSTANT')\n",
    "\n",
    "        #since we have padded we need to add plus 1 for our transformed coordinates\n",
    "        x = x + 1\n",
    "        y = y + 1\n",
    "\n",
    "        x = tf.clip_by_value(x, 0.0, tf.cast(width,tf.float32)+1.0)\n",
    "        \n",
    "        #since the values are in fraction we need to take floor value which selects left pixels\n",
    "        x_float   = tf.floor(x)\n",
    "        y_float   = tf.floor(y)\n",
    "        x_1_float = x_float + 1\n",
    "        \n",
    "        #x_1_float = tf.minimum(x_1_float, tf.cast(width,tf.float32)+1.0 )\n",
    "        \n",
    "        #Since,the index are in integer we convert float into integer\n",
    "        x_int = tf.cast(x_float, tf.int32)\n",
    "        y_int = tf.cast(y_float, tf.int32)\n",
    "        x_1_int = tf.cast(x_1_float, tf.int32)\n",
    "        \n",
    "        #we required total dimention for reshaping \n",
    "        dim_y  = width + 2 * 1 #padding\n",
    "        dim_xy = (width + 2) * (height + 2)\n",
    "\n",
    "        #There are number of images with there individual coordinate space now we need to convert\n",
    "        #individual coordinate space into a single coordinate space\n",
    "        #eg: x = [ [0,1,2,3], [0,1,2,3], [0,1,2,3]] \n",
    "        # y= [[0,0,0,0],[1,1,1,1],[2,2,2,2]]into [0 ,1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
    "        #Converting 2d spatial dimention into 1d vector\n",
    "        \n",
    "        base = tf.tile(tf.expand_dims(tf.range(num_batches),1) * dim_xy, [1, width * height])\n",
    "        base = tf.reshape(base, [-1])\n",
    "    \n",
    "        x_l = x_int   + (base + y_int * dim_y)\n",
    "        x_r = x_1_int + (base + y_int * dim_y)\n",
    "        \n",
    "        #Flattering input image\n",
    "        img_flat = tf.reshape(img, [-1, num_channels]) \n",
    "        \n",
    "        #tf.gather selects pixels of img from coordinate x_l and x_r\n",
    "        #Therefore pixel_l and pixel_r contains only selected coordinates pixels from img\n",
    "        pixel_l = tf.gather(img_flat, x_l)\n",
    "        pixel_r = tf.gather(img_flat, x_r)\n",
    "        \n",
    "        #Now for bilinear interpolation each left and right pixel must be associated with its respective weights.\n",
    "        weights_l = tf.expand_dims(x_1_float - x, 1)#Since nearer pixel has greater weight\n",
    "        weights_r = tf.expand_dims(x - x_float, 1)\n",
    "        \n",
    "\n",
    "        \n",
    "        out = (weights_l * pixel_l) + (weights_r * pixel_r)\n",
    "\n",
    "        return tf.reshape(out, [num_batches, height, width, num_channels])\n",
    "    def bilinear_sampling(img, disparity):\n",
    "       \n",
    "\n",
    "        width_f =  tf.cast(width , tf.float32)\n",
    "        height_f = tf.cast(height, tf.float32)\n",
    "\n",
    "        #Creating meshgrid which contains represents coordinates(x, y) of images\n",
    "        x_grid, y_grid = tf.cast(tf.meshgrid(tf.range(width), \n",
    "                                     tf.range(height)), tf.float32)\n",
    "        \n",
    "        #Flatterning grids\n",
    "        x_flat = tf.reshape(x_grid, [-1])\n",
    "        y_flat = tf.reshape(y_grid, [-1])\n",
    "\n",
    "        #Since, there are num_batches so we need to add up grids for all batches\n",
    "        x_flat = tf.tile(x_flat, [num_batches])\n",
    "        y_flat = tf.tile(y_flat, [num_batches])\n",
    "\n",
    "        #Flatterning disparity size = (num_batches * weight * height)\n",
    "        disparity_flat = tf.reshape(disparity, [-1])\n",
    "    \n",
    "        #Adding disparity to find / applying transformation\n",
    "        x_transf = x_flat + (disparity_flat * width_f) #Since the out of sigmoid funtion in 0 -1 so we muliply with width\n",
    "\n",
    "        #Transformed coordinates are in fraction since, there is no fraction pixel so we interplate\n",
    "        out = interpolate(img, x_transf, y_flat)\n",
    "\n",
    "\n",
    "\n",
    "        return out\n",
    "    \n",
    "    with tf1.variable_scope(\"name\"):\n",
    "        width       = tf.shape(img)[2]\n",
    "        height      = tf.shape(img)[1]\n",
    "        num_batches = tf.shape(img)[0]\n",
    "        num_channels= tf.shape(img)[3]\n",
    "        out = bilinear_sampling(img, disparity)\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "\n",
    "def SSIM(image, pred_image, block_size=3):\n",
    "    \n",
    "    C1 = 0.01 ** 2\n",
    "    C2 = 0.03 ** 2\n",
    "    \n",
    "    u_x = tf.nn.avg_pool2d(image      ,block_size, strides=1, padding='VALID')\n",
    "    u_y = tf.nn.avg_pool2d(pred_image ,block_size, strides=1, padding='VALID')\n",
    "\n",
    "    sigma_x  = tf.nn.avg_pool2d(image**2           ,block_size, strides=1, padding='VALID') - u_x**2\n",
    "    sigma_y  = tf.nn.avg_pool2d(pred_image**2      ,block_size, strides=1, padding='VALID') - u_y**2\n",
    "    sigma_xy = tf.nn.avg_pool2d(image * pred_image ,block_size, strides=1, padding='VALID') - u_x * u_y\n",
    "    \n",
    "    SSIM_num = ((2 * u_x * u_y + C1)   * (2 * sigma_x * sigma_y   + C2)) \n",
    "    SSIM_den = ((u_x**2 + u_y**2 + C1) * (sigma_x**2 + sigma_y**2 + C2))\n",
    "    \n",
    "    SSIM = SSIM_num / SSIM_den\n",
    "    \n",
    "    return tf.clip_by_value((1 - SSIM) / 2, 0, 1)\n",
    "\n",
    "\n",
    "\n",
    "def apperance_matching_loss(image, pred_image):\n",
    "    alpha = 0.85\n",
    "    L1_error = tf.abs(image - pred_image)\n",
    "    ssim_error = SSIM(image, pred_image, 3)\n",
    "    \n",
    "    C_ap = tf.reduce_mean((alpha * ssim_error)) + tf.reduce_mean((1 - alpha) * L1_error)\n",
    "    \n",
    "    return C_ap\n",
    "\n",
    "\n",
    "def disparity_smoothness_loss(disp, image):\n",
    "    \n",
    "    disp_gradient_y , disp_gradient_x  = tf.image.image_gradients(disp)\n",
    "    image_gradient_y, image_gradient_x = tf.image.image_gradients(image)\n",
    "\n",
    "    im_dx = -tf.reduce_mean(tf.abs(image_gradient_x),axis=-1, keepdims=True)\n",
    "    im_dy = -tf.reduce_mean(tf.abs(image_gradient_y),axis=-1, keepdims=True)\n",
    "    \n",
    "    loss_dx = tf.multiply(tf.abs(disp_gradient_x), tf.math.exp(im_dx))\n",
    "    loss_dy = tf.multiply(tf.abs(disp_gradient_y), tf.math.exp(im_dy))\n",
    "    \n",
    "    disp_smoothness_loss = tf.reduce_mean((loss_dx + loss_dy))\n",
    "    \n",
    "    \n",
    "    return disp_smoothness_loss\n",
    "\n",
    "\n",
    "def lr_consistency_loss_left(disp_left, disp_right):\n",
    "    disp_left_from_right = STN(disp_right,  -disp_left)\n",
    "    return tf.reduce_mean(tf.abs(disp_left - disp_left_from_right))\n",
    "    \n",
    "\n",
    "def lr_consistency_loss_right(disp_left, disp_right):\n",
    "    disp_right_from_left = STN(disp_left,  disp_right)\n",
    "    return tf.reduce_mean(tf.abs(disp_right- disp_right_from_left)) \n",
    "        \n",
    "\n",
    "\n",
    "def training_loss_each_scale(image_left,image_right, disp, r):\n",
    "\n",
    "    alpha_ap = 1\n",
    "    alpha_ds = (0.1 / 2 ** r)\n",
    "    alpha_lr = 1\n",
    "    \n",
    "    #predicted disparity\n",
    "    disp_left   = tf.expand_dims(disp[:,:,:,0], 3)\n",
    "    disp_right  = tf.expand_dims(disp[:,:,:,1], 3)\n",
    "\n",
    "    \n",
    "    #Sampling left images form right using left_disparity and vice-versa\n",
    "    pred_left   = STN(image_right, -disp_left)\n",
    "    pred_right  = STN(image_left , disp_right)\n",
    "    \n",
    "    #Apperance_matching_loss\n",
    "    C_ap_l = apperance_matching_loss(image_left,  pred_left)\n",
    "    C_ap_r = apperance_matching_loss(image_right, pred_right)\n",
    "    \n",
    "    #Disparity Smoothness Loss\n",
    "    C_ds_l = disparity_smoothness_loss(disp_left,  image_left)\n",
    "    C_ds_r = disparity_smoothness_loss(disp_right, image_right)\n",
    "    \n",
    "    #Left-Right Disparity Cosnsistency Loss\n",
    "    C_lr_l = lr_consistency_loss_left(disp_left, disp_right)\n",
    "    C_lr_r = lr_consistency_loss_right(disp_left, disp_right)\n",
    "    \n",
    "    loss = alpha_ap * (C_ap_l + C_ap_r) + alpha_ds * (C_ds_l + C_ds_r) + alpha_lr * (C_lr_l + C_lr_r)\n",
    "    \n",
    "    \n",
    "    return loss\n",
    "\n",
    "\n",
    "def total_loss(imgL, imgR, disp):\n",
    "    left_pyramide  = make_pyramide_image(imgL)\n",
    "    right_pyramide = make_pyramide_image(imgR)\n",
    "    disp           = make_pyramide_image(disp)\n",
    "    tot_loss = tf.constant([0.0])\n",
    "    \n",
    "    for i in range(4):\n",
    "        loss = training_loss_each_scale(left_pyramide[i], right_pyramide[i], disp[i], i + 1)\n",
    "        tot_loss = tf.add(tot_loss, loss)\n",
    "    \n",
    "    return tot_loss\n",
    "\n",
    "    \n",
    "def make_pyramide_image(img, num_scales =4):\n",
    "    scaled_imgs = [img]\n",
    "    s = tf.shape(img)\n",
    "    h = s[1]\n",
    "    w = s[2]\n",
    "    for i in range(num_scales - 1):\n",
    "        ratio = 2 ** (i + 1)\n",
    "        nh = h // ratio\n",
    "        nw = w // ratio\n",
    "        scaled_imgs.append(tf.image.resize(img, [nh, nw]))\n",
    "    return scaled_imgs\n",
    "        \n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Papers\n",
    "from bilinear_sampler import *\n",
    "class smoothness_losses:\n",
    "    \n",
    "    def scale_pyramid(self, img, num_scales):\n",
    "        scaled_imgs = [img]\n",
    "        s = tf.shape(img)\n",
    "        h = s[1]\n",
    "        w = s[2]\n",
    "        for i in range(num_scales - 1):\n",
    "            ratio = 2 ** (i + 1)\n",
    "            nh = h // ratio\n",
    "            nw = w // ratio\n",
    "            scaled_imgs.append(tf.image.resize(img, [nh, nw]))\n",
    "        return scaled_imgs\n",
    "\n",
    "    \n",
    "    def gradient_x(self, img):\n",
    "        gx = img[:,:,:-1,:] - img[:,:,1:,:]\n",
    "        return tf.pad(gx,paddings = ((0,0),(0,0),(0,1),(0,0)))\n",
    "\n",
    "    def gradient_y(self, img):\n",
    "        gy = img[:,:-1,:,:] - img[:,1:,:,:]\n",
    "        return tf.pad(gy,paddings=((0,0),(0,1),(0,0),(0,0)))\n",
    "    \n",
    "    def get_disparity_smoothness(self, disp, pyramid):\n",
    "        disp_gradients_x = [self.gradient_x(d) for d in disp]\n",
    "        disp_gradients_y = [self.gradient_y(d) for d in disp]\n",
    "\n",
    "        image_gradients_x = [self.gradient_x(img) for img in pyramid]\n",
    "        image_gradients_y = [self.gradient_y(img) for img in pyramid]\n",
    "\n",
    "        weights_x = [tf.exp(-tf.reduce_mean(tf.abs(g), 3, keep_dims=True)) for g in image_gradients_x]\n",
    "        weights_y = [tf.exp(-tf.reduce_mean(tf.abs(g), 3, keep_dims=True)) for g in image_gradients_y]\n",
    "\n",
    "        smoothness_x = [disp_gradients_x[i] * weights_x[i] for i in range(4)]\n",
    "        smoothness_y = [disp_gradients_y[i] * weights_y[i] for i in range(4)]\n",
    "        return smoothness_x + smoothness_y\n",
    "    \n",
    "    def get_apperance_loss(self, left_est, left_pyramid):\n",
    "        \n",
    "        # L1\n",
    "        self.l1_left = [tf.abs( left_est[i] - left_pyramid[i]) for i in range(4)]\n",
    "        self.l1_reconstruction_loss_left  = [tf.reduce_mean(l) for l in self.l1_left]\n",
    "\n",
    "        # SSIM\n",
    "        self.ssim_left = [self.SSIM_paper( left_est[i], left_pyramid[i]) for i in range(1)]\n",
    "        self.ssim_loss_left  = [tf.reduce_mean(s) for s in self.ssim_left]\n",
    "\n",
    "        # WEIGTHED SUM\n",
    "        self.image_loss_left  = [0.85 * self.ssim_loss_left[i]  + (1 - 0.85) * self.l1_reconstruction_loss_left[i]  for i in range(4)]\n",
    "\n",
    "        return self.image_loss_left\n",
    "    \n",
    "    def generate_image_left(self, img, disp):\n",
    "        return bilinear_sampler_1d_h(img, -disp)\n",
    "    \n",
    "    def generate_image_right(self, img, disp):\n",
    "        return bilinear_sampler_1d_h(img, disp)\n",
    "    \n",
    "    def SSIM_paper(self, x, y):\n",
    "        C1 = 0.01 ** 2\n",
    "        C2 = 0.03 ** 2\n",
    "\n",
    "        mu_x = tf.nn.avg_pool2d(x, 3, 1, 'VALID')\n",
    "        mu_y = tf.nn.avg_pool2d(y, 3, 1, 'VALID')\n",
    "\n",
    "        sigma_x  = tf.nn.avg_pool2d(x ** 2, 3, 1, 'VALID') - mu_x ** 2\n",
    "        sigma_y  = tf.nn.avg_pool2d(y ** 2, 3, 1, 'VALID') - mu_y ** 2\n",
    "        sigma_xy = tf.nn.avg_pool2d(x * y , 3, 1, 'VALID') - mu_x * mu_y\n",
    "\n",
    "        SSIM_n = (2 * mu_x * mu_y + C1) * (2 * sigma_xy + C2)\n",
    "        SSIM_d = (mu_x ** 2 + mu_y ** 2 + C1) * (sigma_x + sigma_y + C2)\n",
    "\n",
    "        SSIM = SSIM_n / SSIM_d\n",
    "\n",
    "        return tf.clip_by_value((1 - SSIM) / 2, 0, 1)\n",
    "    \n",
    "    \n",
    "    def build_outputs(self):\n",
    "        \n",
    "        # STORE DISPARITIES\n",
    "        with tf1.variable_scope('disparities'):\n",
    "            \n",
    "            self.disp_left_est  = [tf.expand_dims(d[:,:,:,0], 3) for d in self.disp_est]\n",
    "            self.disp_right_est = [tf.expand_dims(d[:,:,:,1], 3) for d in self.disp_est]\n",
    "\n",
    "\n",
    "        # GENERATE IMAGES\n",
    "        with tf1.variable_scope('images'):\n",
    "            self.left_est  = [self.generate_image_left(self.right_pyramid[i], self.disp_left_est[i])  for i in range(4)]\n",
    "            self.right_est = [self.generate_image_right(self.left_pyramid[i], self.disp_right_est[i]) for i in range(4)]\n",
    "\n",
    "        # LR CONSISTENCY\n",
    "        with tf1.variable_scope('left-right'):\n",
    "            self.right_to_left_disp = [self.generate_image_left(self.disp_right_est[i], self.disp_left_est[i])  for i in range(4)]\n",
    "            self.left_to_right_disp = [self.generate_image_right(self.disp_left_est[i], self.disp_right_est[i]) for i in range(4)]\n",
    "\n",
    "    \n",
    "        # DISPARITY SMOOTHNESS\n",
    "        with tf1.variable_scope('smoothness'):\n",
    "            self.disp_left_smoothness  = self.get_disparity_smoothness(self.disp_left_est,  self.left_pyramid)\n",
    "            self.disp_right_smoothness = self.get_disparity_smoothness(self.disp_right_est, self.right_pyramid)\n",
    "\n",
    "        \n",
    "    def build_losses(self, disp_est, left_pyramid, right_pyramid):\n",
    "        self.disp_est = disp_est\n",
    "        self.left_pyramid   = left_pyramid\n",
    "        self.right_pyramid  = right_pyramid\n",
    "        \n",
    "        self.build_outputs()\n",
    "        with tf1.variable_scope('losses', reuse=True):\n",
    "            # IMAGE RECONSTRUCTION\n",
    "            # L1\n",
    "            self.l1_left = [tf.abs( self.left_est[i] - self.left_pyramid[i]) for i in range(4)]\n",
    "            self.l1_reconstruction_loss_left  = [tf.reduce_mean(l) for l in self.l1_left]\n",
    "            self.l1_right = [tf.abs(self.right_est[i] - self.right_pyramid[i]) for i in range(4)]\n",
    "            self.l1_reconstruction_loss_right = [tf.reduce_mean(l) for l in self.l1_right]\n",
    "\n",
    "            # SSIM\n",
    "            self.ssim_left = [SSIM( self.left_est[i],  self.left_pyramid[i]) for i in range(4)]\n",
    "            self.ssim_loss_left  = [tf.reduce_mean(s) for s in self.ssim_left]\n",
    "            self.ssim_right = [SSIM(self.right_est[i], self.right_pyramid[i]) for i in range(4)]\n",
    "            self.ssim_loss_right = [tf.reduce_mean(s) for s in self.ssim_right]\n",
    "\n",
    "            # WEIGTHED SUM\n",
    "            self.image_loss_right = [0.85 * self.ssim_loss_right[i] + (1 - 0.85) * self.l1_reconstruction_loss_right[i] for i in range(4)]\n",
    "            self.image_loss_left  = [0.85 * self.ssim_loss_left[i]  + (1 - 0.85) * self.l1_reconstruction_loss_left[i]  for i in range(4)]\n",
    "            self.image_loss = tf.add_n(self.image_loss_left + self.image_loss_right)\n",
    "\n",
    "            # DISPARITY SMOOTHNESS\n",
    "            self.disp_left_loss  = [tf.reduce_mean(tf.abs(self.disp_left_smoothness[i]))  / 2 ** i for i in range(4)]\n",
    "            self.disp_right_loss = [tf.reduce_mean(tf.abs(self.disp_right_smoothness[i])) / 2 ** i for i in range(4)]\n",
    "            self.disp_gradient_loss = tf.add_n(self.disp_left_loss + self.disp_right_loss)\n",
    "\n",
    "            # LR CONSISTENCY\n",
    "            self.lr_left_loss  = [tf.reduce_mean(tf.abs(self.right_to_left_disp[i] - self.disp_left_est[i]))  for i in range(4)]\n",
    "            self.lr_right_loss = [tf.reduce_mean(tf.abs(self.left_to_right_disp[i] - self.disp_right_est[i])) for i in range(4)]\n",
    "            self.lr_loss = tf.add_n(self.lr_left_loss + self.lr_right_loss)\n",
    "\n",
    "            # TOTAL LOSS\n",
    "            self.total_loss = self.image_loss + 0.1 * self.disp_gradient_loss + 1.0 * self.lr_loss\n",
    "        \n",
    "        return self.total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper = smoothness_losses()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "186.59431\n",
      "[186.59433]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(21)\n",
    "num_disp    = np.random.randint(0, 40, size=(1, 512, 512, 2))\n",
    "image_left  = np.random.randint(0, 40, size=(1, 512, 512, 3))\n",
    "image_right = np.random.randint(0, 40, size=(1, 512, 512, 3))\n",
    "\n",
    "\n",
    "disp  = tf.constant(num_disp,dtype=tf.float32)\n",
    "img_L = tf.constant(image_left,  dtype=tf.float32)\n",
    "img_R = tf.constant(image_right, dtype=tf.float32)\n",
    "\n",
    "disp_pyramid  = paper.scale_pyramid(disp, 4)\n",
    "img_L_pyramid = paper.scale_pyramid(img_L, 4)\n",
    "img_R_pyramid = paper.scale_pyramid(img_R, 4)\n",
    "\n",
    "loss = paper.build_losses(disp_pyramid, img_L_pyramid, img_R_pyramid)\n",
    "print(loss.numpy())\n",
    "\n",
    "loss_ = total_loss(img_L, img_R, disp)\n",
    "print(loss_.numpy())\n",
    "\n",
    "# print(len(img_L_pyramid), len(img_R_pyramid))\n",
    "# print(img_L_pyramid[3].numpy().shape)\n",
    "# print(disp[1].numpy().shape)\n",
    "# loss_smooth_ours, dx_our, dd_our = disparity_smoothness_loss(disp[0], image[0])\n",
    "# loss_smooth,dx, dd                 = paper.get_disparity_smoothness(disp, image)\n",
    "\n",
    "# C_ap_l = paper.get_apperance_loss(pre_image, image)\n",
    "# C_ap_l_ours = apperance_matching_loss(image[0], pre_image[0])\n",
    "# print(C_ap_l[0].numpy(), C_ap_l[0].numpy())\n",
    "\n",
    "# print((dx_our.numpy()==\n",
    "#        dx.numpy()))\n",
    "# print(loss_smooth.numpy(), loss_smooth_ours.numpy())\n",
    "# with tf1.Session() as sess:\n",
    "    \n",
    "#     sess.run([loss_smooth_ours])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "#testing apperance matching loss only\n",
    "out = paper.SSIM_paper(img_L,img_R)\n",
    "out_ = SSIM(img_L, img_R)\n",
    "print((out.numpy()==out_.numpy()).all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset_selective total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = np.zeros_like(num_disp)\n",
    "out[:,:,:-1,:] = num_disp[:,:,:-1,:] - num_disp[:,:,1:,:]\n",
    "print(out[:,:,-1:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_t, y_t = np.meshgrid(np.linspace(-1, 1, 5), np.linspace(-1, 1, 5))\n",
    "theta = np.array([[0.7, -0.7, 0], [0.7, 0.7, 0]])\n",
    "theta = np.array([[2, 0, 1], [0, 1, 0]])\n",
    "grid = np.array([x_t, y_t, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = np.dot(theta, grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grid)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(x_t, y_t)\n",
    "plt.axis([-3,3,-3,3])\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(out[0], out[1])\n",
    "plt.axis([-3,3,-3,3])\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.random.randint(0, 10, size =(3, 5))\n",
    "i = tf.constant(a)\n",
    "    index = [0,1]\n",
    "    out = tf.gather(i, index,axis=-1)\n",
    "    out = tf.gather(out, index, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(i)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.random.randint(0, 10, size =(2, 5, 10))\n",
    "b = np.random.randn(2, 5, 10)\n",
    "print(b.shape)\n",
    "img = tf.constant(a)\n",
    "img = tf.cast(img, tf.float32)\n",
    "x_offset = tf.constant(b)\n",
    "x_offset = tf.cast(x_offset, tf.float32)\n",
    "_height = tf.shape(img)[1]\n",
    "_width = tf.shape(img)[2]\n",
    "_height_f  = tf.cast(_height, tf.float32)\n",
    "_width_f  = tf.cast(_width,  tf.float32)\n",
    "_num_batch = tf.shape(img)[0]\n",
    "\n",
    "def _transform(input_images, x_offset):\n",
    "    with tf1.variable_scope('transform'):\n",
    "        # grid of (x_t, y_t, 1), eq (1) in ref [1]\n",
    "        x_t, y_t = tf.meshgrid(tf.linspace(0.0,   _width_f - 1.0,  _width),\n",
    "                               tf.linspace(0.0 , _height_f - 1.0 , _height))\n",
    "\n",
    "        x_t_flat = tf.reshape(x_t, (1, -1))\n",
    "        y_t_flat = tf.reshape(y_t, (1, -1))\n",
    "        \n",
    "        stack = tf.stack([_num_batch,1])\n",
    "\n",
    "        x_t_flat = tf.tile(x_t_flat, tf.stack([_num_batch, 1]))\n",
    "        y_t_flat = tf.tile(y_t_flat, tf.stack([_num_batch, 1]))\n",
    "\n",
    "        x_t_flat = tf.reshape(x_t_flat, [-1])\n",
    "        y_t_flat = tf.reshape(y_t_flat, [-1])\n",
    "        \n",
    "        print(x_t_flat.dtype)\n",
    "        print(x_offset.dtype)\n",
    "\n",
    "        #x_t_flat = x_t_flat + tf.reshape(x_offset, [-1]) * _width_f\n",
    "\n",
    "#         input_transformed = _interpolate(input_images, x_t_flat, y_t_flat)\n",
    "\n",
    "#         output = tf.reshape(\n",
    "#             input_transformed, tf.stack([_num_batch, _height, _width, _num_channels]))\n",
    "        return x_t_flat, y_t_flat, stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_t, y_t, stack = _transform(img, x_offset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = tf.tile(tf.expand_dims(tf.range(_num_batch)* (_height * _width), 1 ),[1,( _height * _width)])\n",
    "base = tf.reshape(base, [-1])\n",
    "base = tf.cast(base, tf.int32)\n",
    "y_t  = tf.cast(y_t, tf.int32)\n",
    "x_t  = tf.cast(x_t, tf.int32)\n",
    "print(base)\n",
    "print(x_t.numpy() + (base + y_t * 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.random.randint(0, 5,  size =(3, 3))\n",
    "a = [[0],[50]]\n",
    "img = tf.constant(a)\n",
    "#img = tf.reshape(img, [1,-1])\n",
    "out = tf.tile(img,[2,1])\n",
    "print(img)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack = tf.stack([_num_batch])\n",
    "print(stack.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.random.randint(0, 5,  size =(3, 3))\n",
    "img = tf.constant(a)\n",
    "img = tf.reshape(img,[-1])\n",
    "print(tf.add_n(img))\n",
    "print(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf1.s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
